<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>臭咸鱼的缺氧瓶</title>
  
  <subtitle>快给我氧气！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://chouxianyu.github.io/"/>
  <updated>2021-05-19T02:06:21.675Z</updated>
  <id>https://chouxianyu.github.io/</id>
  
  <author>
    <name>臭咸鱼</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>李宏毅机器学习课程笔记-14.1 Seq2Seq：Conditional Generation</title>
    <link href="https://chouxianyu.github.io/2021/05/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-14-1-Seq2Seq%EF%BC%9AConditional-Generation/"/>
    <id>https://chouxianyu.github.io/2021/05/19/李宏毅机器学习课程笔记-14-1-Seq2Seq：Conditional-Generation/</id>
    <published>2021-05-19T02:02:27.000Z</published>
    <updated>2021-05-19T02:06:21.675Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于RNN的Generation"><a href="#基于RNN的Generation" class="headerlink" title="基于RNN的Generation"></a>基于RNN的Generation</h2><p>可以用RNN生成一个word、sentence、图片等等。</p><p>一个word有多个character组成，因此RNN每次生成一个character。一个sentence由多个word组成，因此RNN每次生成一个word。一张图片由多个像素组成，因此RNN每次生成一个像素。</p><p><img src="https://pic2.zhimg.com/80/v2-70729446c3202faedf198bb178ba5772_720w.png" alt="img"></p><p>从上到下、从左到右逐个生成像素这种方法(上图右上角)并没有充分考虑pixel之间的位置关系，有一种更充分地考虑了pixel之间位置关系的方法(上图右下角)叫做PixelRNN，PixelRNN根据多个邻居生成一个像素，这可以通过3维LSTM单元(上图左上角)实现。如上图左上角所示，3维LSTM单元有3组输入和3组输出，将几层(每层9个)3维LSTM单元排列在一起，就可以生成一张3×3的图片。</p><p>以下为一些使用RNN进行Generation的论文。</p><p><img src="https://pic1.zhimg.com/80/v2-be4bacf8ceeb49812e97cddcbc82fff3_720w.png" alt="img"></p><h2 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h2><p>只使用RNN进行Generation的话是不够的，因为我们希望生成的结果并不是随机的，比如我们希望机器生成的sentence是合乎情境的，假如我说了“Hello”，那机器就应该说“Nice to meet you”之类的内容，这就是<strong>Conditional Generation</strong>。</p><p>为了实现Conditional Generation，我们可以将<strong>condition</strong>转换成vector输入到RNN中。在Chat-bot和Machine Translation任务中，condition就是一个sentence；在Image Caption任务中，condition就是一张图片。</p><p>在实现Conditional Generation时通常使用<strong>Encoder-Decoder</strong>框架，其中Encoder负责将condition转换为一个vector、Decoder负责将condition vector转换成最后的输出。Encoder和Decoder通常是一起训练(jointly train)的，两者的参数可以相同也可以不同。</p><p>在Chat-bot和Machine Translation任务中，输入和输出都是sequence，所以这类任务都是一种Sequence-to-sequence Learning，简称<strong>Seq2Seq</strong>。</p><p>在Chat-bot任务中，机器应该要考虑聊天记录，比如机器说“Hello”然后我回复“Hi”，如果这时机器也回复“Hi”之类的就很智障了，所以机器需要考虑更长的context，如果用户说过了“我叫臭咸鱼”，机器就不应该再问“你的名字是什么/你叫什么”了。因此有一种做法可以是我们有一个双层的Encoder，首先用Encoder的第一层讲聊天记录作为condition表示为vector，然后输入到Encoder的第二层。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基于RNN的Generation&quot;&gt;&lt;a href=&quot;#基于RNN的Generation&quot; class=&quot;headerlink&quot; title=&quot;基于RNN的Generation&quot;&gt;&lt;/a&gt;基于RNN的Generation&lt;/h2&gt;&lt;p&gt;可以用RNN生成一个word
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Seq2Seq" scheme="https://chouxianyu.github.io/tags/Seq2Seq/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.6模型压缩代码实战</title>
    <link href="https://chouxianyu.github.io/2021/05/08/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-6%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/05/08/李宏毅机器学习课程笔记-13-6模型压缩代码实战/</id>
    <published>2021-05-07T23:59:38.000Z</published>
    <updated>2021-05-08T00:14:21.040Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework7的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><h1 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h1><p>通过Architecture Design、Knowledge Distillation、Network Pruning和Weight Quantization这4种模型压缩策略，用一个非常小的model完成homework3中食物图片分类的任务。</p><h2 id="1-Architecture-Design"><a href="#1-Architecture-Design" class="headerlink" title="1.Architecture Design"></a>1.Architecture Design</h2><p>MobileNet提出了Depthwise &amp; Pointwise Convolution。我们在这里实现MobileNet v1这个比较小的network，后续使用Knowledge Distillation策略训练它，然后对它进行剪枝和量化。</p><h2 id="2-Knowledge-Distillation"><a href="#2-Knowledge-Distillation" class="headerlink" title="2.Knowledge Distillation"></a>2.Knowledge Distillation</h2><p>将ResNet18作为Teacher Net(使用torchvision中的ResNet18，仅将num_classes改成11，加载助教训练好的Accuracy约为88.4%的参数)，将上一步(1.Architecture Design)设计的小model作为Student Net，使用Knowledge_Distillation策略训练Student Net。</p><p>Loss计算方法为$Loss = \alpha T^2 \times KL(\frac{\text{Teacher’s Logits}}{T} || \frac{\text{Student’s Logits}}{T}) + (1-\alpha)(\text{Original Loss})$，关于为什么要对student进行logsoftmax可见<a href="https://github.com/peterliht/knowledge-distillation-pytorch/issues/2" target="_blank" rel="noopener">https://github.com/peterliht/knowledge-distillation-pytorch/issues/2</a></p><p>论文《Distilling the Knowledge in a Neural Network》：<a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">https://arxiv.org/abs/1503.02531</a></p><h2 id="3-Network-Pruning"><a href="#3-Network-Pruning" class="headerlink" title="3.Network Pruning"></a>3.Network Pruning</h2><p>对上一步(2.Knowledge_Distillation)训练好的Student Net做剪枝。</p><p>根据论文《Learning Efficient Convolutional Networks through Network Slimming》，论文链接：<a href="https://arxiv.org/abs/1708.06519" target="_blank" rel="noopener">https://arxiv.org/abs/1708.06519</a><br>BatchNorm层中的gamma值和一些特定卷积核（或者全连接层的一个神经元）相关联，因此可以使用BatchNorm层中的gamma值判断相关通道的重要性。</p><p>Student Net中CNN部分有几个结构相同的Sequential，其结构、权重名称、实现代码、权重形状如下表所示。</p><div class="table-container"><table><thead><tr><th style="text-align:center">#</th><th style="text-align:left">name</th><th style="text-align:left">meaning</th><th>code</th><th>weight shape</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:left">cnn.{i}.0</td><td style="text-align:left">Depthwise Convolution</td><td>nn.Conv2d(x, x, 3, 1, 1, group=x)</td><td>(x, 1, 3, 3)</td></tr><tr><td style="text-align:center">1</td><td style="text-align:left">cnn.{i}.1</td><td style="text-align:left">Batch Normalization</td><td>nn.BatchNorm2d(x)</td><td>(x)</td></tr><tr><td style="text-align:center">2</td><td style="text-align:left"></td><td style="text-align:left">ReLU6</td><td>nn.ReLU6</td><td></td></tr><tr><td style="text-align:center">3</td><td style="text-align:left">cnn.{i}.3</td><td style="text-align:left">Pointwise Convolution</td><td>nn.Conv2d(x, y, 1),</td><td>(y, x, 1, 1)</td></tr><tr><td style="text-align:center">4</td><td style="text-align:left"></td><td style="text-align:left">MaxPooling</td><td>nn.MaxPool2d(2, 2, 0)</td></tr></tbody></table></div><p>独立剪枝prune_count次，每次剪枝的剪枝率按prune_rate逐渐增大，剪枝后微调finetune_epochs个epoch。</p><h2 id="4-Weight-Quantization"><a href="#4-Weight-Quantization" class="headerlink" title="4.Weight Quantization"></a>4.Weight Quantization</h2><p>对第二步(2.Knowledge_Distillation)训练好的Student Net做量化（用更少的bit表示一个value）。</p><p>torch预设的FloatTensor是32bit，而FloatTensor最低可以是16bit。</p><p>如何将32bit转成8bit的int呢？对每个weight进行min-max normalization，然后乘以$2^8-1$再四舍五入成整数，这样就可以转成uint8了。</p><h1 id="数据集描述"><a href="#数据集描述" class="headerlink" title="数据集描述"></a>数据集描述</h1><p>数据集为homework3中食物图片分类数据集。</p><p>11个图片类别，训练集中有9866张图片，验证集中有3430张图片，测试集中有3347张图片。</p><p>训练集和验证集中图片命名格式为<code>类别_编号.jpg</code>，编号不重要。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw7_NetworkCompression" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw7_NetworkCompression</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework7的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="知识蒸馏" scheme="https://chouxianyu.github.io/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/"/>
    
      <category term="网络剪枝" scheme="https://chouxianyu.github.io/tags/%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"/>
    
      <category term="参数量化" scheme="https://chouxianyu.github.io/tags/%E5%8F%82%E6%95%B0%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.5模型压缩之动态计算</title>
    <link href="https://chouxianyu.github.io/2021/05/07/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-5%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B9%8B%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97/"/>
    <id>https://chouxianyu.github.io/2021/05/07/李宏毅机器学习课程笔记-13-5模型压缩之动态计算/</id>
    <published>2021-05-07T03:25:13.000Z</published>
    <updated>2021-05-07T03:25:50.584Z</updated>
    
    <content type="html"><![CDATA[<p>动态计算（Dynamic Computation）就是资源充足时就做到最好，资源不足时就减少运算量、先求有再求好(但也不要太差)。</p><p>一种方法是训练多个从小到大的model，然后选择合适的模型，这样的问题是需要存储很多个model。</p><p>另外一种方法是，<strong>训练一个在中间层就可以得到最终结果的model</strong>。因为网络浅层和深层提取到的特征一般分别是低级特征和高级特征，所以在网络浅层得到的结果一般要比在网络深层得到的结果差一些。在网络浅层就计算最终结果可能会迫使网络浅层学习一些高级特征，这会破坏网络从浅层到深层逐步提取低/高级特征的架构。那如何处理这些问题呢？可以看一看Multi-Scale Dense Convolutional Networks：<a href="https://arxiv.org/abs/1703.09844" target="_blank" rel="noopener">https://arxiv.org/abs/1703.09844</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;动态计算（Dynamic Computation）就是资源充足时就做到最好，资源不足时就减少运算量、先求有再求好(但也不要太差)。&lt;/p&gt;
&lt;p&gt;一种方法是训练多个从小到大的model，然后选择合适的模型，这样的问题是需要存储很多个model。&lt;/p&gt;
&lt;p&gt;另外一种方法是
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="动态计算" scheme="https://chouxianyu.github.io/tags/%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.4模型压缩之架构设计</title>
    <link href="https://chouxianyu.github.io/2021/05/06/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-4%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B9%8B%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    <id>https://chouxianyu.github.io/2021/05/06/李宏毅机器学习课程笔记-13-4模型压缩之架构设计/</id>
    <published>2021-05-06T00:23:13.000Z</published>
    <updated>2021-05-06T00:38:46.076Z</updated>
    
    <content type="html"><![CDATA[<p>调整Network的架构设计（Architecture Design），让它变得只需要比较少的参数，这是在实际操作中最有效的做法。</p><h2 id="Low-Rank-Approximation"><a href="#Low-Rank-Approximation" class="headerlink" title="Low Rank Approximation"></a>Low Rank Approximation</h2><p>如果是Fully Connected Network，前一层和后一层分别有N、M个neuron则需要$N\times M$个参数，我们可以在这两层中间加一个有K个neuron的层(不要激活函数)就需要$K(N+M)$个neuron，这样就可以减少参数量，但是根据线性代数的知识可知这3层的性能不一定比之前的2层好。</p><h2 id="Depthwise-amp-Pointwise-Convolution"><a href="#Depthwise-amp-Pointwise-Convolution" class="headerlink" title="Depthwise &amp; Pointwise Convolution"></a>Depthwise &amp; Pointwise Convolution</h2><p>在普通卷积中，每个filter（卷积核）要处理输入的所有channel。假设输入有$I$个channel，有$O$个尺寸为$k\times k$的filter，则需要$(k\times k\times I)\times O$个参数、输出$O$个channel。</p><p>深度可分离卷积(Depthwise Separable Convolution)又称为<strong>Depthwise&amp;Pointwise Convolution</strong>，分为以下2步，共需要$k\times k\times I+I\times O$个参数、输出$O$个channel。</p><ol><li><p>Depthwise Convolution</p><p> 在这一步中，filter的数量等于输入channel的数量，即<strong>每个filter只处理一个channel，这步的作用就是修改输入的尺寸</strong>。</p><p> 假设输入有$I$个channel，因此就有$I$个filter；假设每个filter的尺寸为$k\times k$，则需要$(k\times k\times1)\times I$个参数、输出$I$个channel。</p></li><li><p>Pointwise Convolution</p><p> 在这一步中，以上一步(Depthwise Convolution)的输出作为输入，<strong>每个filter的尺寸必须为$1\times 1$，和普通卷积核一样要处理输入的所有channel，这步的作用就是修改输入的通道数</strong>。</p><p> 假设有$O$个filter，则需要$(1\times1\times I)\times O$个参数、输出$O$个channel。</p></li></ol><h2 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a>Group Convolution</h2><p>Group Convolution就是把输入的多个channel分成多个group，对每个group分别进行一次或多次普通卷积。Group Convolution算是普通卷积和Depthwise Convolution的折衷，当group数量和输入的通道数相同时它就相当于Depthwise Convolution，当group数量为1时它就相当于普通卷积。</p><h2 id="不同卷积的PyTorch实现"><a href="#不同卷积的PyTorch实现" class="headerlink" title="不同卷积的PyTorch实现"></a>不同卷积的PyTorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通卷积, weight数量 = in_chs * out_chs * kernel_size^2</span></span><br><span class="line">nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Group Convolution, Group数量可以自行控制，表示要分成几个group，其中in_chs和out_chs必须可以被groups整除</span></span><br><span class="line">nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Depthwise Convolution, 输入通道数=输出通道数=group数量, weight数量 = in_chs * kernel_size^2</span></span><br><span class="line">nn.Conv2d(in_chs, out_chs=in_chs, kernel_size, stride, padding, groups=in_chs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pointwise Convolution, 也就是1×1卷积, weight数量 = in_chs * out_chs</span></span><br><span class="line">nn.Conv2d(in_chs, out_chs, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Depthwise Separable Convolution被广泛地用在各种小型网络中：SqueezeNet、MobileNet、ShuffleNet、Xception，其中最知名的为MobileNet。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;调整Network的架构设计（Architecture Design），让它变得只需要比较少的参数，这是在实际操作中最有效的做法。&lt;/p&gt;
&lt;h2 id=&quot;Low-Rank-Approximation&quot;&gt;&lt;a href=&quot;#Low-Rank-Approximation&quot; c
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.3模型压缩之参数量化</title>
    <link href="https://chouxianyu.github.io/2021/05/05/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-3%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B9%8B%E5%8F%82%E6%95%B0%E9%87%8F%E5%8C%96/"/>
    <id>https://chouxianyu.github.io/2021/05/05/李宏毅机器学习课程笔记-13-3模型压缩之参数量化/</id>
    <published>2021-05-05T01:49:34.000Z</published>
    <updated>2021-05-05T01:54:04.032Z</updated>
    
    <content type="html"><![CDATA[<p>参数量化就是Parameter Quantization。</p><ol><li><p>用更少的bit表示一个value</p><p> 比如说本来用32位表示一个weight，现在用16位表示一个weight，这样就缩小了一半。</p></li><li><p>Weight Clustering</p><p> 根据weight的值对weight进行聚类，每个类中的weight都用同一个value(比如该类中所有weight的平均值)表示。每个类有个id，2个bit就可以表示4个类的id(再进一步还可以使用哈夫曼编码)，在存储时只需要存储每个weight所属的类的id以及每个类对应的value即可。</p><p> 因为每个类中的weight都用了同一个value表示，所以模型会有一些精度损失。</p></li><li><p>Binary Weights</p><p> weight的值只有±1。</p><p> 有不少研究者提出直接训练一个Binary Network，最早的是Binary Connect（<a href="http://arxiv.org/abs/1511.00363），其它的还有Binary" target="_blank" rel="noopener">http://arxiv.org/abs/1511.00363），其它的还有Binary</a> Network（<a href="https://arxiv.org/abs/1602.02830）、XNOR-Net（https://arxiv.org/abs/1603.05279）。" target="_blank" rel="noopener">https://arxiv.org/abs/1602.02830）、XNOR-Net（https://arxiv.org/abs/1603.05279）。</a></p><p> Binary Connect在训练中有2个分别使用real value和binary value的model，暂称为R和B。首先初始化R的参数，然后找到和R最接近的B，再使用B的梯度更新R的参数，然后再找到和R最接近的B，循环该过程直到停止，最后就使用最终的B。</p><p> Binary Connect其实像是一种Regularization，它约束weight的值必须是±1。</p></li></ol><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参数量化就是Parameter Quantization。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用更少的bit表示一个value&lt;/p&gt;
&lt;p&gt; 比如说本来用32位表示一个weight，现在用16位表示一个weight，这样就缩小了一半。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="参数量化" scheme="https://chouxianyu.github.io/tags/%E5%8F%82%E6%95%B0%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.2模型压缩之知识蒸馏</title>
    <link href="https://chouxianyu.github.io/2021/05/04/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-2%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B9%8B%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/"/>
    <id>https://chouxianyu.github.io/2021/05/04/李宏毅机器学习课程笔记-13-2模型压缩之知识蒸馏/</id>
    <published>2021-05-04T01:37:48.000Z</published>
    <updated>2021-05-04T01:47:41.640Z</updated>
    
    <content type="html"><![CDATA[<p>知识蒸馏就是Knowledge Distillation。</p><p>Knowledge Distillation：<a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">https://arxiv.org/abs/1503.02531</a></p><p>Do Deep Nets Really Need to be Deep?：<a href="https://arxiv.org/abs/1312.6184" target="_blank" rel="noopener">https://arxiv.org/abs/1312.6184</a></p><p>熟悉YOLO的读者，可以根据这个仓库感受一下剪枝和知识蒸馏：<a href="https://github.com/tanluren/yolov3-channel-and-layer-pruning" target="_blank" rel="noopener">https://github.com/tanluren/yolov3-channel-and-layer-pruning</a></p><h2 id="Student-and-Teacher"><a href="#Student-and-Teacher" class="headerlink" title="Student and Teacher"></a>Student and Teacher</h2><p>什么是Knowledge Distillation？</p><p>我们可以让一个较小的<strong>Student Net</strong>向较大的<strong>Teacher Net</strong>学习，使得Student Net的输出尽可能接近Teacher Net的输出。</p><p>普通的训练方式为仅在数据集上训练Student Net，而Knowledge Distillation的思路是：即使Teacher Net的输出并不一定是正确的，但<strong>Teacher Net可以提供一些数据集无法提供的信息</strong>，比如手写数字图片分类模型Teacher Net的输出为“1：0.7，7：0.2，9：0.1”，这不仅说明这张图片像1，<strong>还可以说明1和7、9很相似</strong>。</p><p>或者可以这么理解：学生自己直接做题目太难了，让学生学习下老师是怎么想的可能会更好。</p><h2 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h2><p>Knowledge Distillation有什么用呢？</p><p>打Kaggle比赛时很多人的做法是ensemble（将多个model的结果进行平均）。Ensemble通常可以得到更好的精度，但现实中设备上不可能放这么多个model，这时就可以利用Knowledge Distillation让Student Net向Teacher Net学习，最终设备上只运行Student Net就可以。</p><h2 id="Temperature"><a href="#Temperature" class="headerlink" title="Temperature"></a>Temperature</h2><p>在分类任务中，网络的最后一般有个softmax函数：$y_i=\frac{e^{x_i}}{\sum_je^{x^j}}$，其中$y_i$是输入属于类别$i$的置信度。</p><p>在Knowledge Distillation中，我们需要对softmax函数进行调整：$y_i=\frac{e^{\frac{x_i}{T}}}{\sum_je^{\frac{x^j}{T}}}$，其中$T$为Temperature，一般是一个大于1的数，它的作用是使得Teacher Net输出的属于各个类别的置信度更加接近，如下图所示。</p><p><img src="https://pic1.zhimg.com/80/v2-c06e6c918f5c8ac800f28f35deca8473_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;知识蒸馏就是Knowledge Distillation。&lt;/p&gt;
&lt;p&gt;Knowledge Distillation：&lt;a href=&quot;https://arxiv.org/abs/1503.02531&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;htt
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="知识蒸馏" scheme="https://chouxianyu.github.io/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.1模型压缩之网络剪枝</title>
    <link href="https://chouxianyu.github.io/2021/05/02/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-1%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B9%8B%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"/>
    <id>https://chouxianyu.github.io/2021/05/02/李宏毅机器学习课程笔记-13-1模型压缩之网络剪枝/</id>
    <published>2021-05-01T22:24:53.000Z</published>
    <updated>2021-05-01T22:40:07.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>网络剪枝（Network Pruning）就是删除一个较大网络中的一些weight或neuron得到一个更小的网络。</p><p>我们相信，<strong>通常情况下我们训练出的神经网络是over-parameterized</strong>，即其中存在很多weight或neuron是没有用的(比如有些neuron的输出总是0、有些weight非常接近0) ，因此我们可以把这些没有用的weight或neuron剪掉。</p><p>在90年代，Yann Le Cun就提出了“网络剪枝”，paper名称为Optimal Brain Damage。</p><p>有个问题是：为什么不直接使用较小Network而是对较大Network进行剪枝？常见的解释是：较小的Network训练出来的结果一般都不好，而较大的Network更容易optimize（李老师这个视频有讲解为什么：<a href="https://www.youtube.com/watch?v=_VuWvQUMQVk）。在训练神经网络时可能会遇到local" target="_blank" rel="noopener">https://www.youtube.com/watch?v=_VuWvQUMQVk）。在训练神经网络时可能会遇到local</a> minima和saddle point的问题，但如果Network够大这种问题就会不那么严重，现在有很多文献甚至可以证明只要Network够大就可以用梯度下降找到global optimal。</p><h2 id="How-to-Prune-a-Network"><a href="#How-to-Prune-a-Network" class="headerlink" title="How to Prune a Network"></a>How to Prune a Network</h2><ol><li><p>训练出一个较大的Network</p></li><li><p>评估该Network中每个weight和neuron的重要性</p><p> 这一步有很多种做法</p><ul><li><p>weight的重要性</p><p>  比如：如果其值接近0，则说明该weight不重要，因此可以计算weight的L1或L2判断weight的重要性。</p></li><li><p>neuron的重要性</p><p>  比如：给定dataset，如果某个neural的输出都是0那么该neural是不那么重要的</p></li></ul></li><li><p>根据重要性将weight和neuron排序并删除那些不那么重要的weight和neuron</p><p> 删除一些weight和neuron后，Network会变小但精度一般也会变低，因此还需要进行fine-tune</p><p> 一次最好不要删除太多neuron或weight，否则Network的精度会无法通过fine-tune恢复，最好是每次只删除一小部分然后进行fine-tune并重复该过程</p></li><li><p>fine-tune</p><p> 训练剪枝得到的较小的网络</p></li></ol><p>熟悉YOLO的读者，可以根据这个仓库（<a href="https://github.com/tanluren/yolov3-channel-and-layer-pruning）感受一下剪枝和知识蒸馏。" target="_blank" rel="noopener">https://github.com/tanluren/yolov3-channel-and-layer-pruning）感受一下剪枝和知识蒸馏。</a></p><h2 id="Lottery-Ticket-Hypothesis"><a href="#Lottery-Ticket-Hypothesis" class="headerlink" title="Lottery Ticket Hypothesis"></a>Lottery Ticket Hypothesis</h2><p>论文链接：<a href="https://arxiv.org/abs/1803.03635，这是ICLR2019的一篇论文" target="_blank" rel="noopener">https://arxiv.org/abs/1803.03635，这是ICLR2019的一篇论文</a></p><p>如下图所示，现有一个较大网络A，随机初始化其参数并记该参数为W，训练该较大网络A并进行剪枝得到较小网络B。有个现象是：如果我们随机初始化较小网络B的参数并进行训练，得到的结果就不行；但如果使用参数W中的对应参数初始化，得到的结果就可以。</p><p><img src="https://pic4.zhimg.com/80/v2-6bbbbfc39567d8a138f36ac44ef94849_720w.png" alt="img"></p><h2 id="Rethinking-the-Value-of-Network-Pruning"><a href="#Rethinking-the-Value-of-Network-Pruning" class="headerlink" title="Rethinking the Value of Network Pruning"></a>Rethinking the Value of Network Pruning</h2><p>论文链接：<a href="https://arxiv.org/abs/1810.05270，这是ICLR2019的一篇论文" target="_blank" rel="noopener">https://arxiv.org/abs/1810.05270，这是ICLR2019的一篇论文</a></p><p>这篇论文的结论和Lottery Ticket Hypothesis一文相反：现有剪枝后的网络，将其参数随机初始化是可以训练出好的结果的。</p><p>ICLR2019的review是开放的，网上可以搜到两篇文章作者的讨论，知乎上也有关于这两篇论文的讨论，后续也有人做了相关研究。</p><h2 id="Some-Issue-in-Weight-Pruning"><a href="#Some-Issue-in-Weight-Pruning" class="headerlink" title="Some Issue in Weight Pruning"></a>Some Issue in Weight Pruning</h2><p>如果是weight pruning，那剪枝后的Network会变得不规则（比如有些neuron有2个weight而有些neuron有4个weight）。这样的不规则的Network是不好用keras等代码框架实现的，并且GPU只能对矩阵运算进行加速而无法加速这样的Network。比较常见的实做方法是将需要剪掉的weight设成0，因此仍然可以用GPU加速，但这样其实并没有使网络变小。</p><p>实际上做weight pruning是很麻烦的，通常都进行neuron pruning，因为比较容易用代码实现、也容易达到加速的目的。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;网络剪枝（Network Pruning）就是删除一个较大网络中的一些wei
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="网络剪枝" scheme="https://chouxianyu.github.io/tags/%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.4对抗攻击代码实战</title>
    <link href="https://chouxianyu.github.io/2021/05/01/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-4%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/05/01/李宏毅机器学习课程笔记-12-4对抗攻击代码实战/</id>
    <published>2021-05-01T00:13:08.000Z</published>
    <updated>2021-05-01T00:29:31.272Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework6的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述</p><p>  选择一个Proxy Network实现<strong>Black Box</strong> Attack，通过FGSM(Fast Gradient Sign Method)实现Non-targeted Adversial Attack。</p></li><li><p>数据集描述</p><p>  有200张图片，命名格式为<code>编号.png</code>，尺寸为224×224。</p><p>  categories.csv：1000个类别，索引为[0,999]，</p><p>  labels.csv：每张图片的信息(包括类别索引)</p></li><li><p>评估指标</p><ul><li>所有输入图片$x^0$和攻击图片$x’$的L-infinity的平均值</li><li>攻击的成功率</li></ul></li><li><p>结果</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Original Proxy Network Accuracy: <span class="number">0.865</span></span><br><span class="line">After Attack(epsilon: <span class="number">0.1</span>) Accrucy: <span class="number">0.03</span></span><br><span class="line">Original Proxy Network Accuracy: <span class="number">0.865</span></span><br><span class="line">After Attack(epsilon: <span class="number">0.01</span>) Accrucy: <span class="number">0.27</span></span><br></pre></td></tr></table></figure><p>  使用预训练的VGG16作为Proxy Network，可知在攻击前Proxy Nerwork的准确率为0.865，而攻击后准确率为0.03(epsilon为0.1)、0.27(epsilon为0.01)</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework6的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.3对抗防御入门</title>
    <link href="https://chouxianyu.github.io/2021/04/30/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-3%E5%AF%B9%E6%8A%97%E9%98%B2%E5%BE%A1%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/30/李宏毅机器学习课程笔记-12-3对抗防御入门/</id>
    <published>2021-04-30T01:55:55.000Z</published>
    <updated>2021-05-01T00:17:37.833Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-Defense"><a href="#What-is-Defense" class="headerlink" title="What is Defense"></a>What is Defense</h2><p>有人说模型容易被攻破是因为过拟合，但其实并不是，因为weight regularization、dropout、model ensemble都不能抵挡Adversarial Attack，并且Attack可以攻击多个model。</p><p>Defense分为两类：</p><ul><li><p>Passive Defense</p><p>  不修改模型，而是在模型前加一个filter防止模型被攻击，其实这是Anomaly Detection的一个特例。</p></li><li><p>Proactive Defense</p><p>  训练模型时就对Attack进行防御</p></li></ul><p>如果攻击者知道Defense的具体实现，那攻击者一般仍然可以将Defense攻破。</p><h2 id="Passive-Defense"><a href="#Passive-Defense" class="headerlink" title="Passive Defense"></a>Passive Defense</h2><p>在模型前加一个filter防止模型被攻击，filter的作用就是扰动攻击信号$\Delta x$使其无效，这个filter并不需要很复杂，有时smoothing就可以，还有Gaussian Filter、Median Filter、Bilateral Filter等等。</p><ul><li><p>Feature Squeeze</p><p>  将图片输入模型得到输出P1，然后分别使用2个Squeezer对图片进行处理后再输入到模型得到输出P2、P3，如果P1和P2的差距、P2和P3的差距超过了某个值就判断该图片是攻击图片。</p><p>  详见：Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks(<a href="https://arxiv.org/abs/1704.01155" target="_blank" rel="noopener">https://arxiv.org/abs/1704.01155</a>)</p></li><li><p>Randomization at Inference Phase</p><p>  将图片随机稍微缩放然后随机padding，然后随机选择其中一个结果输入到模型。</p><p>  详见：Mitigating Adversarial Effects Through Randomization(<a href="https://arxiv.org/abs/1711.01991" target="_blank" rel="noopener">https://arxiv.org/abs/1711.01991</a>)</p></li></ul><h2 id="Proactive-Defense"><a href="#Proactive-Defense" class="headerlink" title="Proactive Defense"></a>Proactive Defense</h2><p>在训练模型时就找出模型的漏洞并进行改善。</p><p>首先用训练集训练模型，然后多次迭代，在每次迭代中使用某种攻击方法分别找到每个训练集样本对应的攻击样本$x’$，然后把这些攻击样本添加到训练集中进行训练(这有点像数据增强)，多次迭代的原因是基于新的训练集训练后模型可能会产生新的漏洞。</p><p>注意：假如在Proactive Defense时我们使用的攻击方法为A，那我们的模型也许可以防御他人的A攻击，但仍无法防御其它攻击方法。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;What-is-Defense&quot;&gt;&lt;a href=&quot;#What-is-Defense&quot; class=&quot;headerlink&quot; title=&quot;What is Defense&quot;&gt;&lt;/a&gt;What is Defense&lt;/h2&gt;&lt;p&gt;有人说模型容易被攻破是因为过拟合，但
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.2对抗攻击进阶</title>
    <link href="https://chouxianyu.github.io/2021/04/28/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-2%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E8%BF%9B%E9%98%B6/"/>
    <id>https://chouxianyu.github.io/2021/04/28/李宏毅机器学习课程笔记-12-2对抗攻击进阶/</id>
    <published>2021-04-28T02:35:42.000Z</published>
    <updated>2021-04-28T02:36:53.301Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h2><p>Attack可以是分别为每个输入$x^0$找到对应的攻击信号$\Delta x$，还可以是找到一个适用于所有输入的攻击信号$\Delta x$，这就是Universal Adversarial Attack，详见：Universal adversarial perturbations(<a href="https://arxiv.org/abs/1610.08401)。" target="_blank" rel="noopener">https://arxiv.org/abs/1610.08401)。</a></p><h2 id="One-Pixel-Attack"><a href="#One-Pixel-Attack" class="headerlink" title="One Pixel Attack"></a>One Pixel Attack</h2><p>One Pixel Attack就是攻击时的constraint为只能修改图片中一个pixel，即$d(x^0,x’)=||x^0-x’||_0=||\Delta x||_0\leq1$，其中可以将L0范数理解为非零元素的个数。</p><p>如何确定要攻击哪个像素呢？暴力求解速度会很慢。还有个问题是我们是否需要最佳的攻击方案？如果能够使用Loss梯度下降找到最佳的攻击方案，那当然是好的，但其实我们只需攻击成功即可，因为攻击的目标主要是使模型失效，只要可以攻击成功就行。比如原模型对某图片的分类结果是置信度为16.48%的Cup，我们能找到一个方案使模型分类结果是置信度为16.74%的Soup Bowl即可而不需要必须使得置信度为100%。同理，我们只要能找到某个可以击破的像素就行而并不需要找到最薄弱的像素。</p><p>那如何找到一个攻击方案呢？用Differential Evolution就行。Differential Evolution的好处是有较大的概率得到全局最优解并且不需要计算梯度也就不需要被攻击模型的参数。Differential Evolution与遗传算法非常类似，都包括变异、杂交和选择操作，但这些操作的具体定义与遗传算法有所不同。</p><p>详见One pixel attack for fooling deep neural networks(<a href="https://arxiv.org/abs/1710.08864)。" target="_blank" rel="noopener">https://arxiv.org/abs/1710.08864)。</a></p><h2 id="Adversarial-Reprogramming"><a href="#Adversarial-Reprogramming" class="headerlink" title="Adversarial Reprogramming"></a>Adversarial Reprogramming</h2><p>我们可以在不改变模型参数的情况下，通过Attack来修改模型的“功能”，比如将一个图片分类模型的功能改为方块计数(方块数量对应某种种类)，详见：</p><ul><li>Adversarial Reprogramming of Neural Networks(<a href="https://arxiv.org/abs/1806.11146v2" target="_blank" rel="noopener">https://arxiv.org/abs/1806.11146v2</a>)</li><li><a href="https://arxiv.org/abs/1705.09554" target="_blank" rel="noopener">https://arxiv.org/abs/1705.09554</a></li><li><a href="https://arxiv.org/abs/1707.05572" target="_blank" rel="noopener">https://arxiv.org/abs/1707.05572</a></li></ul><h2 id="Attack-in-the-Physical-World"><a href="#Attack-in-the-Physical-World" class="headerlink" title="Attack in the Physical World"></a>Attack in the Physical World</h2><p>有一个问题是，我们说的这些攻击在物理世界中会失效吗？比如相机等设备会不会像人一样无法识别那些攻击信号呢？答案是不一定。有人做了相关实验，将扰动得到的图片$x’$打印出来，然后用手机、相机等拍照再做分类或识别，仍然可以成功攻击模型，详见：Adversarial examples in the physical world(<a href="https://arxiv.org/abs/1607.02533v4)、https://www.youtube.com/watch?v=zQ_uMenoBCk&amp;feature=youtu.be" target="_blank" rel="noopener">https://arxiv.org/abs/1607.02533v4)、https://www.youtube.com/watch?v=zQ_uMenoBCk&amp;feature=youtu.be</a></p><p>攻击还可以用在人脸识别领域，比如我戴一个实体眼镜(用于攻击)之后可能就会被人脸识别系统识别为其他人，详见：<a href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf</a></p><p>攻击还可以用在自动驾驶中，假如汽车在自动驾驶时需要看红绿灯等标志物，那在这些标志物上贴一些攻击信号也许就会导致车辆“失控”，详见：<a href="https://arxiv.org/abs/1707.08945" target="_blank" rel="noopener">https://arxiv.org/abs/1707.08945</a></p><h2 id="Attack-Text-amp-Audio"><a href="#Attack-Text-amp-Audio" class="headerlink" title="Attack Text &amp; Audio"></a>Attack Text &amp; Audio</h2><p>攻击并不仅限于Image，还可以攻击Text，可参考：<a href="https://arxiv.org/pdf/1707.07328.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1707.07328.pdf</a></p><p>攻击并不仅限于Image和Text，还可以攻击Audio，可参考：</p><ul><li><a href="https://nicholas.carlini.com/code/audio_adversarial_examples" target="_blank" rel="noopener">https://nicholas.carlini.com/code/audio_adversarial_examples</a></li><li><a href="https://adversarial-attacks.net" target="_blank" rel="noopener">https://adversarial-attacks.net</a></li><li>现实中ASR可能会受到攻击，ASR指Automatic Speech Recognition(自动语音识别)，即语音转文字，详见：<a href="https://nicholas.carlini.com/code/audio_adversarial_examples/" target="_blank" rel="noopener">https://nicholas.carlini.com/code/audio_adversarial_examples/</a></li><li>ASV也可能会受到攻击，ASV指Automatic Speaker Verification，即识别是谁讲话，详见：<a href="https://arxiv.org/abs/1911.01840" target="_blank" rel="noopener">https://arxiv.org/abs/1911.01840</a></li></ul><h2 id="Hidden-Voice-Attack"><a href="#Hidden-Voice-Attack" class="headerlink" title="Hidden Voice Attack"></a>Hidden Voice Attack</h2><p>Hidden Voice Attack就是生成一段人类无法听懂的audio但仍然可以骗过你的模型，比如用一段人类听不懂但被模型判定为“Hey, Siri”的audio启动你的苹果手机。</p><p>详见：<a href="https://arxiv.org/abs/1904.05734" target="_blank" rel="noopener">https://arxiv.org/abs/1904.05734</a></p><p>如下图所示，处理audio的步骤为Preprocessing、Signal Processing、Model Inference，Hidden Voice Attack就是在Signal Processing阶段进行攻击。</p><p><img src="https://pic4.zhimg.com/80/v2-c9deeab05746a3649cacdad7f5ff7c91_720w.png" alt="img"></p><p>如下图所示，对audio的扰动方式有4种，具体不再详细介绍。</p><p><img src="https://pic1.zhimg.com/80/v2-57afffde6ff0ea8a468ce57bbd9b3f83_720w.png" alt="img"></p><h3 id="Time-Domain-Inversion"><a href="#Time-Domain-Inversion" class="headerlink" title="Time Domain Inversion"></a>Time Domain Inversion</h3><p>Time Domain Inversion简称TDI，它利用了magnitude FFT多对一的性质(两个不同的signal经过mFFT可以得到相同结果)，所以我们可以将time domain中的signal进行处理，处理之后会影响人听懂但不影响模型。</p><h3 id="Random-Phase-Generation"><a href="#Random-Phase-Generation" class="headerlink" title="Random Phase Generation"></a>Random Phase Generation</h3><p>FFT返回了一个复数$a+bi$，而$magnitude=\sqrt{a^2+b^2}$，不同的$a$和$b$可以计算得到相同的magnitude，所以可以对$a$和$b$进行修改，修改后会影响人听懂但不影响模型。</p><h3 id="High-Frequency-Addition"><a href="#High-Frequency-Addition" class="headerlink" title="High Frequency Addition"></a>High Frequency Addition</h3><p>High Frequency Addition简称HFA。</p><p>在Preprocessing过程中会使用low-pass filter过滤掉比人声高很多的频段以增加Voice Processing System的准确率，那我们就可以在audio中加入高频段audio，这样会影响人听懂但不影响模型。</p><h3 id="Time-Scaling"><a href="#Time-Scaling" class="headerlink" title="Time Scaling"></a>Time Scaling</h3><p>将audio缩短到model能正确辨识但人听不懂。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Universal-Adversarial-Attack&quot;&gt;&lt;a href=&quot;#Universal-Adversarial-Attack&quot; class=&quot;headerlink&quot; title=&quot;Universal Adversarial Attack&quot;&gt;&lt;/a&gt;Un
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.1对抗攻击入门</title>
    <link href="https://chouxianyu.github.io/2021/04/27/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-1%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/27/李宏毅机器学习课程笔记-12-1对抗攻击入门/</id>
    <published>2021-04-27T02:23:23.000Z</published>
    <updated>2021-04-27T03:13:03.268Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>我们希望我们的模型不仅仅是在大多数情况下可用的，还希望它能够应对来自外界的“攻击”，特别是在垃圾邮件分类、恶意软件检测、网络入侵检测等任务中。</p><p>这个领域为对抗攻击与防御（Adversarial Attack and Defense），目前攻击是比较容易的而防御比较困难。</p><h2 id="What-is-Attack"><a href="#What-is-Attack" class="headerlink" title="What is Attack"></a>What is Attack</h2><p>attack就是往原输入$x^0$中添加一些特别的噪声$\Delta x$(并不是随机生成的)得到一个稍微有些不同的输入$x’=x^0+\Delta x$，而模型却得到一个与原输出截然不同的输出。如下图所示，在图像分类任务中，对一张“Tiger Cat”图片添加一些特别的噪声$\Delta x$后，人类还能看出它是“Tiger Cat”，但模型却认为它是其它的类别。</p><p><img src="https://pic1.zhimg.com/80/v2-5610b9b55bf8893362a8526352810834_720w.png" alt="img"></p><h2 id="Loss-Function-For-Attack"><a href="#Loss-Function-For-Attack" class="headerlink" title="Loss Function For Attack"></a>Loss Function For Attack</h2><p>攻击可以分为两种：Non-targeted Attack和Targeted Attack。</p><h3 id="How-To-Train"><a href="#How-To-Train" class="headerlink" title="How To Train"></a>How To Train</h3><p>我们是这样训练一个普通的神经网络的：将输入$x^0$输入到模型后，我们希望<strong>模型的输出$y^0$和标签$y^{true}$越接近越好</strong>，则损失函数为$L_{train}(\theta)=C(y^0,y^{true})$。<strong>此时输入$x^0$是固定的，我们需要不断调整模型参数$\theta$</strong>，使得$L_{train}(\theta)$最小。</p><h3 id="Non-targeted-Attack"><a href="#Non-targeted-Attack" class="headerlink" title="Non-targeted Attack"></a>Non-targeted Attack</h3><p>如果是Non-targeted Attack，将输入$x’=x+\Delta x$输入到模型后，我们希望<strong>模型的输出$y’$和标签$y^{true}$的差异越大越好</strong>，则损失函数为$L_{Non-targeted\ Attack}(x’)=-C(y’,y^{true})$，比$L_{train}(\theta)$多了一个负号。<strong>此时模型参数$\theta$是固定的，我们需要不断调整输入$x’$</strong>，使$L_{Non-targeted\ Attack}(x’)$最小。</p><h3 id="Targeted-Attack"><a href="#Targeted-Attack" class="headerlink" title="Targeted Attack"></a>Targeted Attack</h3><p>如果是Targeted Attack，将输入$x’=x+\Delta x$输入到模型后，我们希望<strong>模型的输出$y’$和标签$y^{true}$的差异越大越好并且模型的输出$y’$与某个$y^{false}$越接近越好</strong>，其中$y^{false}$需要人为选择，则损失函数为$L_{Targeted\ Attack}(x’)=-C(y’,y^{true})+C(y’,y^{false})$。<strong>此时模型参数$\theta$是固定的，我们需要不断调整输入$x’$</strong>，使$L_{Targeted\ Attack}(x’)$最小。</p><h2 id="Constraint-For-Attack"><a href="#Constraint-For-Attack" class="headerlink" title="Constraint For Attack"></a>Constraint For Attack</h2><p>在Attack中，除了要使$L_{Non-targeted\ Attack}(x’)$和$L_{Targeted\ Attack}(x’)$最小之外，我们还希望<strong>$x^0$和$x’$之间的差异较小</strong>，即$d(x^0,x’)\leq\epsilon$，其中$\epsilon$需要人为选择，这样才能实现真正的Attack。</p><p>主要有两种计算$d(x^0,x’)$的方法，但在不同的任务中应该有不同的计算方法，因为其代表着人类视角下$x^0$和$x’$之间的差异。</p><h3 id="L2-norm"><a href="#L2-norm" class="headerlink" title="L2-norm"></a>L2-norm</h3><p>L2-norm为$x^0$和$x’$中每个像素之差的平方和，即$d(x^0,x’)=||x^0-x’||_2=||\Delta x||_2=(\Delta x_1)^2+(\Delta x_2)^2+(\Delta x_3)^2+\dots$</p><h3 id="L-infinity"><a href="#L-infinity" class="headerlink" title="L-infinity"></a>L-infinity</h3><p>L-infinity为$x^0$和$x’$中每个像素之差的最大值，即$d(x^0,x’)=||x^0-x’||_{\infin}=||\Delta x||_{\infty}=max\{\Delta x_1,\Delta x_2,\Delta_3,\dots\}$</p><p>对于图像中的pixel来讲，也许L-infinity是更有效的计算方法。</p><h2 id="How-to-Attack"><a href="#How-to-Attack" class="headerlink" title="How to Attack"></a>How to Attack</h2><p>我们在Attack时要训练的参数是输入$x’$而非模型参数$\theta$，在$d(x^0,x’)\leq\epsilon$的情况下使得$L(x’)$最小，即$x^*=arg\mathop{min}_\limits {d(x^0,x’)\leq\epsilon}L(x’)$。</p><p>关于如何训练输入$x’$而非模型参数$\theta$，可以参考下Explainable AI的代码部分，其实就是设置输入$x’$的梯度是可追踪的并在定义优化器时传入输入$x’$而非模型参数$\theta$。</p><p><img src="https://pic1.zhimg.com/80/v2-cabb0848c34eca5fe5f4009181b49e7b_720w.png" alt="img"></p><p>如上图所示，在训练时有两个关键点。第一点是输入$x’$应该用$x^0$初始化；第二点是在每个iteration中需要判断保证$d(x^0,x’)\leq\epsilon$，具体来讲就是当发现$d(x^0,x’)&gt;\epsilon$时就需要将$x’$修正为所有满足$d(x^0,x)&gt;\epsilon$的$x$中与$x’$最接近的那个。那要怎么找到所有满足$d(x^0,x)&gt;\epsilon$的$x$中与$x’$最接近的那个呢？下图中圆形和正方形中的$x$均满足$d(x^0,x)&gt;\epsilon$，所以中心$x^0$与$x’$连线与圆形或正方形的交点就是要修正的结果。</p><p><img src="https://pic2.zhimg.com/80/v2-163a5c710e5ed504d06debfb7c509493_720w.png" alt="img"></p><h2 id="Attack-Approaches"><a href="#Attack-Approaches" class="headerlink" title="Attack Approaches"></a>Attack Approaches</h2><ul><li>FGSM (<a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">https://arxiv.org/abs/1412.6572</a>)</li><li>Basic iterative method (<a href="https://arxiv.org/abs/1607.02533" target="_blank" rel="noopener">https://arxiv.org/abs/1607.02533</a>) </li><li>L-BFGS (<a href="https://arxiv.org/abs/1312.6199" target="_blank" rel="noopener">https://arxiv.org/abs/1312.6199</a>)</li><li>Deepfool (<a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">https://arxiv.org/abs/1511.04599</a>)</li><li>JSMA (<a href="https://arxiv.org/abs/1511.07528" target="_blank" rel="noopener">https://arxiv.org/abs/1511.07528</a>)</li><li>C&amp;W (<a href="https://arxiv.org/abs/1608.04644" target="_blank" rel="noopener">https://arxiv.org/abs/1608.04644</a>)</li><li>Elastic net attack (<a href="https://arxiv.org/abs/1709.04114" target="_blank" rel="noopener">https://arxiv.org/abs/1709.04114</a>)</li><li>Spatially Transformed (<a href="https://arxiv.org/abs/1801.02612" target="_blank" rel="noopener">https://arxiv.org/abs/1801.02612</a>) </li><li>One Pixel Attack (<a href="https://arxiv.org/abs/1710.08864" target="_blank" rel="noopener">https://arxiv.org/abs/1710.08864</a>)</li><li>……</li></ul><p>虽然有很多方法都可以进行attack，但它们的主要区别在于使用了不同的constraint或者使用了不同的optimization method。</p><h2 id="FGSM"><a href="#FGSM" class="headerlink" title="FGSM"></a>FGSM</h2><p>FGSM即Fast Gradient Sign Method，本次homework(hw6_AdversarialAttack)就使用了FGSM。</p><p>FGSM中输入的更新规则为$x^*=x^0-\epsilon\Delta x$。它首先计算出损失$L$关于$x$的每个维度的梯度，如果梯度大于0则修改为+1、小于0则修改为-1，也就是说$x^0$的所有维要么$+\epsilon$是要么是$-\epsilon$。</p><p>假设FGSM使用L-infinity计算$d(x^0,x^<em>)$，如果梯度指向左下角那么$x^</em>$就在方框的右上角；如果gradient指向左上角那么$x^<em>$就在方框的右下角；因此在FGSM中我们只在意梯度方向而不在意其大小。我们可以认为FGSM使用一个非常大的学习率使$x$飞出正方形，但因为要保证$d(x^0,x’)\leq\epsilon$所以$x^</em>$就会被限制到方形区域内部。所以就像是“一拳超人”，只攻击一次就达到好的效果。</p><p><img src="https://pic1.zhimg.com/80/v2-8c2bf52f38a95de4070288719e1eed4c_720w.png" alt="img"></p><h2 id="Black-Box-Attack"><a href="#Black-Box-Attack" class="headerlink" title="Black Box Attack"></a>Black Box Attack</h2><p>Attack可以分为White Box和Black Box。White Box Attack指<strong>模型参数$\theta$是已知的</strong>，Black Box Attack指<strong>模型参数$\theta$是未知的</strong>。</p><p>在Black Box Attack中，我们不知道Black Network的参数$\theta$。现假设我们知道Black Network的训练集，那我们就可以使用这份训练集自行训练出一个Proxy Network，然后基于Proxy Network和训练集就可以得到$x’$，这个$x’$一般也可以成功攻击Black Network。如果Black Network是一个在线API，我们既不知道Black Network的参数也不知道它的训练集，那上传大量输入后就可以得到大量对应的输出，并以这些输入输出对为训练集得到Proxy Network和$x’$。</p><p>有相关实验证明，Black Box Attack是非常有可能攻击成功的，详见：Delving into Transferable Adversarial Examples and Black-box Attacks(<a href="https://arxiv.org/abs/1611.02770" target="_blank" rel="noopener">https://arxiv.org/abs/1611.02770</a>)</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;我们希望我们的模型不仅仅是在大多数情况下可用的，还希望它能够应对来自外界的“
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.5基于PyTorch的Explainabe AI实战</title>
    <link href="https://chouxianyu.github.io/2021/04/25/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-5%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84Explainabe-AI%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/04/25/李宏毅机器学习课程笔记-11-5基于PyTorch的Explainabe-AI实战/</id>
    <published>2021-04-25T01:48:58.000Z</published>
    <updated>2021-04-25T01:56:27.641Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework5的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><h1 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h1><p>在homework3中我们通过CNN实现了食物图片分类，详见我之前的文章《李宏毅机器学习课程笔记-7.4基于CNN和PyTorch的食物图片分类》，这次作业的任务就是探究这个CNN的可解释性，具体如下</p><ol><li><p><strong>Saliency Map</strong></p><p> 按照《Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps》，计算每个像素对最终分类结果的重要性。</p><p> 我們把一张图片输入到model，将model的输出与label进行对比计算得到loss，因此与loss相关的变量有image、model parameter和label这3者。</p><p> 通常情況下，我們训练模型时希望找到一组好的model parameter来拟合image和label，因此loss在backward时我们只在乎loss关于model parameter的梯度。但在数学上image本身也是continuous tensor，我们可以<strong>在model parameter和label都固定的情况下计算loss关于image的梯度，这个梯度代表稍微改变image的某个pixel value会对loss产生什么影响，我们习惯把这个影响的程度解读为该pixel对于结果的重要性（每个pixel都有自己的梯度）</strong>。</p><p> 因此将loss关于一张图片中每个pixel的梯度计算并画出来，就可以看出该图中哪些像素是model在计算结果时的重要依据。那如何用代码实现我们的这个想法呢？非常简单，在一般训练中我们都是在forward后计算模型输出与标签之间的loss，然后进行loss的backward，其实在PyTorch中这个backword计算的是loss对<strong>model parameter</strong>的梯度，因此我們只需要用一行代码<code>images.requires_grad_()</code>使得<strong>image</strong>也要被计算梯度。</p></li><li><p><strong>Filter Visualization</strong></p><p> 基于Gradient Ascent，实现Activation maximization，找到最能够激活某个filter的图片，以观察模型学到了什么。</p><p> 这里我们想要知道某一个filter到底学习到了什么，我们需要做两件事情：<strong>①Filter Visualization：挑几张图片看看某个filter的输出；②Filter Activation：看看什么图片可以最大程度地activate该filter</strong>。</p><p> 在代码实现方面，我们一般是直接把图片输入到model，然后直接forward，那要如何取出model中某层的输出呢？虽然我们可以直接修改model的forward函数使其返回某层的输出，但这样比较麻烦，还可能会因此改动其它部分的代码。因此PyTorch提供了方便的解决方法：<strong>hook</strong>。</p></li><li><p><strong>LIME</strong></p><p> 绿色代表一个component和结果正相关，红色则代表该component和结果负相关。</p><p> 《”Why Should I Trust You?”: Explaining the predictions of Any Classifier》</p><p> 注：根据助教的示例，我遇到了一个BUG<code>KeyError: &#39;Label not in explanation&#39;</code>，暂未解决……</p></li></ol><h1 id="数据集描述"><a href="#数据集描述" class="headerlink" title="数据集描述"></a>数据集描述</h1><p>使用homework3使用的数据集以及训练出的CNN模型。</p><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><p><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations" target="_blank" rel="noopener">https://github.com/utkuozbulak/pytorch-cnn-visualizations</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework5的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.4模型无关的局部解释(LIME)</title>
    <link href="https://chouxianyu.github.io/2021/04/24/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-4%E6%A8%A1%E5%9E%8B%E6%97%A0%E5%85%B3%E7%9A%84%E5%B1%80%E9%83%A8%E8%A7%A3%E9%87%8A-LIME/"/>
    <id>https://chouxianyu.github.io/2021/04/24/李宏毅机器学习课程笔记-11-4模型无关的局部解释-LIME/</id>
    <published>2021-04-24T02:36:52.000Z</published>
    <updated>2021-04-24T02:37:44.740Z</updated>
    
    <content type="html"><![CDATA[<p>模型无关的局部解释（Local Interpretable Model-Agnostic Explanations，LIME）指<strong>使用一个Interpretable Model拟合一个Uninterpretable Model的局部</strong>，比如使用Linear Model或者Decision Tree模拟Neural Network。</p><p>具体来讲，对于局部范围内的相同输入，我们希望两个模型的输出尽可能接近。这里要重点强调局部范围的概念，因为实际上Linear Model并不能模拟整个Neural Network但却可以模拟其中的一个Local Region，这也是LIME可行的原因。</p><h2 id="案例：使用Linear-Model拟合Neural-Network"><a href="#案例：使用Linear-Model拟合Neural-Network" class="headerlink" title="案例：使用Linear Model拟合Neural Network"></a>案例：使用Linear Model拟合Neural Network</h2><ol><li><p>定位：确定需要解释的data point(下图5个蓝点中最中间的蓝点)</p></li><li><p>取样：在上一步确定的data point周围sample获得更多的data point(下图5个蓝点)</p><p> sample的<strong>范围</strong>需要根据情况调整，一般范围小则拟合得更准确</p><p> sample的<strong>方法</strong>不同，结果也会不同</p></li><li><p>拟合：使用Linear Model模拟上一步确定的data point及其对应的Neural Network输出</p></li><li><p>解释：对Linear Model进行解释，进而解释Neural Network的局部</p></li></ol><p><img src="https://pic1.zhimg.com/80/v2-a29bafdc2312575cab096090938493b2_720w.png" alt="img"></p><h2 id="案例：LIME-For-Image-Classification"><a href="#案例：LIME-For-Image-Classification" class="headerlink" title="案例：LIME For Image Classification"></a>案例：LIME For Image Classification</h2><p>如何将LIME应用到Image Classification呢？假设有一张图片被分类为frog，下面只讲一些关键点。</p><ul><li><p>如何进行sample？</p><p>  首先可以将图片分成多个segment：$\{s_1,s_2,\dots,s_n\}$，随机去除其中的一些segment就可以得到该图片“周围”的一些图片</p></li><li><p>将LIME应用于图片时，一般要进行Feature Extraction，那如何做呢？</p><p>  使用$x_i$表示图片中的每个segment是否被删除，其中$i=1,…,n$，若$x_i$为1则表示该segment被删除，否则表示该segment未被删除</p></li><li><p>如何解释Linear Model？</p><p>  设Linear Model为$y=w_1x_1+..+w_nx_n$，$w_i$的值有以下3种情况</p><ul><li>$w_i\approx 0$表示$s_i$对分类为frog没有影响；</li><li>$w_i&gt; 0$表示$s_i$对分类为frog具有正面影响，即这个segment使得模型倾向于将图片分类为frog</li><li>$w_i&lt;0$表示$s_i$对分类为frog具有负面影响，即这个segment使得模型倾向于认为该图片不是frog类别</li></ul></li></ul><h2 id="Tree-Regularization"><a href="#Tree-Regularization" class="headerlink" title="Tree Regularization"></a>Tree Regularization</h2><p><strong>理论上可以用无深度限制的Decision Tree拟合完整的Neural Network，但Decision Tree的深度不可能没有限制</strong>，因此在使用Decision Tree拟合Neural Network时需要对Decision Tree的复杂度进行约束。</p><p>设Neural Network的参数为$\theta$、Decision Tree的参数为$T_\theta$，使用Decision Tree的平均深度表示其参数$T_\theta$的复杂度$O(T_\theta)$。在使用Decision Tree拟合Neural Network时，不仅要使两者输出相近还要使$O(T_\theta)$最小化，因此优化目标为$\theta^*=arg\ {\rm min}\ L(\theta) + \lambda O(T_\theta)$。</p><p>因此我们<strong>在训练神经网络时就可以使用Tree Regularization使得训练出的神经网络更具有可解释性</strong>，$O(T_\theta)$不能微分，解决方法详见《Beyond Sparsity: Tree Regularization of Deep Models for Interpretability》。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;模型无关的局部解释（Local Interpretable Model-Agnostic Explanations，LIME）指&lt;strong&gt;使用一个Interpretable Model拟合一个Uninterpretable Model的局部&lt;/strong&gt;，比如使用
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
      <category term="LIME" scheme="https://chouxianyu.github.io/tags/LIME/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.3Explainable AI(Global Explanation)</title>
    <link href="https://chouxianyu.github.io/2021/04/23/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-3Explainable-AI-Global-Explanation/"/>
    <id>https://chouxianyu.github.io/2021/04/23/李宏毅机器学习课程笔记-11-3Explainable-AI-Global-Explanation/</id>
    <published>2021-04-23T03:33:37.000Z</published>
    <updated>2021-04-23T03:34:13.996Z</updated>
    
    <content type="html"><![CDATA[<p>假定在图片分类任务中，<strong>Global Explanation要求机器说明它认为一个类别(比如“cat”)是什么样子，而非针对一张图片进行解释。</strong></p><h2 id="Activation-maximization"><a href="#Activation-maximization" class="headerlink" title="Activation maximization"></a>Activation maximization</h2><p>在<a href="https://zhuanlan.zhihu.com/p/361283328" target="_blank" rel="noopener">李宏毅机器学习课程笔记-7.2CNN学到了什么</a>一文中，我们已讲过Activation maximization，不再复述，这里讲一些相关的新知识。</p><ol><li>在Activation maximization的MNIST手写数字识别案例中，我们观察到机器学习到的数字在人类看来完全就是噪音，由此可以想到：将机器认为是数字(或其它事物)的内容作为噪声添加到其它数据中，也许这样就可以实现Attack。</li><li>在使用Activation maximization观察模型学习到的内容时，我们可能需要使用大量<strong>Regularization(保证“可解释性”)</strong>以及暴调超参数，详见《Understanding Neural Networks Through Deep Visualization》。</li></ol><h2 id="“Regularization”-From-Generator"><a href="#“Regularization”-From-Generator" class="headerlink" title="“Regularization” From Generator"></a>“Regularization” From Generator</h2><p><strong>除了使用人工设置的Regularization来告诉机器什么是一张正常的输出(比如image)，还可以使用Generator进行Regularization</strong>。</p><p>Image Generator的输入是一个低维向量$z$，其输出为一张图片$x$，即$x=G(z)$。通常这个低维向量$z$是从某个已知的distribution(比如高斯分布、正态分布)中sample出来的，我们可以收集很多图片并使用GAN或者VAE训练这个Generator。</p><p>那如何使用Image Generator生成对图片的限制呢？以图片分类为例，将Generator输出的图片$x$输入到Image Classifier中得到输出分类结果$y_i$，目标是找到一个$z^<em>$使得图片$x$属于对应类别$i$的可能性$y_i$最大，即$z^</em>=arg \ max y_i$。得到$z^<em>$之后将其输入至Image Generator就可以得到一个图片$x$。如果通过$x^</em>=arg \ max y_i$直接得到图片呢，则不能保证结果的“可解释性”，因而需要对结果进行“可解释性”的约束，上述过程中Generator的作用就是对图片进行约束以确保生成的图片$x$是“可解释”的。</p><p>注：在进行$z^*=arg \ max y_i$时，Image Generator和Classifier的参数是不参与本次训练的。</p><p>那使用Generator能得到什么样的结果呢？结果挺好的，详见《Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space》。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假定在图片分类任务中，&lt;strong&gt;Global Explanation要求机器说明它认为一个类别(比如“cat”)是什么样子，而非针对一张图片进行解释。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;Activation-maximization&quot;&gt;&lt;a href=&quot;#Ac
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.2Explainable AI(Local Explanation)</title>
    <link href="https://chouxianyu.github.io/2021/04/22/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-2Explainable-AI-Local-Explanation/"/>
    <id>https://chouxianyu.github.io/2021/04/22/李宏毅机器学习课程笔记-11-2Explainable-AI-Local-Explanation/</id>
    <published>2021-04-22T00:40:25.000Z</published>
    <updated>2021-04-22T00:41:07.591Z</updated>
    
    <content type="html"><![CDATA[<p>假定在图片分类任务中有一张图片，<strong>Local Explanation</strong>则要求机器说明为什么它认为这张图片是某个类别(比如“cat”)。</p><p>Explainable AI(<strong>Local Explanation</strong>)的目标是，知道每个component对于最终结果的重要性。我们可以通过remove或者modify其中一个component，看decision会有什么变化。</p><h2 id="基于梯度判断Component重要性"><a href="#基于梯度判断Component重要性" class="headerlink" title="基于梯度判断Component重要性"></a>基于梯度判断Component重要性</h2><p>假设输入是$x$，它有很多component $\{x_1,x_2,\dots,x_N\}$组成。如果输入是image，则component一般是pixel、segment或patch等；如果输入是text，则component一般是word。对于图片，我们可以在图片上“放置”一个灰块以覆盖图像的一小部分，观察其对结果的影响，见《<strong>Visualizing <em>and</em> Understanding Convolutional Networks</strong>》。注：component的选取、remove或者modify也是需要研究的。</p><p>还有另一种方法是，输入为$\{x_1,…,x_n\}$，对某个pixel $x_n$加上$\Delta x$，用$\frac{\Delta y}{\Delta x}$来表示扰动$\Delta x$对结果$y$的影响，即通过$\frac{\partial y_k}{\partial x_n}$的绝对值表示某个pixel对$y_k$的影响，见《<strong>Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</strong>》。</p><p>还有很多其它<strong>基于梯度来判断Component重要性</strong>的方法：</p><ul><li><p>Grad-CAM</p></li><li><p>SmoothGrad</p></li><li><p>Layer-wise Relevance Propagation(LRP)</p><p>  Redistribute the output, Backward propagation until reaching input</p></li><li><p>Guided Backpropagation</p></li></ul><h2 id="梯度饱和"><a href="#梯度饱和" class="headerlink" title="梯度饱和"></a>梯度饱和</h2><p>基于梯度来判断component重要性的方法也存在着局限性：<strong>梯度饱和(Gradient Saturation)和Noisy Gradient</strong>。</p><p>考虑$\frac{\partial大象}{\partial鼻子长度}$，可知在一定范围内，鼻子越长，则判定为大象的概率就越大，但随着鼻子长度增加到一定数值后，鼻子长度对于判定大象的影响几乎为0，这时就出现了梯度饱和，如下图所示。</p><p><img src="https://pic4.zhimg.com/80/v2-ccef0f3a481afd976ed03ce3e6a12484_720w.png" alt="img"></p><p>那如何解决梯度饱和的问题呢？解决方法就是<strong>Global Explanation</strong>，可以参考Integrated gradient和DeepLIFT。</p><p>相对于梯度饱和，另外一个问题就是<strong>Noisy Gradient</strong>，即Gradient变化非常大，解决方法是<strong>SmoothGrad</strong>（在计算梯度时添加噪声以扰动生成多个样本，并计算平均梯度）</p><h2 id="Attack-Interpretation"><a href="#Attack-Interpretation" class="headerlink" title="Attack Interpretation"></a>Attack Interpretation</h2><p>向输入中加入一些细微的噪声，这样并不影响视觉效果和模型的输出，但这样可以<strong>攻击explanation</strong>，如下图所示，详见《Interpretation of Neural Networks is Fragile》。</p><p><img src="https://pic2.zhimg.com/80/v2-704a838681754edb670b33ef0c228987_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假定在图片分类任务中有一张图片，&lt;strong&gt;Local Explanation&lt;/strong&gt;则要求机器说明为什么它认为这张图片是某个类别(比如“cat”)。&lt;/p&gt;
&lt;p&gt;Explainable AI(&lt;strong&gt;Local Explanation&lt;/stron
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.1Explainable AI引言</title>
    <link href="https://chouxianyu.github.io/2021/04/21/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-1Explainable-AI%E5%BC%95%E8%A8%80/"/>
    <id>https://chouxianyu.github.io/2021/04/21/李宏毅机器学习课程笔记-11-1Explainable-AI引言/</id>
    <published>2021-04-21T01:48:40.000Z</published>
    <updated>2021-04-21T01:58:47.017Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Explainable-AI是什么"><a href="#Explainable-AI是什么" class="headerlink" title="Explainable AI是什么"></a>Explainable AI是什么</h2><p>我们希望，机器不仅要知道“是什么”还要知道“为什么”，或者说<strong>机器不仅要给出答案还要给出explanation</strong>。</p><p>Explanation可以分为两类：</p><ol><li><p><strong>Local Explanation</strong></p><p> 假定在图片分类任务中有一张图片，要求机器说明<strong>为什么它认为这张图片是某个类别(比如“cat”)</strong>。</p></li><li><p><strong>Global Explanation</strong></p><p> 假定在图片分类任务中，要求机器说明<strong>它认为一个类别(比如“cat”)是什么样子</strong>，而非针对一张图片进行解释。</p></li></ol><h2 id="Explainable-AI有什么用"><a href="#Explainable-AI有什么用" class="headerlink" title="Explainable AI有什么用"></a>Explainable AI有什么用</h2><p>在使用机器挑选简历时，我们需要知道机器为什么选择某份简历(性别?还是实力)。</p><p>在使用机器判定罪犯是否可以假释时，我们需要知道机器为什么判定是或否(实证?还是肤色)。</p><p>在使用机器判定是否给某人贷款时，我们需要知道机器为什么判定是或否。</p><p>通过Explainable AI，我们可以知道模型学到了什么从而进行模型诊断，对模型进行改进和调整。我们不仅只关注模型在数据集上的精确度，还需要进行模型诊断，因为有可能精确度很高但实际上机器什么都没学到。</p><h2 id="Explainable-AI是否有必要"><a href="#Explainable-AI是否有必要" class="headerlink" title="Explainable AI是否有必要"></a>Explainable AI是否有必要</h2><p>李宏毅老师认为Explainable AI的目标并非完全理解模型是如何work的，而是为了让人感到comfortable。</p><p>因为深度学习是一个黑盒所以有些人认为深度学习不可信，这有些因噎废食。人脑等很多事物对现在的人类来讲都也还是黑盒，完全理解模型的work机理不是必要的，因为某些东西是黑盒就不使用它也不行。</p><p>Explainable AI其实就是为了使老板、客户、自己等感到comfortable，甚至对不同人也应该有不同的解释。</p><h2 id="Interpretable-VS-Powerful"><a href="#Interpretable-VS-Powerful" class="headerlink" title="Interpretable VS Powerful"></a>Interpretable VS Powerful</h2><p>决策树既是interpretable又是powerful的，但当分支特别多的时候决策树的表现也会很差，这时可以使用Random Forest或者XGBoost，但它们虽然powerful但不interpretable。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Explainable-AI是什么&quot;&gt;&lt;a href=&quot;#Explainable-AI是什么&quot; class=&quot;headerlink&quot; title=&quot;Explainable AI是什么&quot;&gt;&lt;/a&gt;Explainable AI是什么&lt;/h2&gt;&lt;p&gt;我们希望，机器不仅要
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.4基于Smoothness假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-4%E5%9F%BA%E4%BA%8ESmoothness%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/19/李宏毅机器学习课程笔记-10-4基于Smoothness假设的半监督学习/</id>
    <published>2021-04-19T00:27:39.000Z</published>
    <updated>2021-04-19T00:29:53.557Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Smoothness假设"><a href="#Smoothness假设" class="headerlink" title="Smoothness假设"></a>Smoothness假设</h2><h3 id="Smoothness假设的定义"><a href="#Smoothness假设的定义" class="headerlink" title="Smoothness假设的定义"></a>Smoothness假设的定义</h3><p>基于Smoothness假设的半监督学习的基本思路是“近朱者赤近墨者黑”，即<strong>相似的$x$具有相同的$\hat y$</strong>，其具体<strong>定义</strong>为：</p><ol><li>$x$的<strong>分布不平均</strong>，在某些地方(high density region)很集中，在某些地方很分散</li><li>如果$x^1$和$x^2$在一个<strong>high density region</strong>中距离非常近，则$x^1$和$x^2$通过1个<strong>high density path</strong>相连、$\hat y^1=\hat y^2$。</li></ol><p>举一个例子，如下图所示，$x^1,x^2,x^3$是3个样本，如果单纯地看它们之间的相似度，显然$x^2$和$x^3$更接近一些。但对于smoothness assumption来说，$x^1$和$x^2$是位于同一个high density region中，它们之间有high density path；而$x^2$与$x^3$之间则是“断开”的，没有high density path，因此$x^1$与$x^2$更“像”。</p><p><img src="https://pic1.zhimg.com/80/v2-a45cf1b179557c638d294edf952053a2_720w.png" alt="img"></p><h3 id="手写数字识别举例"><a href="#手写数字识别举例" class="headerlink" title="手写数字识别举例"></a>手写数字识别举例</h3><p>再举一个手写数字识别和人脸识别的例子，如下图所示，最左侧的2、最右侧的2和最右侧的3，从<strong>pixel角度</strong>来看明显是最右侧的2和3更加相似(尽管两者并非是同一个数字)，但如果考虑最左侧的2朝着最右侧的2的演化过程，可以发现产生了一种“<strong>间接相似性</strong>”(high density path)。根据Smoothness假设，由于这6个2之间存在间接的相似而这6个2和最右侧的3之间不存在high density path，因此这6个2是彼此相似的；而最右侧的3和这6个2是不相似的。</p><p><img src="https://pic4.zhimg.com/80/v2-c8fd736cc00ef0209e973b93b62b2541_720w.png" alt="img"></p><h3 id="文章分类举例"><a href="#文章分类举例" class="headerlink" title="文章分类举例"></a>文章分类举例</h3><p>假设对天文学(astronomy)和旅行(travel)的文章进行分类，它们有各自的专属词汇，此时如果unlabeled data与label data的词汇是相同或重合(overlap)的，那么就很容易分类；但真实情况中unlabeled data和labeled data之间可能没有任何重复的word，因为世界上的词汇太多了，sparse的分布中overlap难以发生。</p><p>但如果unlabeled data足够多，就会以一种<strong>相似传递</strong>的形式，建立起文档之间相似的桥梁。</p><h2 id="cluster-and-then-label"><a href="#cluster-and-then-label" class="headerlink" title="cluster and then label"></a>cluster and then label</h2><p>如何实现基于Smoothness假设的半监督学习呢？在具体实现上，最简单的方式是cluster and then label。</p><p>cluster and then label就是先<strong>把所有样本(包括有标签样本和无标签样本)分成几个cluster，然后根据每个cluster中各类别有标签样本的数量确定该cluster中所有样本的label，然后进一步用这些cluster学习得到分类器</strong>。</p><p>这种方法不一定会得到好的结果，因为该方法有个<strong>前提是我们能够把同类别的样本分到同一个cluster</strong>，而这并不容易。对图像分类来说，如果仅仅依据pixel-wise相似度来划分cluster，得到的结果一般都会很差。所以为了满足这个前提，我们需要设计较好的方法来描述一张图片(比如使用Deep Autoencoder提取图片特征feature)，以保证cluster时能够将同类别的样本分到同一个cluster。</p><h2 id="Graph-based-Approach"><a href="#Graph-based-Approach" class="headerlink" title="Graph-based Approach"></a>Graph-based Approach</h2><h3 id="high-density-path"><a href="#high-density-path" class="headerlink" title="high density path"></a>high density path</h3><p>如何实现基于Smoothness假设的半监督学习呢？我们可以将每个样本视为图中的1个点，<strong>通过图来表示connected by a high density path</strong>。Graph-based方法的基本思路是图中的有标注样本会影响与它们邻近的无标注样本并在图中产生“<strong>间接相似性</strong>”，即使某些无标注样本没有直接与有标注样本相连也仍然可以被判定为相似。如果想要让这种方法生效，<strong>收集到的数据一定要足够多</strong>，否则可能导致无法形成path、失去了information的传递效果。</p><h3 id="如何建立一张图"><a href="#如何建立一张图" class="headerlink" title="如何建立一张图"></a>如何建立一张图</h3><p>有时候点之间的边是比较好建立的(比如网页超链接、论文引用)，有时候需要我们自行建立点之间的边。图的好坏对最终结果的影响是非常关键的，但如何建图是一件heuristic的事情，需要我们凭经验和直觉来做，<strong>建图步骤</strong>如下：</p><ol><li><p>定义两个样本$x^i,x^j$之间的相似度计算方法$s(x^i,x^j)$</p><p> 如果是基于pixel-wise的相似度，那结果可能比较差，建议使用更好的方法(比如使用Autoencoder提取图片特征，并基于提取到的特征计算相似度)。</p><p> 推荐使用的相似度计算方法为高斯径向基函数(Gaussian Radial Basis Function)：$s(x^i,x^j)=exp(-\gamma||x^i-x^j||^2)$，其中$x^i,x^j$均为vector。经验上来说exp(exponential)通常是可以帮助提升性能的，因为它使得仅当$x^i,x^j$非常接近时similarity才会大、只要距离稍微远一点similarity就会迅速变小，也就是使用exponential可以做到<strong>只有非常近的两个点才能相连、稍微远一点就无法相连</strong>的效果。</p></li><li><p>建立点和点之间的边</p><ul><li><p>k-Nearest Neighbor(K近邻算法)</p><p>  在特征空间中，如果一个样本附近的k个最近样本的大多数属于某一类别，则该样本也属于这个类别</p></li><li><p>e-Neighborhood</p></li></ul></li><li><p>设置点和点之间边的权重</p><p> 一条边的权重应该和该边两个顶点的相似度成比例</p></li></ol><h3 id="如何定量地评估一个图符合Smoothness假设的程度"><a href="#如何定量地评估一个图符合Smoothness假设的程度" class="headerlink" title="如何定量地评估一个图符合Smoothness假设的程度"></a>如何定量地评估一个图符合Smoothness假设的程度</h3><p>那如何定量地评估一个图符合Smoothness假设的程度呢？</p><p><img src="https://pic1.zhimg.com/80/v2-db490c6a659a6fb1765c956d9f584cac_720w.png" alt="img"></p><p>如上图所示，我们定义1个图的<strong>Smoothness</strong>为$S=\frac{1}{2}\sum_{i,j}w_{i,j}(y^i-y^j)^2$并希望它<strong>越小越好</strong>，其中$i,j$为所有样本点的索引、$x^i$表示样本的特征、$y^j$表示样本的标注(有可能是伪标签)、$w_{i,j}$是2个样本之间边的权重、$\frac{1}{2}$只是为了方便计算。</p><p>上式Smoothness定义还可以表示为$S=y^TLy$，其中$y$是1个(R+U)-dim的vector：$y=[\dots,y^i,\dots,y^j,\dots]^T$、$L$是1个(R+U)×(R+U)的矩阵(名字叫做Graph Laplacian)。</p><p>Graph Laplacian的定义为$L=D-W$，其中$W_{i,j}$为2个样本点之间边的权重，把$W$每行元素之和放在该行对应的对角线上其它元素值为0即可得到$D$，如上图所示。在图神经网络(Spectral-based Convolution)中，有关于Graph Laplacian的介绍。</p><h3 id="如何训练"><a href="#如何训练" class="headerlink" title="如何训练"></a>如何训练</h3><p>Smoothness定义$S=y^TLy$中$y$是模型的输出(预测得到的类别)，它是取决于模型参数的，因此训练时仅需在有标注数据的损失函数上加上Smoothness即可：$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda S$，其中$\lambda S$可以被视为正则项。</p><p>由上可知，<strong>训练目标</strong>为：</p><ol><li>有标注数据的交叉熵越小越好，即模型的输出与标注越接近越好</li><li>所有数据的Smoothness越小越好，即不管是有标注数据还是无标注数据，模型输出都要符合Smoothness Assumption的假设</li></ol><p>注：训练时可以不仅仅要求整个模型的输出层要smooth，还可以对模型中任意一个隐藏层加上smooth的限制。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Smoothness假设&quot;&gt;&lt;a href=&quot;#Smoothness假设&quot; class=&quot;headerlink&quot; title=&quot;Smoothness假设&quot;&gt;&lt;/a&gt;Smoothness假设&lt;/h2&gt;&lt;h3 id=&quot;Smoothness假设的定义&quot;&gt;&lt;a href=
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.3基于Low-density Separation假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/18/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-3%E5%9F%BA%E4%BA%8ELow-density-Separation%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/18/李宏毅机器学习课程笔记-10-3基于Low-density-Separation假设的半监督学习/</id>
    <published>2021-04-18T07:17:34.000Z</published>
    <updated>2021-04-18T07:18:14.773Z</updated>
    
    <content type="html"><![CDATA[<p>按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即<strong>假设不同类别数据之间应该有1个很明显的boundary</strong>。</p><h3 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h3><p>最简单的基于Low-density Separation假设的半监督学习是Self-training。</p><ol><li><p>使用有标签的数据训练1个模型$f^*$，模型类型和训练方式没有限制，神经网络、深或浅、其它机器学习方法等等都可以</p></li><li><p>使用模型$f^<em>$生成未标注数据的伪标签(Pseudo-label)，即$y^u=f^</em>(x^u)$</p></li><li><p>取出一部分未标注数据将它们添加到有标签数据中，然后回到步骤1</p><p> 如何选择未标注数据仍然是一个open question，可以自行设计策略，比如给每个样本一个置信度。</p></li></ol><p>Self-training和<strong>生成模型中的半监督学习</strong>(见上1篇文章)还挺像的，它们的区别在于：</p><ol><li>Self-training使用<strong>hard label</strong>，即假定某个无标签样本一定属于某个类别(“非黑即白”)</li><li>生成模型使用<strong>soft label</strong>，即假定某个无标签样本有一定概率属于某类别(也可以理解为一个样本可以按照后验概率划分成多个部分，不同部分属于不同类别)</li></ol><p>Self-training使用了hard label，它并不适用于regression。</p><p>生成模型使用了soft label，它生成的伪标签在分类任务中是没有用的。因为把某个无标签样本(通过soft label生成伪标签)丢进模型重新训练模型，模型参数根本不会发生变化。</p><p>实际上，low-density separation就是<strong>通过hard label来提升分类效果</strong>的方法。</p><h3 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h3><p>该方法是Self-training的进阶版。</p><p>Self-training中使用的hard label还是有些武断和激进，Entropy-based Regularization对此进行了改进。</p><p><strong>在使用神经网络进行分类时，$y^u=f^<em>_{\theta^</em>}(x^u)$，其中$y_u$是1个one-hot编码。现在我们并不限制其必须是某个类别，而是将其看做1个分布，我们希望这个分布越集中越好(“非黑即白”)，因为分布越集中时它的含义就是样本$x^u$属于某类别的概率很大属于其它类别的概率很小</strong>。</p><p>我们可以使用Entropy评估分布$y^u$的集中程度$E(y^u)=-\sum_{m=1}^5y_m^uln(y_m^u)$，假设是5分类，其值越小则表示分布$y^u$越集中。</p><p>无监督分类的目标为有标签数据分类正确、无标签数据分类结果集中，所以损失函数则为$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda\sum_{x^u}E(y^u)$，其中第1项为有标签数据的交叉熵损失、第2项为无标签数据的entropy、$\lambda$表示无标签数据的损失权重，因为式中第2项的作用类似于regularization，所以该方法被称为Entropy-based Regularization。</p><h3 id="Semi-supervised-SVM"><a href="#Semi-supervised-SVM" class="headerlink" title="Semi-supervised SVM"></a>Semi-supervised SVM</h3><p>SVM为两个类别的数据找到一个boundary，该boundary与两个类别的margin最大、分类错误最小。</p><p>Semi-supervised SVM穷举所有无标签数据的类别并进行计算，最终选择与两个类别的margin最大、分类错误最小的boundary。</p><p>在数据量大的时候，Semi-supervised SVM难以穷举出所有情况，但还有一种求近似解的方法，其大致思路是初始化一些label，然后每次尝试改动1个样本的label并判断是否更优，如果更优则改变该样本的label，具体见Transductive Inference for Text Classification using Support Vector Machines。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即&lt;strong&gt;假设不同类别数据之间应该有1个很明显的boundary&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;Self-training&quot;&gt;&lt;a href=&quot;#Self-training&quot;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.2生成模型中的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/17/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-2%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/17/李宏毅机器学习课程笔记-10-2生成模型中的半监督学习/</id>
    <published>2021-04-17T02:46:22.000Z</published>
    <updated>2021-04-17T02:49:17.526Z</updated>
    
    <content type="html"><![CDATA[<p>生成模型中的半监督学习：Semi-supervised Learning for Generative Model</p><h2 id="有监督生成模型"><a href="#有监督生成模型" class="headerlink" title="有监督生成模型"></a>有监督生成模型</h2><p>有监督生成模型：Supervised Generative Model</p><p>如下图所示，在有监督生成模型中，得到$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$后，就可以计算出$x$属于类别$C_i$的概率$P(C_i|x)$。</p><p><img src="https://pic4.zhimg.com/80/v2-ee9b2801a6e660c4526a62103c10d2e0_720w.png" alt="img"></p><h2 id="半监督生成模型"><a href="#半监督生成模型" class="headerlink" title="半监督生成模型"></a>半监督生成模型</h2><p>半监督生成模型：Semi-supervised Generative Model</p><p>基于有监督生成模型，当有了无标签数据之后(下图中绿色圆点)，我们会明显发现有监督生成模型中的$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$并不够正确，比如2个类别的分布应该接近于下图中虚线圆圈、先验概率$P(C_1)$应该小于$P(C_2)$，所以应该使用无标签数据重新估计$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$。</p><p><img src="https://pic4.zhimg.com/80/v2-a334756241f389f2ca620c5f35ab5269_720w.png" alt="img"></p><h3 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h3><p>具体来讲，按照以下步骤进行计算：</p><ol><li><p>初始化参数：$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><p> 可以随机初始化，也可以用有标签数据估算</p></li><li><p>通过$\theta$计算每个样本$x^u$属于类别$C_i$的概率$P_\theta(C_i|x^u)$</p></li><li><p><strong>更新参数$\theta$</strong>（其实重点就是如何同时利用有标签数据和无标签数据实现半监督）</p><ul><li>$P(C_1)=\frac{N_1+\sum_{x^u}P(C_1|x^u)}{N}$，其中$N$是所有样本的数量、$N_1$是属于类别$C_1$的样本的数量。</li><li>$\mu^1=\frac{1}{N_1}\sum_{x^r\in C_1}x^r+\frac{1}{\sum_{x^u}P(C_1|x^u)}\sum_{x^u}P(C_1|x^u)x^u$，其中$x^r,x^u$分别指有标签的样本和无标签的样本</li></ul><p>同理可知其它参数的计算和更新方法</p></li><li><p>返回第2步</p></li></ol><p>理论上，上述步骤是可以收敛的，但参数$\theta$的初始化值会影响结果。其实上面的第2步是EM算法中的E，第3步是EM算法中的M。</p><h3 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h3><p>$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><ul><li><p>Maximum likelihood with labelled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)$最大(有一个Closed-form solution)，其中每个有标注样本$x^r$的$P_\theta(x^r,\hat y^r)=P_\theta(x^r|\hat y^r)P(\hat y^r)$。</p></li><li><p>Maximum likelihood with labelled &amp; unlabeled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)+\sum_{x^u}logP_\theta(x^u)$最大(该式并不是凹函数，所以需要迭代求解)，其中每个无标注样本$x^u$的$P_\theta(x^u)=P_\theta(x^u|C_1)P(C_1)+P_\theta(x^u|C_2)P(C_2)$</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生成模型中的半监督学习：Semi-supervised Learning for Generative Model&lt;/p&gt;
&lt;h2 id=&quot;有监督生成模型&quot;&gt;&lt;a href=&quot;#有监督生成模型&quot; class=&quot;headerlink&quot; title=&quot;有监督生成模型&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概率生成模型" scheme="https://chouxianyu.github.io/tags/%E6%A6%82%E7%8E%87%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.1半监督学习简介</title>
    <link href="https://chouxianyu.github.io/2021/04/16/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-1%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>https://chouxianyu.github.io/2021/04/16/李宏毅机器学习课程笔记-10-1半监督学习简介/</id>
    <published>2021-04-16T00:22:16.000Z</published>
    <updated>2021-04-16T00:50:25.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有监督学习-Supervised-Learning"><a href="#有监督学习-Supervised-Learning" class="headerlink" title="有监督学习(Supervised Learning)"></a>有监督学习(Supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R$，其中每组数据包括算法的输入与输出(标签)。</p><h2 id="半监督学习-Semi-supervised-Learning"><a href="#半监督学习-Semi-supervised-Learning" class="headerlink" title="半监督学习(Semi-supervised Learning)"></a>半监督学习(Semi-supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R+\{ x^u\}_{u=R+1}^{U+R}$，即其中部分数据有标签而大量数据没有标签($U&gt;&gt;R$)。</p><p>半监督学习可以分为以下2种情况</p><ol><li><p><strong>Transductive Learning</strong></p><p> unlabeled data is the testing data，只使用testing data中的feature，并没有使用testing data中的label，所以并没有cheating。</p><p> 适用于已知testing data的情况，比如kaggle比赛。</p></li><li><p><strong>Inductive Learning</strong></p><p> unlabeled data is not the testing data，完全不使用testing data。</p><p> 适用于testing data未知的情况，这是大多数情况。</p></li></ol><h2 id="为什么需要半监督学习"><a href="#为什么需要半监督学习" class="headerlink" title="为什么需要半监督学习"></a>为什么需要半监督学习</h2><p>其实缺的并不是数据，缺少的是有标签的数据。利用这些大量的没有标签的数据进行学习，这是非常有价值的。</p><h2 id="为什么半监督学习有用"><a href="#为什么半监督学习有用" class="headerlink" title="为什么半监督学习有用"></a>为什么半监督学习有用</h2><p>The <strong>distribution</strong> of the unlabeled data tell us something：无标注数据的分布可以告诉我们一些东西</p><p><img src="https://pic3.zhimg.com/80/v2-676d19916cb98d7f251ff22a08eec087_720w.png" alt="img"></p><p><strong>半监督学习往往伴随着假设，而该假设的合理与否决定了结果的好坏程度。</strong>如上图所示，在猫狗图片分类中一只狗被认为是一只猫，这很可能是由于这2张图片的背景都是绿色，因此假设的合理性至关重要。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;有监督学习-Supervised-Learning&quot;&gt;&lt;a href=&quot;#有监督学习-Supervised-Learning&quot; class=&quot;headerlink&quot; title=&quot;有监督学习(Supervised Learning)&quot;&gt;&lt;/a&gt;有监督学习(Supe
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
