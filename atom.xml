<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>臭咸鱼的缺氧瓶</title>
  
  <subtitle>快给我氧气！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://chouxianyu.github.io/"/>
  <updated>2021-03-19T12:25:47.568Z</updated>
  <id>https://chouxianyu.github.io/</id>
  
  <author>
    <name>臭咸鱼</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PoolNet论文详解</title>
    <link href="https://chouxianyu.github.io/2021/03/19/PoolNet%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    <id>https://chouxianyu.github.io/2021/03/19/PoolNet论文详解/</id>
    <published>2021-03-19T12:20:04.000Z</published>
    <updated>2021-03-19T12:25:47.568Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><ul><li><p>论文名称</p><p>  A Simple Pooling-Based Design for Real-Time Salient Object Detection</p></li><li><p>作者</p><p>  Jiang-Jiang Liu, Qibin Hou, <strong>Ming-Ming Cheng</strong>等</p></li><li><p>发表时间</p><p>  2020年</p></li><li><p>来源</p><p>  CVPR2019</p></li></ul><h1 id="主要收获"><a href="#主要收获" class="headerlink" title="主要收获"></a>主要收获</h1><ul><li>知识<ul><li>low-level和high-level可以指人类意识中的低级和高级，也可以指CNN物理结构中的浅层（低层）和深层（高层）。</li><li><strong>因为</strong>CNN类似于金字塔的结构特点；其浅层阶段具有较大尺寸并保留丰富的低级信息；其深层阶段包含更多高级语义信息也<strong>更容易从中得到显著目标的位置</strong>，但很coarse（粗糙）。</li></ul></li><li>一些未知的东西<ul><li>FPN</li><li>上采样</li><li>ResNet</li><li>PPM</li><li>Richer convolutional features for edge detection</li><li>SRM（A stagewise refinement model for detecting salient objects in images）</li><li>weight decay</li><li>balanced binary cross entropy loss</li><li>standard binary cross entropy loss，BCE？</li></ul></li></ul><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ol><li><p>思路</p><p> 通过扩展<strong>池化</strong>在CNN中的作用，实现SOD。</p></li><li><p>实现</p><p> 基于<strong>U-shape</strong> architecture，构造2个模块</p><ol><li><p>GGM（global guidance module）</p><p> 自底向上，用来<strong>为不同层的特征图提供</strong>潜在显著目标的位置信息。</p></li><li><p>FAM（feature aggregation module）</p><p> 从顶向下，使coarse-level的语义信息和fine-level的特征<strong>较好地融合</strong>。</p><p> 在自顶向下的融合操作之后添加FAM，可以将GGM中coarse-level的特征与不同尺度的特征无缝融合。</p><p>这2个模块使高级语义信息逐渐完善，生成信息丰富的显著性图。</p></li></ol></li><li><p>通过锐化细节，和SOTA相比可以更精确地定位目标。</p></li><li><p>300×400的图片，FPS超过30，代码<a href="http://mmcheng.net/poolnet/。" target="_blank" rel="noopener">http://mmcheng.net/poolnet/。</a></p></li></ol><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li><p>U-shape结构</p><ul><li>多数传统方法通过手工设计的特征，单独或同时捕捉局部细节和全局上下文信息，但其性能因缺乏高层语义信息而受到限制，而CNN可以在不同尺度空间中提取高级语义信息和低级细节特征。</li><li><strong>因为</strong>CNN类似于金字塔的结构特点，其浅层阶段具有较大尺寸并保留丰富的低级信息，其深层阶段包含更多高级语义信息也<strong>更容易从中得到显著目标的位置</strong>。</li><li><strong>基于上述知识</strong>，学者设计了许多结构，其中U-shape的结构最受关注，其通过在分类网络上构建自上而下的路径来构建丰富的特征图。</li></ul></li><li><p>U-shape结构还存在提升空间</p><ul><li><p>存在问题</p><ol><li>因为U-shape结构中高级语义信息（位于深层网络）是逐步传到浅层的，与此同时深层捕捉到的位置信息可能会被稀释。</li><li>一个CNN的感受野大小和其深度是不成比例的。</li></ol></li><li><p>解决方法</p><ul><li><p>现有方法</p><p>  现有方法（见原文参考文献）通过引入注意力机制、以循环方式细化特征图、结合多尺度特征信息、向显著图添加额外约束（例如边界loss）等方法解决上述U-shape结构的问题。</p></li><li><p>本文方法</p><p>  本文提出的方法是基于U-shape并扩展池化技术，其中GGM和FAM都是基于FPN（feature pyramid networks）的。</p></li></ul></li></ul></li><li><p><strong>PoolNet</strong></p><p>  因为GGM和FAM都基于池化，所以将本文方法取名为PoolNet。</p><ul><li><p>GGM</p><p>  GGM包括一个修改过的PPM（pyramid pooling module）和一系列GGF（global guiding flows）。</p><ul><li><p>PPM</p><p>  和SRM（A stagewise refinement model for detecting salient objects in images）直接将PPM插入U-shape结构不同，本文提出的GGM是一个独立的模块。具体来讲，即把PPM放在backbone顶部用来捕捉全局指导信息（显著目标的位置）</p></li><li><p>GGF</p><p>  通过GGF，PPM收集到的高级语义信息可以传送到所有金字塔层，弥补了U-shape网络自上而下信号逐渐被稀释的问题。</p></li></ul></li><li><p>FAM</p><p>  考虑到来自GGF的coarse-level特征图与金字塔不同尺度特征图的融合问题，本文提出了一种FAM，其输入为融合后的特征图。</p><p>  该模块首先将融合（==应该是FPN操作？==）得到的特征图转换到多个特征空间，以捕获不同尺度的局部上下文信息，然后将这些信息进行组合以更好地权衡融合的输入特征图的组成。（==最后半句没懂，“权衡”一词具体指什么？==）</p></li></ul></li><li><p>edge detection branch</p><p>  还使用了边缘检测分支（edge detection branch），通过和边缘检测协同训练以锐化显著物体的细节。</p></li><li><p>性能</p><ul><li><p>精度</p><p>  <strong>Without bells and whistles，大幅超过之前的SOTA。</strong></p></li><li><p>速度</p><ul><li>一个NVIDIA Titan Xp GPU，图片尺寸300 × 400，<strong>速度超过30FPS</strong>。</li><li>不使用边缘检测分支时，5000张图片，训练时长不超过6小时，比多数方法快很多，因为池化操作比较快速。</li></ul></li></ul></li></ul><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><p>暂略</p><h1 id="3-PoolNet"><a href="#3-PoolNet" class="headerlink" title="3. PoolNet"></a>3. PoolNet</h1><ul><li>high-level semantic features are helpful for discovering the specific locations of salient objects.</li><li>low- and midlevel features are also essential for improving the features extracted from deep layers from coarse level to fine level.</li></ul><h2 id="3-1-Overall-Pipeline"><a href="#3-1-Overall-Pipeline" class="headerlink" title="3.1. Overall Pipeline"></a>3.1. Overall Pipeline</h2><ul><li>基于FPN（一种U型结构，从底向上和自顶向下，优点是可以组合多层特征）<ul><li>在从底向上之后引入GGM，提取高级语义信息后将其与各个金字塔层融合。</li><li>GGM之后，引入FAM保证不同尺度的特征图可以无缝融合。</li></ul></li></ul><h2 id="3-2-Global-Guidance-Module"><a href="#3-2-Global-Guidance-Module" class="headerlink" title="3.2. Global Guidance Module"></a>3.2. Global Guidance Module</h2><ul><li><p>现有不足</p><ul><li><p>FPN的问题</p><p>  问题之一：自顶向下是在自底向上之后的，就是高级特征被传给低层时会逐渐稀释。</p></li><li><p>CNN的问题</p><p>  根据实验，CNN的感受野比理论上要小得多，<strong>特别是对于较深的层</strong>，所以整个网络的感受野并不足够大以捕捉输入的全局信息。</p></li><li><p>直接影响</p><p>  可以看原文图2，只能检测到显著目标的局部。</p></li></ul></li><li><p>解决方法：GGM</p><p>  使得每个尺度的特征图都可以感知显著目标的位置。</p><ul><li><p>PPM</p><p>  包括4个子分支，作用是<strong>捕获</strong>输入图像的上下文信息。</p><p>  第一和最后一个子分支分别是一个identity mapping layer和一个global average pooling layer。</p><p>  中间的两个分支，我们采用adaptive average pooling layer，以确保它们输出的特征图分别具有3×3和5×5的空间大小。</p></li><li><p>GGF</p><p>  作用是将PPM捕捉到的信息与接下来自顶向下中不同金字塔层的特征图合理地<strong>融合</strong>在一起。</p><p>  与SRM（A stagewise refinement model for detecting salient objects in images）不同，它是将PPM视为U形结构的一部分，而本文中的GGM独立于U形结构。</p><p>  如原文图1中的绿色箭头，通过引入一系列GGF（identity mappings），可以将高级语义信息传递到各个级别的特征。</p><p>  这样，我们在自上而下路径的每个部分中显式增加了全局导航信息的权重，以<strong>确保在构建FPN时不会稀释位置信息</strong>。</p><p>  可以看原文图2，观察GGF的具体作用。</p></li></ul></li></ul><h2 id="3-3-Feature-Aggregation-Module"><a href="#3-3-Feature-Aggregation-Module" class="headerlink" title="3.3. Feature Aggregation Module"></a>3.3. Feature Aggregation Module</h2><ul><li><p>解决的问题</p><p>  使GGM的粗略特征图与金字塔不同尺度的特征地图无缝融合。</p><p>  具体来讲，在原始的FPN（VGGNet版本）中，高层特征图上采样比率为2，所以在上采样后边加一个3×3的卷积可以减少其带来的aliasing effect。</p><p>  但是，<strong>GGF还需要更大的上采样比率</strong>，比如8。所以使用FAM充分、高效地处理GGF和不同金字塔层特征图之间巨大的尺寸差异。</p></li><li><p>FAM</p><ul><li><p>结构</p><p>  每个FAM包含4个子分支，如原文图3所示。在forward过程中，输入的特征图先以不同比率进行下采样（平均池化），然后再以不同比率进行上采样，然后将4个分支融合（sum），然后送入一个3×3的卷积层。</p></li><li><p>优点</p><ul><li>减少上采样带来的aliasing effect，特别是当上采样比率较大（比如8）的时候。</li><li>使每个spatial location（空间位置）可以看到不同尺度空间的局部上下文信息，而且增大了整个网络的感受野。</li></ul></li></ul></li><li><p>实验</p><ul><li><p>原文图4</p><p>  将FAM替换成2个卷积层进行对比，把FAM模块附近的特征图可视化，证明FAM可以更好地捕捉显著目标的位置和细节信息。</p></li><li><p>原文图2</p><p>  f列和g列（尤其是第2行）进行对比，证明引入FAM可以sharpen显著目标的细节信息。</p><p>在下文的实验部分，会给出更多的数值结果。</p></li></ul></li></ul><h1 id="4-Joint-Training-with-Edge-Detection"><a href="#4-Joint-Training-with-Edge-Detection" class="headerlink" title="4. Joint Training with Edge Detection"></a>4. Joint Training with Edge Detection</h1><ul><li><p>问题</p><p>  第3节描述的网络结构已经在多个常用评估准则上超过了之前所有SOTA的单个模型的结果。</p><p>  但是原文作者发现<strong>许多不准确（incomplete or over-predicted）的预测是由于不清晰的目标边界造成的</strong>。</p></li><li><p>Edge Detection Branch</p><p>  在第3节描述的结构中添加1个预测分支，<strong>用来estimate显著目标的边界</strong>，具体结构见原文图1。</p><p>  在3个不同尺度的FAM之后添加3个residual block，<strong>用来information transformation</strong>，这3个residual block和<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">ResNet</a>的设计相似并且具有<code>{128,256,512}</code>个通道（从fine level到coarse level）；和<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_Richer_Convolutional_Features_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Richer convolutional features for edge detection</a>一文相同，每个residual block后面都有1个16通道的3×3卷积层（<strong>用来feature compression</strong>），还有1个单通道的1×1卷积层（<strong>用来边缘检测</strong>）。</p><p>  将上述3个16通道的3×3特征图进行拼接（concatenate）然后将其送入3个连续的48通道3×3卷积层，以将捕捉到的边缘信息传递给显著性目标检测分支，<strong>用来增强细节</strong>。</p></li><li><p>Train Edge Detection Branch taking the boundaries of salient objects as GT</p><p>  和<a href="http://arxiv.org/abs/1704.03604" target="_blank" rel="noopener">Instancelevel salient object segmentation</a>一文相似，本文在训练阶段将显著目标的边界作为GT<strong>用来联合训练</strong>，然而这并没有带来任何性能提升并且仍然缺少目标边界的细节信息。如图5的c列，当场景的前后景对比度较低时，得到的显著性图和边界图仍然很模糊。<strong>导致这个问题的原因可能是来自显著目标的GT边界图仍然缺少显著目标的大部分细节信息</strong>。GT边界只告诉我们显著目标的外边界的位置，特别是当显著目标之间有重叠的时候。</p></li><li><p>Train Edge Detection Branch taking the boundaries of salient objects as GT</p><p>  根据上述内容，本文尝试了和边缘检测任务实现协同训练，使用和和<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_Richer_Convolutional_Features_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Richer convolutional features for edge detection</a>一文中相同的数据集。在训练时，来自显著目标检测数据集和边缘检测数据集的图像被交替输入。如图5所示，和边缘检测任务实现协同训练大幅提升了检测到的显著目标的细节。在下文实验部分，会给出更多的定量分析。</p></li></ul><h1 id="5-Experimental-Results"><a href="#5-Experimental-Results" class="headerlink" title="5. Experimental Results"></a>5. Experimental Results</h1><h2 id="5-1-Experiment-Steup"><a href="#5-1-Experiment-Steup" class="headerlink" title="5.1. Experiment Steup"></a>5.1. Experiment Steup</h2><ul><li><p>实现细节</p><p>  使用PyTorch框架，所有实验中的学习率优化器为Adam（5e-4的weight decay，初始学习率为5e-5然后15个epoch之后除以10）。</p><p>  本文的网络共训练24个epoch。</p><p>  网络backbone（如VGG-16、ResNet-50）的参数通过在ImageNet数据集上预训练的对应模型进行初始化，剩余参数随机初始化。</p><p>  如果没有特别声明，本文中消融实验（ablation experiments）默认使用VGG-16作为backbone，并使用和<a href="http://arxiv.org/abs/1704.03604" target="_blank" rel="noopener">Instancelevel salient object segmentation</a>一文相同的联合数据集（MSRA-B和HKU-IS）。</p><p>  本文在数据增强方面只使用了水平翻转。</p><p>  在训练和测试中，和<a href="http://arxiv.org/pdf/1611.04849v4.pdf" target="_blank" rel="noopener">Deeply supervised salient object detection with short connections</a>一文中一样，输入图片的尺寸保持不变。</p></li><li><p>数据集和损失函数</p><p>  在6个常用数据集（ECSSD、PASCALS、DUT-OMRON、HKU-IS、SOD和DUTS）上开展实验以评估性能。</p><p>  显著性目标检测中使用使用standard binary cross entropy loss，边缘检测使用balanced binary cross entropy loss。</p></li><li><p>评估标准</p><p>  使用3个广泛应用的指标（PR曲线、F-measure score和MAE）评估本文提出的方法。</p></li></ul><h2 id="5-2-Ablation-Studies"><a href="#5-2-Ablation-Studies" class="headerlink" title="5.2. Ablation Studies"></a>5.2. Ablation Studies</h2><p>ablation的译文是消融。</p><p>该section首先研究GGM和FAM的有效性，然后开展实验研究如何配置GGM，最后研究协同训练对性能的影响。</p><ul><li><p>Effectiveness of GGM and FAMs</p><p>  基于FPN的baseline，以VGG-16为backbone，研究GGM和FAMs的有效性。除了GGM和FAMs的不同组合，其它所有配置都相同。原文表1展示了其在数据集DUT-O和SOD上的性能，对应的视觉比较可以在原文图2中看到。</p><ul><li><p>GGM Only</p><p>  原文表1第4行数据说明GGM提升了F-measure和MAE。<strong>GGM生成的全局指导信息使网络更多地关注显著目标的完整性，大幅提升了所得显著性图的质量。因此，显著目标的细节（这些细节容易被感受野有限的模型错误预测为背景，比如原文图2的最后1行）可以被增强</strong>。</p></li><li><p>FAMs Only</p><p>  原文表1第5行的数据说明简单地将FAMs嵌入到原文图1所示的FPN baseline中提升了F-measure和MAE。这可能是因为<strong>FAM中的池化操作扩大了整个网络的感受野</strong>，并且FPN baseline仍然需要融合不同尺度的特征图，这说明<strong>FAM了缓解上采样aliasing effect的有效性</strong>。</p></li><li><p>GGM &amp; FAMs</p><p>  原文表1最后1行的数据说明同时引入GGM和FAMs可以得到更优的F-measure和MAE，<strong>这说明GGM和FAM是互补的。通过它们可以精确地定位显著目标并改善其细节（如图2所示）。原文图6中包含更多的定性结果。</strong></p></li></ul></li><li><p>Configuration of GGM</p><p>  为更好地了解GGM，独立使用PPM和GGF开展实验，数据分别在原文表1的第2行和第3行。这2个实验的结果都比使用GGM时的结果（原文表1第4行的数据）。<strong>这说明PPM和GGF在GGM中都起着重要作用。</strong></p></li><li><p>The Impact of Joint Training</p><p>  如原文表2所示，在3个数据集上，将显著目标边界（SalEdge）作为GT进行训练并没有提升baseline的性能，而使用标准的边缘（StdEdge）作为GT可以大幅提升baseline的性能，特别是MAE。这说明<strong>引入详细的边缘信息有助于显著性目标检测</strong>。</p></li></ul><h2 id="5-3-Comparisons-to-the-State-of-the-Arts"><a href="#5-3-Comparisons-to-the-State-of-the-Arts" class="headerlink" title="5.3. Comparisons to the State-of-the-Arts"></a>5.3. Comparisons to the State-of-the-Arts</h2><p>该section比较了本文方法和13个SOTA方法（具体是哪13个方法见原文，此处省略）。为公平比较，这13个方法的结果是原结果或者使用初始公开代码得到的结果。所有结果都不经过任何后处理，所有预测得到的显著性图都使用同一份代码进行评估。</p><ul><li><p>Quantitative Comparisons</p><p>  如原文表3所示，分别使用VGG-16和ResNet-50作为backbone，并在多份训练集上开展实验以<strong>排除潜在的性能波动</strong>。可以看到，在相同的训练集上，使用相同的backbone，PoolNet超过了之前所有的SOTA方法。平均速度（FPS）对比如原文表4所示。</p></li><li><p>PR Curves</p><p>  原文图7为在3个数据集上的PR曲线，可以看到PoolNet的PR曲线优于其它算法。随着Recall值趋于1，PoolNet的Precision比其它算法高很多。这说明PooNet得到的显著性图的错误正样本（false positives）较少。</p></li><li><p>Visual Comparisons</p><p>  原文图6给出了PoolNet和其它算法的定性对比。从上到下，分别是<strong>透明目标、小目标、大目标、复杂形状和前背景低对比度</strong>。可以看出，在几乎所有环境下，PoolNet不仅可以正确找出显著目标，还可以增强它们的边缘。</p></li></ul><h1 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h1><p> 本文设计GGM和FAM两个模块，提出PoolNet，并和边缘检测任务实现协同训练，在6个常用数据集上的效果优于之前所有SOTA方法。</p><p>GGM和FAM是独立于网络结构的，<strong>可以灵活地迁移到任何基于金字塔的模型</strong>。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;论文名称&lt;/p&gt;
&lt;p&gt;  A Simple Pooling-Based Design for Real-
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="显著性目标检测" scheme="https://chouxianyu.github.io/tags/%E6%98%BE%E8%91%97%E6%80%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="PoolNet" scheme="https://chouxianyu.github.io/tags/PoolNet/"/>
    
  </entry>
  
  <entry>
    <title>BASNet论文详解</title>
    <link href="https://chouxianyu.github.io/2021/03/08/BASNet%E8%AE%BA%E6%96%87%E8%AF%A6%E8%A7%A3/"/>
    <id>https://chouxianyu.github.io/2021/03/08/BASNet论文详解/</id>
    <published>2021-03-08T03:04:00.000Z</published>
    <updated>2021-03-08T03:35:13.463Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><ul><li><p>论文名称</p><p>  BASNet: Boundary-Aware Salient Object Detection</p></li><li><p>作者</p><p>  Xuebin Qin等</p></li><li><p>发表时间</p><p>  2019年</p></li><li><p>来源</p><p>  CVPR2019</p></li></ul><h1 id="主要收获"><a href="#主要收获" class="headerlink" title="主要收获"></a>主要收获</h1><ul><li><p>知识</p><ul><li><p>本文混合损失函数中的3种loss</p></li><li><p>本文核心是混合损失函数以及refine module，其中refine module借用了ResNet中的思路：$S_{refined}=S_{coarse}+S_{residual}$。</p></li><li><p>如图3所示，coarse saliency map存在2方面的问题：①the blurry and noisy boundaries(边界不准确、不清晰), ②the unevenly predicted regional probabilities(同类区域中像素概率不均匀)</p></li><li><p>RRM_LC和RRM_MS等模块比较shallow，所以很难捕捉到可用于refinement的high level information。</p></li><li><p>评估指标</p><ul><li><p>PR Curve</p><p>  PR Curve是1种评估预测所得显著性图的标准方式。1张显著性图的precision和recall通过比较二值化的显著性图及其ground truth计算。<strong>1个二值化threshold对应的1对precision和recall是数据集中所有显著性图的平均precision和recall</strong>。threshold从0到1变化，可以得到<strong>1个precision-recall pair序列</strong>，画出来就是PR Curve。</p></li><li><p>F-measure</p><p>  F-measure可以全面地衡量precision和recall，其<strong>基于1对precision和recall进行计算</strong>。在进行算法比较时，一般采用最大的F-measure进行比较。</p></li><li><p>MAE</p><p>  MAE指显著性图与其ground truth的average absolute per-pixel difference。<strong>模型对于1个数据集的MAE为所有显著性图的MAE的平均值</strong>。</p></li></ul></li></ul></li><li><p>一些未知的东西</p><ul><li>U-Net</li><li>SegNet</li><li>dilation convolution</li><li>感受野的计算方法</li></ul></li></ul><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul><li>背景：多数前人工作只关注region accuracy而非boundary quality。</li><li>本文提出：a predict-refine architecture: BASNet and a new hybrid loss for Boundary-Aware Salient object detection<ul><li>BASNet<ul><li>a densely supervised Encoder-Decoder network, in charge of saliency prediction</li><li>a residual refinement module(RRM), in charge of saliency map refinement</li></ul></li><li>The hybrid loss<ul><li>3级层次结构：pixel-level, patch-level, map-level</li><li>方式：混合3种loss，Binary Cross Entropy (BCE), Structural SIMilarity (SSIM) and Intersection-over-Union (IoU) losses</li></ul></li></ul></li><li><strong>效果</strong>：effectively segment the salient object regions and accurately predict <strong>the fine structures with clear boundaries</strong><ul><li>精度：在6个数据集上，ofregional and boundary evaluation measures超过SOTA。</li><li>速度：over 25 fps on a single GPU</li></ul></li><li>Code：<a href="https://github.com/NathanUA/BASNet" target="_blank" rel="noopener">https://github.com/NathanUA/BASNet</a></li></ul><h1 id="1-Inroducion"><a href="#1-Inroducion" class="headerlink" title="1. Inroducion"></a>1. Inroducion</h1><ul><li><p>背景</p><p>  近期FCN被用于显著性目标检测，性能优于传统算法，但their predicted saliency maps are still <strong>defective in fine structures and/or boundaries</strong>，如图1(c)和(d)所示。</p></li><li><p><strong>two main challenges</strong> in accurate salient object detection</p><ol><li>network：networks that <strong>aggregate multi-level deep features</strong> are needed</li><li>loss：models trained with CE loss usually have <strong>low confidence</strong> in differentiating boundary pixels, leading to <strong>blurry</strong> boundaries. Other losses such as Intersection over Union (IoU) loss, F-measure loss and Dice-score loss are not specifically designed for capturing <strong>fine structures</strong>。</li></ol></li><li><p>BASNet: the prediction module and RRM</p><p>  To capture both <strong>global (coarse)</strong> and <strong>local (fine)</strong> contexts，a new <strong>predict-refine</strong> network is proposed。</p><ul><li><p>the prediction module</p><p>  a <strong>U-Net-like</strong> densely supervised Encoder-Decoder network，transfers the input image to a probability map</p></li><li><p>RRM</p><p>  a novel residual refinement module，refines the predicted map by learning the residuals between the coarse saliency map and ground truth</p></li></ul></li><li><p>the hybrid loss</p><p>  To obtain <strong>high confidence</strong> saliency map and <strong>clear</strong> boundary, we propose a hybrid loss that combines Binary Cross Entropy (<strong>BCE</strong>), Structural SIMilarity (<strong>SSIM</strong>) and <strong>IoU</strong> losses, which are expected to learn from ground truth information in <strong>pixel-, patch- and map- level</strong>, respectively.</p><p>  <strong>Rather than using explicit boundary losses</strong> (NLDF+ , C2S ), we implicitly inject the goal of accurate boundary prediction in the hybrid loss, contemplating that it may help reduce spurious error from cross propagating the information learned on the boundary and the other regions on the image。</p><p>  毕竟任务不是边缘检测，所以不能只检测边缘。</p></li></ul><h1 id="2-Related-Works"><a href="#2-Related-Works" class="headerlink" title="2. Related Works"></a>2. Related Works</h1><ul><li><p>Traditional Methods</p><p>  早期方法根据1个<strong>预定义</strong>的基于<strong>手工特征</strong>计算的saliency measure<strong>搜索像素</strong>以检测显著目标。Borji等人提供了1个全面的综述。</p></li><li><p>Patch-wise Deep Methods</p><p>  受深度卷积神经网络推动图片分类发展的启发，早期的deep方法基于从单/多尺度提取的<strong>local image patches</strong>将image pixels和super pixels分类为显著/非显著。这些方法通常生成<strong>coarse outputs</strong>因为在全连接层中<strong>spatial information会丢失</strong>。</p></li><li><p>FCN-based Methods</p><p>  相比于Traditional Methods和Patch-wise Deep Methods，基于FCN的方法取得了重要进展，因为FCN is able to <strong>capture richer spatial and multiscale information</strong>。</p><p>  UCF、Amulet、NLDF+、DSS+、HED、RAS、LFR、BMPM。</p></li><li><p>Deep Recurrent and attention Methods</p><p>  PAGRN、RADF+、RFCNPiCANetR</p></li><li><p>Coarse to Fine Deep Methods</p><p>  为捕捉finer structures和more accurate boundaries，学者提出了大量refinement策略。</p><p>  SRM、R3Net+、DGRL</p></li></ul><h1 id="3-BASNet"><a href="#3-BASNet" class="headerlink" title="3. BASNet"></a>3. BASNet</h1><h2 id="3-1-Overview-of-Network-Architecture"><a href="#3-1-Overview-of-Network-Architecture" class="headerlink" title="3.1. Overview of Network Architecture"></a>3.1. Overview of Network Architecture</h2><p>BASNet包括2个Module：Predict Module和Refine Module，如图2所示。</p><ul><li><p>Predict Module</p><p>  a U-Net-like densely supervised Encoder-Decoder network，作用是predict saliency map from input images</p></li><li><p>Refine Module</p><p>  Residual Refinement Module，<strong>refines the resulting saliency map</strong> of the prediction module by learning the residuals between the saliency map and the ground truth。</p></li></ul><h2 id="3-2-Predict-Module"><a href="#3-2-Predict-Module" class="headerlink" title="3.2. Predict Module"></a>3.2. Predict Module</h2><ul><li><p>整体</p><ul><li>受U-Net和SegNet启发，predict module是1个<strong>Encoder-Decoder</strong>网络，这种结构可以同时捕捉<strong>high level global contexts and low level details</strong>。</li><li>受HED启发，为减少过拟合，通过ground truth对decoder每个stage的最后1层进行监督，如图2所示。</li></ul></li><li><p>encoder</p><p>  encoder部分包含<strong>1个输入卷积层</strong>和<strong>6个由basic res-blocks组成的stage</strong>，其中输入卷积层和前4个stage是修改过的<strong>ResNet34</strong>。</p><p>  改动为本文中的输入卷积层有64个步长为1的3×3卷积核而非步长为2的7×7卷积核，并且在输入卷积层之后没有pooling，这使得在前几层获得更大尺寸的特征图但也减小了整体的感受野。</p><p>  为获得和ResNet34相同的感受野，本文<strong>在ResNet34又加了2个stage</strong>，每个stage均由size为2的不重叠maxpooling层及3个512filter的basic res-block组成。</p></li><li><p>bridge</p><p>  为进一步捕捉global infomation，本文<strong>在encoder和decoder之间添加了1个bridge</strong>。</p><p>  该bridge包括3个512核的dilation为2的3×3卷积层，其中每个卷积层后都有1个BN层和ReLU。</p></li><li><p>decoder</p><p>  decoder几乎和encoder完全对称。decoder的每个stage包含3个卷积层，每个卷积层后有1个BN层和ReLU。</p><p>  <strong>每个stage的输入是</strong>其前1个stage的输出和其对应的encoder中的stage的输出的<strong>concatenate</strong>结果。</p><p>  为得到side-output saliency maps，bridge和decoder中每个stage的输出被进行处理，处理过程为：<strong>1个3×3卷积、上采样、sigmoid</strong>。因此输入1张图片，本文的predict module在训练过程中输出<strong>7个saliency maps</strong>，其中<strong>最后1个saliency map</strong>的accuracy最高，所以其作为predict module的最终输出传入refine module。</p></li></ul><h2 id="3-3-Refine-Module"><a href="#3-3-Refine-Module" class="headerlink" title="3.3. Refine Module"></a>3.3. Refine Module</h2><ul><li>Refinement Module通常被定义为1个<strong>residual block</strong>，其通过学习saliency map和ground truth之间的residual$S_{residual}$来refine预测得到的coarse saliency map$S_{coarse}$，公式为$S_{refined}=S_{coarse}+S_{residual}$。</li><li>如图3所示，<strong>coarse包含2方面的含义</strong>：①the blurry and noisy boundaries, ②the unevenly predicted regional probabilities，模型预测所得的coarse saliency map中这2方面的问题都会有。</li><li><strong>RRM_LC</strong>(residual refinement module based on local context)起初被提出是用于boundary refinement，因为其感受野较小，Islam和Deng等人iteratively或recurrently在不同尺度上使用它refine saliency maps。Wang等人使用了PPM(pyramid pooling module)，其中3个尺度的pyramid pooling features被concatenate。为避免池化操作导致细节损失，<strong>RRM_MS</strong>使用kernel size和dilation不同的卷积层捕捉multi-scale contexts。然而这些模块是shallow的，所以<strong>很难捕捉到可用于refinement的high level information</strong>。</li><li>本文的<strong>RRM和predict module结构相似</strong>但简单很多，其包含1个输入层、1个encoder、1个bridge、1个decoder和1个输出层。encoder和decoder都包含<strong>4个stage</strong>，<strong>每个stage</strong>只包含1个64核的3×3卷积层，<strong>每个卷积层</strong>后面都有1个BN层和1个ReLU。bridge和1个stage结构相同，也包含1个64核的3×3卷积层(后面跟着1个BN层和1个ReLU)。encoder中下采样时使用maxpooling，decoder中上采样时使用bilinear interpolation。RRM的输出即本文整个模型最终的输出。</li></ul><h2 id="3-4-Hybrid-Loss"><a href="#3-4-Hybrid-Loss" class="headerlink" title="3.4. Hybrid Loss"></a>3.4. Hybrid Loss</h2><ul><li><p>训练中的Loss是各个side output的loss的加权和，每个side output的loss公式都是1个hybrid loss(3种loss之和)。本文模型对8个side output进行深度监督，其中7个side output来自Predict Module、1个side output来自Refine Module。</p><ul><li>BCE Loss：在二分类和分割任务中，二值交叉熵损失函数（Binary Cross Entropy Loss，BCE Loss）是最常用的损失函数。公式略</li><li>SSIM Loss：结构相似损失（Structural Similarity Loss，SSIM Loss）在提出时被用于图像质量评价。它可以捕捉一张图片中的结构信息，因此本文将其集成于混合损失函数中，以获取显著目标标注中的结构信息。公式略</li><li>IoU Loss：交并比损失（Intersection over Union Loss，IoU Loss）在提出时被用来衡量2个集合的相似性，后来被作为目标检测和分割的标准评估指标。最近，它也被用在了显著性目标检测的训练中。公式略</li></ul></li><li><p>本文阐述了3种loss的作用，图5中的热力图展示了每个像素的loss随训练过程的变化，3列分别代表训练过程中的不同阶段，3行分别是不同的loss。</p><ul><li><p>BCE Loss是<strong>pixel-level</strong>的measure，它并不考虑周围像素的label并且foreground像素和background像素的权重相同，<strong>有助于所有像素的收敛</strong>。</p></li><li><p>SSIM Loss是<strong>patch-level</strong>的measure，它考虑每个像素的local neighborhood，<strong>对边界具有更高的权重</strong>(即使预测前景的概率相同，但边界附近的loss比前景中心的loss更高)。</p><p>  在训练过程的初始阶段，边界周围像素的loss是最大的(见图5第2行)，<strong>这帮助集中于边界附近像素的收敛</strong>。随着训练过程，foreground的SSIM Loss减小而<strong>background的loss成为主导项</strong>。但只有当background的预测非常接近ground truth(0)时 background的loss才会起作用，<strong>这时loss会从1急速下降到0</strong>，因为通常只有在训练晚期BCE loss平滑(flat)时background的预测才会到0。SSIM Loss保证有足够的梯度使得网络继续学习。因为预测被push到0，background的预测看起来会更clean。</p></li><li><p>IoU Loss是<strong>map-level</strong>的measure，但是本文为了阐述所以根据式6画出了每个像素的IoU Loss。</p><p>  随着foreground的预测越来越接近1，foreground的loss最终变成0。</p><p>把3个loss混合起来，<strong>利用BCE使每个像素都有smooth gradient，利用IoU给予foreground更多注意力，通过SSIM基于图像结构使得边界的loss更大</strong>。</p></li></ul></li></ul><h1 id="4-Experimental-Results"><a href="#4-Experimental-Results" class="headerlink" title="4. Experimental Results"></a>4. Experimental Results</h1><h2 id="4-1-Datasets"><a href="#4-1-Datasets" class="headerlink" title="4.1. Datasets"></a>4.1. Datasets</h2><p>在6个常用数据集上对模型进行了评估。具体是哪些数据集、这些数据集有哪些特点请见原文。</p><h2 id="4-2-Implementation-and-Experimental-Setup"><a href="#4-2-Implementation-and-Experimental-Setup" class="headerlink" title="4.2. Implementation and Experimental Setup"></a>4.2. Implementation and Experimental Setup</h2><ul><li><p>训练</p><ul><li>使用DUTS-TR训练模型，训练前进行离线数据增强(将图片水平翻转)。</li><li>将图片resize到256×256并随机裁剪成224×224。</li><li>encoder的部分参数使用ResNet34的预训练模型进行初始化，其它卷积层通过Xavier初始化。</li><li>使用Adam进行训练，超参数为默认值（初始学习率1e-3，betas=(0.9, 0.999)，eps=1e-8，weight decay=0）</li><li>一直训练到loss收敛，不使用validation set。最终经历了400k iterations，batch size为8，耗时125小时c</li></ul></li><li><p>测试/推理</p><p>  将原图resize到256×256，再将最终得到的显著图resize back到原图大小</p></li><li><p>软/硬件环境</p><p>  训练和测试的软硬件环境一致。</p><p>  PyTorch0.4.0，An eight-core PC with an AMD Ryzen 1800x 3.5 GHz CPU (with 32GB RAM) and a GTX 1080ti GPU (with 11GB memory)</p><p>  256×256图片的推理耗时为0.04秒。</p></li></ul><h2 id="4-3-Evaluation-Metrics"><a href="#4-3-Evaluation-Metrics" class="headerlink" title="4.3. Evaluation Metrics"></a>4.3. Evaluation Metrics</h2><p>PR Curve、F-measure、MAE、relaxed F-measure of boundary ($relaxF^b_{\beta}$)。对这几个评估指标的具体介绍请见原文。</p><ul><li><p>PR Curve</p><p>  PR Curve是1种评估预测所得显著性图的标准方式。1张显著性图的precision和recall通过比较二值化的显著性图及其ground truth计算。<strong>1个二值化threshold对应的1对precision和recall是数据集中所有显著性图的平均precision和recall</strong>。threshold从0到1变化，可以得到<strong>1个precision-recall pair序列</strong>，画出来就是PR Curve。</p></li><li><p>F-measure</p><p>  F-measure可以全面地衡量precision和recall，其<strong>基于1对precision和recall进行计算</strong>。在进行算法比较时，一般采用最大的F-measure进行比较。</p></li><li><p>MAE</p><p>  MAE指显著性图与其ground truth的average absolute per-pixel difference。<strong>模型对于1个数据集的MAE为所有显著性图的MAE的平均值</strong>。</p></li><li><p>relaxed F-measure of boundary</p><p>  此处省略，请见原文。</p></li></ul><h2 id="4-4-Ablation-Study"><a href="#4-4-Ablation-Study" class="headerlink" title="4.4. Ablation Study"></a>4.4. Ablation Study</h2><p>这个section验证了本文模型中的每个关键component。消融实验包括architecture ablation和loss ablation2个部分。消融实验是在ECSSD数据集上进行的。</p><ul><li><p>architecture ablation</p><p>  为证明BASNet的有效性，本文提供了BASNet与其它相关结构的量化对比结果。</p><p>  Loss都使用BCE，首先以U-Net作为baseline，然后是Encoder-Decoder Network、Deep Supervision、RRM_LC、RRM_MS、RRM_Ours，结果如表1所示，可见本文提出的<strong>BASNet在这5个实验中性能最优</strong>。</p></li><li><p>loss ablation</p><p>  为阐述本文提出的fusion loss的有效性，本文基于BASNet使用不同loss进行了1系列实验。表1中的结果证明<strong>本文提出的hybrid loss极大地提升了性能</strong>，特别是边界的质量。</p><p>  为进一步阐述损失函数对于BASNet预测质量的影响，使用不同Loss对BASNet进行训练的结果如图7所示，很明显可以看出<strong>本文提出的混合损失函数达到了最优的质量</strong>。</p></li></ul><h2 id="4-5-Comparison-with-State-of-the-arts"><a href="#4-5-Comparison-with-State-of-the-arts" class="headerlink" title="4.5. Comparison with State-of-the-arts"></a>4.5. Comparison with State-of-the-arts</h2><p>和15个SOTA算法进行比较。公平起见，使用原文作者提供的显著性图或者使用原文作者公开的模型。</p><ul><li><p>Quantitative evaluation</p><p>  <strong>图6</strong>展示了在5个数据集上的PR曲线和F-measure曲线，表2展示了在6个数据集上的maximum region-based F-measure、MAE、the relaxed boundary Fmeasure。数据提了很多个percent（略）</p></li><li><p>Qualitative evaluation</p><p>  <strong>图8</strong>展示对比了8种算法对<strong>不同类型图片</strong>的识别效果图，图片类型有images with low contrast、fine structures、large object touching image boundaries、complex object boundaries。</p></li></ul><h1 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h1><p>略</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;论文名称&lt;/p&gt;
&lt;p&gt;  BASNet: Boundary-Aware Sal
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="显著性目标检测" scheme="https://chouxianyu.github.io/tags/%E6%98%BE%E8%91%97%E6%80%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="BASNet" scheme="https://chouxianyu.github.io/tags/BASNet/"/>
    
  </entry>
  
  <entry>
    <title>PSPNet论文阅读笔记</title>
    <link href="https://chouxianyu.github.io/2021/03/05/PSPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://chouxianyu.github.io/2021/03/05/PSPNet论文阅读笔记/</id>
    <published>2021-03-05T07:53:52.000Z</published>
    <updated>2021-03-05T08:14:43.765Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><ul><li><p>论文名称</p><p>  Pyramid Scene Parsing Network</p></li><li><p>作者</p><p>  Hengshuang Zhao等</p></li><li><p>发表时间</p><p>  2016年</p></li><li><p>来源</p><p>  CVPR2017</p></li></ul><h1 id="主要收获"><a href="#主要收获" class="headerlink" title="主要收获"></a>主要收获</h1><h2 id="知识"><a href="#知识" class="headerlink" title="知识"></a>知识</h2><ul><li><p>scene parsing的目标是给图片中每个像素赋予1个类别标签，其可以提供对场景的完整理解，预测每个element的标签、位置和形状。</p></li><li><p>本文主要贡献</p><ul><li>提出PSPNet，将difficult scenery context features嵌入1个FCN based pixel prediction framework。</li><li>基于deeply supervised loss，为ResNet提供1个高效的优化策略。</li><li>为SOTA的scene parsing and semantic segmentation构建了1个practical system，并公开了所有关键细节。</li></ul></li><li><p>本文方法原理</p><p>  为获得合适的global features，本文提出PSPNet。除了<strong>使用传统的dilated FCN实现pixel prediction</strong>，我们<strong>将pixel-level feature扩展到了专门设计的global pyramid pooling的特征中</strong>，局部和全局的clues共同使得最终的预测更可靠。我们还提出了1种使用deeply supervised loss的优化策略。我们给出了所有实验细节（对本文模型的性能很重要），并公开了代码和训练好的模型。</p></li><li><p><strong>本文核心思路</strong></p><p>  scene parsing还面临着diverse scenes和unrestricted vocabulary的困难，其导致一些外表相似的物体被错误预测，但当有了context prior之后，理应可以得到正确的预测。目前基于FCN算法的主要问题也是缺乏利用global scene category clue的合适策略。所以PSPNet基于FCN将<strong>PPM（pyramid pooling module）</strong>作为高效的global context prior。</p></li><li><p><strong>PPM核心思路</strong></p><p>  感受野的大小可以大概表示我们能用多少context information。而CNN的实验感受野比其理论感受野小得多，特别是网络深层。这使得许多网络没有充分融合重要的global scenery prior。</p><p>  Global average pooling直接将所有像素混合得到1个vector可能会失去spatial relation并导致ambiguity。考虑到这一点，Global context information和sub-region context有助于区分各种category，1个更有力的representation可以是来自不同sub-regions的具有这些感受野的信息的融合。</p></li><li><p>其它</p><ul><li>FCN用卷积层代替全连接层进行分类</li><li>dilated convolution可以增大神经网络的感受野。</li><li>本文baseline network是FCN和dilated network(《Semantic image segmentation with deep convolutional nets and fully connected crfs》)。</li><li>一些工作主要探索了2个方向：multi-scale feature ensembling和structure prediction，这2个方向都都改善了scene parsing的localization ability。</li><li>开创性的《Semantic image segmentation with deep convolutional nets and fully connected crfs》使用条件随机场(CRF)作为post processing以精化分割结果。</li><li>《Parsenet: Looking wider to see better》证明了global average pooling with FCN可以提升语义分割结果。</li></ul></li></ul><h2 id="一些未知的东西"><a href="#一些未知的东西" class="headerlink" title="一些未知的东西"></a>一些未知的东西</h2><ul><li>scene和vocabulary具体指什么？</li><li>context prior具体指什么？</li><li>knowledge graph（知识图谱）是什么？</li><li>dilated convolution是什么？</li></ul><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul><li><p>背景</p><p>  对于unrestricted open vocabulary和diverse scenes，scene parsing(场景解析)具有挑战性。</p></li><li><p>方法</p><p>  本文使用PPM(pyramid pooling module)和提出的PSPNet(pyramid scene parsing network)，<strong>实现了通过融合different-region-based context获取全局context信息的能力</strong>。本文中的global prior presentation(全局先验表征)可在scene pareing任务中有效产生高质量结果，而PSPNet提供了1个出色的pixel-level prediction framework。</p></li><li><p>结果</p><p>  本文提出的方法在多个数据集上实现了SOTA，取得ImageNet scene parsing challenge 2016、PASCAL VOC 2012 benchmark和Cityscapes benchmark的第1名。单独1个PSPNet在PASCAL VOC 2012取得mIoU accuracy 85.4%的新纪录，在Cityscapes取得mIoU accuracy 80.2%的新纪录。</p></li></ul><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li><p>背景和意义</p><p>  基于semantic segmentation的scene parsing是计算机视觉中的基本主题，其目标是<strong>给图片中每个像素赋予1个类别标签</strong>。<strong>scene parsing可提供对场景的完整理解，它可以预测每个element的标签、位置和形状</strong>。对于自动驾驶、机器人感应等潜在应用，该主题引起了广泛兴趣。</p></li><li><p>困难</p><p>  <strong>scene parsing的困难与scene和label的多样性紧密相关</strong>。首创的scene parsing任务是对LMO数据集中2688张图片的33个场景进行分类。更多最近的PASCAL VOC语义分割数据集和PASCAL context数据集中包括更多context相似的标签，比如chair和sofa、horse和cow等等。新的ADE20K是最具挑战性的1个数据集数据集，其具有大量无限制开放的vocabulary和更多的scene类别，图1展示了其中一些具有代表性的图片。为这些数据集找到1个有效的算法需要克服许多困难。</p></li><li><p>目前进展</p><p>  scene parsing的SOTA算法多数是基于全卷积神经网络（FCN）。基于CNN的算法推动了dynamic object understanding，但考虑到<strong>diverse scenes和unrestricted vocabulary</strong>则还面临着挑战。图2第1行中1个boat被错误识别为car，出现这些错误是由于<strong>similar appearance of objects</strong>。但<strong>当图片的context prior为1条河附近的boathouse时，理应得到正确的预测</strong>。</p><p>  为了精准的场景感知，知识图谱依赖于scene context的先验信息(prior information)。我们发现<strong>目前基于FCN算法的主要问题是缺乏利用global scene category clue的合适策略</strong>。对于complex scene understanding，为了获取1个global image-level feature，<strong>spatial pyramid poolin</strong>g被广泛应用，因为spatial statistics为overall scene interpretation提供了较好的descriptor。<strong>Spatial pyramid pooling network</strong>进一步增强了这个能力。</p></li><li><p>本文方法原理</p><p>  与上述方法不同，为获得合适的global features，本文提出PSPNet。除了<strong>使用传统的dilated FCN实现pixel prediction</strong>，我们<strong>将pixel-level feature扩展到了专门设计的global pyramid pooling的特征中</strong>，局部和全局的clues共同使得最终的预测更可靠。我们还提出了1种使用deeply supervised loss的优化策略。我们给出了所有实验细节（对本文模型的性能很重要），并公开了代码和训练好的模型。</p></li><li><p>本文方法性能</p><p>  在所有公开数据集上达到SOTA，是ImageNet scene parsing challenge 2016的冠军、PASCALVOC 2012 semantic segmentation benchmark的第1名、urban scene Cityscapes data的第1名。这证明PSPNet为pixellevel prediction tasks指明了1个方向，它甚至可以帮助基于CNN的stereo matching、optical flow、depth estimation等。</p></li><li><p>本文主要贡献</p><ul><li>提出PSPNet，将difficult scenery context features嵌入1个FCN based pixel prediction framework。</li><li>基于deeply supervised loss，为ResNet提供1个高效的优化策略。</li><li>为SOTA的scene parsing and semantic segmentation构建了1个practical system，并公开了所有关键细节。</li></ul></li></ul><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><ul><li><p>受<strong>FCN用卷积层代替全连接层进行分类</strong>的启发，scene parsing和semantic segmentation等pixel-level prediction任务取得了巨大进步。为增大神经网络的感受野，《Semantic image segmentation with deep convolutional nets and fully connected crfs》和《Multi-scale context aggregation by dilated convolutions》使用了<strong>dilated convolution</strong>。Noh等人提出了1个coarse-to-fine structure with deconvolution network以学习segmentation mask。<strong>本文baseline network是FCN和dilated network(《Semantic image segmentation with deep convolutional nets and fully connected crfs》)</strong>。</p></li><li><p>其它工作主要探索了2个方向。</p><ul><li>第1个方向是multi-scale feature ensembling。因为在深度网络中，higher-layer feature包含更多semantic meaning，很少location information。<strong>融合多尺度的特征</strong>可以提高性能。</li><li><p>第2个方向是基于structure prediction。开创性的《Semantic image segmentation with deep convolutional nets and fully connected crfs》<strong>使用条件随机场(CRF)作为post processing以精化分割结果</strong>。还有一些方法通过end-to-end modeling精化了网络。</p><p>这2个方向都都改善了scene parsing的<strong>localization ability</strong>（predicted semantic boundary fits objects），然而在复杂场景中还有很大空间可以更加有效地利用必要信息。</p></li></ul></li><li><p>为充分利用global image-level priors(for diverse scene understanding)，一些方法使用传统方法而非神经网络提取了global context information。在object detection frameworks下也有了相似的提升。Liu等人证明了<strong>global average pooling with FCN可以提升语义分割结果</strong>。然而本文实验证明，对于ADE20K数据集，<strong>这些global descriptors还不足够representative</strong>。因此本文使用PSPNet实现了通过融合<strong>different-region-based context</strong>获取全局context信息的能力。</p></li></ul><h1 id="3-Pyramid-Scene-Parsing-Network"><a href="#3-Pyramid-Scene-Parsing-Network" class="headerlink" title="3. Pyramid Scene Parsing Network"></a>3. Pyramid Scene Parsing Network</h1><p>在把应用FCN到scene parsing时，我们观察到一些具有代表性的失败案例并对其进行了分析。这激发了我们<strong>将pyramid pooling module 作为高效global context prior</strong>的思路。图3展示了PSPNet的结构。</p><h2 id="3-1-Important-Observations"><a href="#3-1-Important-Observations" class="headerlink" title="3.1. Important Observations"></a>3.1. Important Observations</h2><p>ADE20K数据集包含150个stuff/object category labels（比如wall、sky、tree）和1038张imagelevel scene descriptors（比如airport terminal、bedroom、street），所以形成了大量的label和分布广阔的scene。检查了《Semantic understanding of scenes through the ADE20K dataset》提供的FCN baseline的预测结果，我们总结出了complex-scene parsing的几个普遍问题：Mismatched Relationship、Confusion Categories和Inconspicuous Classes（具体内容见原文）。总结这些问题，很多错误与<strong>不同感受野的contextual relationship和global information</strong>部分或完全相关。因此1个具有合适<strong>global-scene-level prior</strong>的神经网络可以大量提高scene parsing的性能。</p><h2 id="3-2-Pyramid-Pooling-Module"><a href="#3-2-Pyramid-Pooling-Module" class="headerlink" title="3.2. Pyramid Pooling Module"></a>3.2. Pyramid Pooling Module</h2><p>实验证明，pyramid pooling module是高效的global contextual prior。</p><p>在1个神经网络中，<strong>感受野的大小可以大概表示我们能用多少context information</strong>。虽然理论上ResNet的感受野已经超过输入图片的大小了，但Zhou等人发现<strong>CNN的实验感受野比其理论感受野小得多，特别是网络深层</strong>。这使得<strong>许多网络没有充分融合重要的global scenery prior</strong>。本文提出1个高效的global prior representation来解决这个问题。</p><p>Global average pooling可以很好地作为global contextual prior的baseline model，常常被用在图片分类任务中，也被用于semantic segmentation。考虑到ADE20K数据集中图片scene的复杂性，该策略并不足以涵盖必要信息：<strong>图片的每个像素被标注为许多stuff/objects，直接将它们混合得到1个vector可能会失去spatial relation并导致ambiguity</strong>。考虑到这一点，<strong>Global context information和sub-region context有助于区分各种category</strong>，1个更有力的representation可以是来自不同sub-regions的具有这些感受野的信息的融合。一些场景/图片分类方面的工作[引]也得到了相似结论。</p><p>在《Hypercolumns for object segmentation and fine-grained localization》中，pyramid pooling生成的不同层次的feature maps最终被flatten和concatenate，然后送入1个全连接层进行分类。该global prior的目标是移除CNN用于图片分类时fixed-size的constraint。为进一步减少不同sub-region之间的context information loss，本文提出1个hierarchical global prior，<strong>包含不同尺度和不同sub-region的信息</strong>，称其为pyramid pooling module，用来在神经网络最后1个特征图上构建global scene prior，如图3(c)所示。</p><p><strong>PPM的具体结构：</strong></p><p>PPM融合4个不同金字塔尺度的特征。最coarse的level是<strong>global pooling</strong>，生成1个single bin output。接下来的pyramid level将特征图<strong>划分成不同的sub-region并为不同location形成pooled representation</strong>。PPM中不同level的输出包含不同尺寸的特征图。为了保持global feature的占比，我们在每1个pyramid level后使用<strong>1×1卷积</strong>以将context representation的dimension减少到1。然后将这些1维特征图<strong>上采样</strong>以使其与初始特征图大小相同。最终将不同level的特征<strong>concatenate</strong>后作为最终的pyramid pooling global feature。</p><p>注意pyramid level的数量和每个level的size是<strong>可以修改</strong>的，它们与输入至pyramid pooling layer的特征图的size相关。该结构采用size不同、stride不同的pooling kernel以提取不同sub-region的特征。因此这些kernel在representation上应该保持合理的gap。本文中的PPM包含<strong>4个level</strong>，bin的size分别是<strong>1×1、2×2、3×3和6×6</strong>。关于选择最大池化还是平均池化，本文5.2节中做了大量实验。</p><h2 id="3-3-Network-Architecture"><a href="#3-3-Network-Architecture" class="headerlink" title="3.3. Network Architecture"></a>3.3. Network Architecture</h2><p>如图3所示，输入1张图片，使用预训练的<strong>ResNet</strong>模型并使用<strong>dilated network的策略</strong>提取得到feature map。最后feature map的size是输入图片size的1/8。然后使用PPM获取context information。通过本文4个level的PPM，可以涵盖图片的whole、half和small portions。然后将PPM4个分支的输出和PPM的输入concatenate。最后再用1个卷积层获得最后的prediction。</p><p>PSPNet为pixel-level scene parsing提供了高效的global contextual prior。PPM提取到的特征比global pooling更具代表性。考虑到计算成本，PSPNet相比于其 baseline(the original dilated FCN network)并没有增加多少计算成本。通过end-to-end learning，全局的PPM特征和局部的FCN特征可以最优化。</p><h1 id="4-Deep-Supervision-for-ResNet-Based-FCN"><a href="#4-Deep-Supervision-for-ResNet-Based-FCN" class="headerlink" title="4. Deep Supervision for ResNet-Based FCN"></a>4. Deep Supervision for ResNet-Based FCN</h1><p>深度网络可以得到好的性能，但增加网络深度可能导致optimization difficulty，ResNet通过在每个block中使用skip connection解决了这个问题。ResNet的Latter layers主要基于previous ones学习residues。</p><p>相反地，本文通过1个additional loss生成initial results，然后通过the final loss学习residue。因此，深度网络的优化被分解成易解的2个。</p><p>略……</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;论文名称&lt;/p&gt;
&lt;p&gt;  Pyramid Scene Parsing Network&lt;/p&gt;
&lt;/li&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="scene parsing" scheme="https://chouxianyu.github.io/tags/scene-parsing/"/>
    
      <category term="PSPNet" scheme="https://chouxianyu.github.io/tags/PSPNet/"/>
    
  </entry>
  
  <entry>
    <title>FPN网络图解及论文笔记</title>
    <link href="https://chouxianyu.github.io/2021/03/02/FPN%E7%BD%91%E7%BB%9C%E5%9B%BE%E8%A7%A3%E5%8F%8A%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>https://chouxianyu.github.io/2021/03/02/FPN网络图解及论文笔记/</id>
    <published>2021-03-02T14:38:21.000Z</published>
    <updated>2021-03-02T15:00:11.761Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FPN网络图解"><a href="#FPN网络图解" class="headerlink" title="FPN网络图解"></a>FPN网络图解</h1><p><img src="https://pic4.zhimg.com/v2-4bda90f7c75b31ff8d669a5f71860943_b.jpg" alt="FPN"></p><p><strong>原图片以及PPT源文件下载链接（欢迎关注我的知乎！）：</strong></p><p>链接：<a href="https://pan.baidu.com/s/10y78HagInyCuCA-aMeNJpg" target="_blank" rel="noopener">https://pan.baidu.com/s/10y78HagInyCuCA-aMeNJpg</a></p><p>提取码：iccm </p><p>复制这段内容后打开百度网盘手机App，操作更方便哦</p><h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><ul><li><p>论文名称</p><p>  Feature Pyramid Networks for Object Detection</p></li><li><p>作者</p><p>  Tsung-Yi Lin等</p><p>  Facebook AI Research</p></li><li><p>发表时间</p><p>  2017年</p></li><li><p>来源</p><p>  CVPR2017</p></li></ul><h1 id="主要收获"><a href="#主要收获" class="headerlink" title="主要收获"></a>主要收获</h1><ul><li><p>知识</p><ul><li><p>高级语义信息是有助于识别目标但有害于定位目标，低级空间信息有害于识别目标但有助于定位目标（由于其下采样次数较少，所以其可以更准确地定位）。</p></li><li><p>SSD没有利用higher-resolution maps，而本文证明了higher-resolution maps对于检测小物体很重要。</p></li><li><p>Introduction整体思路</p><p>  Feature Pyramids可以用于检测不同尺度的目标。</p><p>  Featurized Image Pyramids将图片缩放到不同大小并分别提取其特征并进行检测，其结构如图1(a)所示，其被大量应用于手工特征，其优点是每个层次都具有很强的语义信息（即使是high-resolution levels），其缺点是分别提取每个层次的特征并进行检测导致推理时间相应加倍。</p><p>  在recognition任务中，卷积网络逐渐取代了手工特征。卷积网络（Single feature map）逐渐不仅可以表示高级语义，在尺度变化方面也更具稳健性，因此可以只在一个尺度的特征图上进行检测，其结构如图1(b)所示，但其缺点是未利用到卷积网络固有的Pyramidal feature hierarchy。</p><p>  卷积网络（Pyramidal feature hierarchy）天然具有多尺度的、金字塔型的特征层次，其结构如图1(c)所示，其缺点是造成不同层次特征图之间的语义差异，high-resolution maps中包含的低级特征降低了该特征图在目标检测任务中的表征能力。SSD并没有利用higher-resolution maps，但本文证明了higher-resolution maps对于检测小物体很重要。</p><p>  如图2(top)所示，一些采用自上到下路径和skip connections的方法仅在自上到下路径顶部的单个特征图上进行预测，实际上这些方法还需要image pyramids以识别多尺度的目标。</p><p>  如图2(bottom)和图1(d)所示，FPN自然地利用卷积网络固有的金字塔层次同时创建每层都有较强语义信息的特征金字塔，通过1个从上到下的路径和侧边连接将low-resolution、semantically strong的特征和high-resolution、semantically weak的特征结合起来，在自上到下路径所有特征图上都进行预测，最终仅从单尺度的输入图片得到各层都有较强语义信息的特征金字塔，且不需额外计算成本。</p></li><li><p>FPN以<strong>任意大小</strong>的单张图片为输入。</p></li><li><p>对于ResNet，FPN并不将其第1个stage的输出包含到FPN中因为其内存占用量比较大。</p></li><li><p>FPN中bottom-up路径中相邻层间下采样比例为2</p></li><li><p>FPN的building block</p><p>  <strong>图3</strong>展示了创建top-down路径中特征图的building block。将top-down路径中coarser-resolution的特征图<strong>上采样（比例为2）</strong>，将bottom-up路径中的特征图<strong>通过1×1卷积减少通道数</strong>，然后将两者<strong>相加（element-wise）</strong>。这个过程一直迭代到生成最大的特征图。在开始top-down路径之前会在bottom-up路径顶层<strong>使用1×1卷积生成尺度最小的特征图</strong>。在每个相加操作之后<strong>使用3×3卷积减少上采样带来的混淆效应</strong>（aliasing effect）。</p></li><li><p>FPN和传统的featurized image pyramid一样，各个金字塔层都使用<strong>共享的classifier/regressor</strong>。</p></li></ul></li><li><p>一些未知的东西</p><ul><li><p>特征金字塔</p><p>  原文：E. H. Adelson, C. H. Anderson, J. R. Bergen, P. J. Burt, and J. M. Ogden. Pyramid methods in image processing. RCA engineer, 1984.</p></li><li><p>尺度不变性（scale-invariant）</p></li></ul></li></ul><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul><li>Feature Pyramids（特征金字塔）是识别系统中用来检测不同尺度的目标的一个基本组件</li><li><p>近期深度学习目标检测方法却避免了pyramid representations，如原文图1(b)，部分原因是它们是计算和内存密集型的</p></li><li><p>FPN(Feature Pyramid Network)</p><ul><li>使用少量成本，利用卷积网络固有的多尺度金字塔层次结构来构建特征金字塔</li><li>是一种带有侧向连接的自顶向下的结构，可以<strong>在所有尺度上构建高级语义特征</strong></li></ul></li><li>性能<ul><li>将FPN应用于基本的Faster-RCNN，在COCO detection benchmark上超过SOTA的single model</li><li>在GPU上达6FPS</li></ul></li></ul><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li><p>识别不同尺寸的目标是计算机视觉领域的一个基础挑战</p></li><li><p><strong>Featurized Image Pyramids</strong>（特征化的图像金字塔）</p><ul><li><p>定义</p><p>  Featurized Image Pyramids即Feature pyramids built upon image pyramids（建立在图像金字塔上的特征金字塔），见原文<strong>图1(a)</strong>。也就是<strong>将图片缩放到不同大小并分别提取其特征并进行检测</strong>。</p><p>  其构成了标准解决方案的基础，其具有<strong>尺度不变性（scale-invariant）</strong>，因为可以通过金字塔中的不同层来处理不同尺寸的目标，可以基于层维度和位置维度对目标进行扫描检测。</p></li><li><p>应用</p><p>  Featurized Image Pyramids在<strong>手工设计的特征</strong>中被大量使用，如DPM算法。</p></li><li><p>优点</p><p>  所有最近的ImageNet和COCO比赛的前几名都在Featurized Image Pyramids上进行多尺度测试。</p><p>  Featurized Image Pyramids的主要优点是<strong>每个层次都具有很强的语义信息，即使是high-resolution levels</strong>。</p></li><li><p>缺点</p><ul><li>分别提取每个层次的特征并进行检测，推理时间相应地加倍。</li><li><p>考虑到内存等因素，不可能端到端地在图像金字塔上训练卷积网络，最多只能在测试的时候使用图像金字塔（同时这也造成训练和测试的不一致性）</p><p>因为这些原因，Fast和Faster R-CNN默认也就没有使用FIP。</p></li></ul></li></ul></li><li><p>卷积网络（Single feature map）</p><p>  在Recognition任务中，手工特征逐渐被卷积网络取代。</p><p>  卷积网络不仅可以表示高级语义，在尺度变化方面也更具稳健性，因此可以<strong>只在一个尺度的特征图上进行检测</strong>，如原文<strong>图1(b)</strong>。</p><p>  但即使具备这样的稳健性，卷积网络中仍然需要金字塔（可以通过Pyramidal feature hierarchy改进）。</p></li><li><p>卷积网络（Pyramidal feature hierarchy）</p><ul><li><p>固有金字塔特征层次</p><p>  然而image pyramids并不是实现多尺度特征表示的唯一方法，<strong>卷积神经网络天然具有多尺度的、金字塔型的特征层次</strong>（feature hierarchy），如原文<strong>图1(c)</strong>。</p></li><li><p>缺点</p><p>  卷积网络的特征层次产生了不同尺寸的特征图，但是<strong>造成不同层次特征图之间的语义差异</strong>，尺寸大的特征图（high-resolution maps）包含着低级特征，这些<strong>低级特征降低了该特征图在目标检测任务中的表征能力</strong>。</p><p>  SSD是第一批尝试利用卷积网络中Pyramidal feature hierarchy的方法之一，但其也存在不足。理想情况中，SSD系列会利用forward pass中生成的多尺度特征，因此没有额外计算成本。但是为了避免使用低级特征，SSD没有使用已有的层，而是从网络高层开始构建金字塔并添加几个新层。因此<strong>SSD没有利用higher-resolution maps，而本文证明了higher-resolution maps对于检测小物体很重要</strong>。</p></li></ul></li><li><p>Feature Pyramid Network</p><ul><li><p>定义</p><p>  自然地利用卷积网络固有的金字塔层次同时创建每层都有较强语义信息的特征金字塔。如<strong>图1(d)和图2(bottom)</strong>所示，通过1个从上到下的路径和侧边连接<strong>将low-resolution、semantically strong的特征和high-resolution、semantically weak的特征结合</strong>起来，<strong>仅从单尺度的输入图片得到各层都有较强语义信息的特征金字塔</strong>，且不需额外计算成本。</p></li><li><p>相关工作</p><p>  如<strong>图2(top)</strong>所示，其它采用自上到下路径和skip connections的方法<strong>仅在自上到下路径顶部的单个特征图上进行预测</strong>，实际上<strong>这些方法还需要image pyramids以识别多尺度的目标</strong>，而FPN是在自上到下路径所有特征图上都进行预测。</p></li><li><p>效果</p><p>  在detection和segmentation系统上进行评估，仅将FPN应用于基础的Faster R-CNN在COCO detection benchmark上实现SOTA。</p><p>  在ablation experiments中，对于bounding box proposals，FPN将AR(Average Recall)提升了8 points；对于目标检测，将COCO-style Average Precision (AP)提升了2.3 points，将PASCAL-style AP，提高了3.8 points。</p><p>  FPN易于应用于到mask proposals并能提升实例分割的AR和速度。</p><p>  FPN可以进行端到端的多尺度训练，并且在训练和测试时都可以用，还不增加计算成本。</p></li></ul></li></ul><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><ul><li><p>Hand-engineered features and early neural networks</p><p>  SIFT特征用于特征点匹配，HOG和后来的SIFT在整个图像金字塔上进行密集计算，它们在图像分类、目标检测、人体姿态估计等任务中被大量使用。</p><p>  很快地也有了许多关于featurized image pyramids的研究。Dollar等人首先按尺度稀疏采样得到1个金字塔，然后对缺失的level进行插值，实现了快速的金字塔计算。在HOG和SIFT之前，使用卷积网络进行人脸检测的早期工作计算图像金字塔上的浅层网络以检测跨多尺度的人脸。</p></li><li><p>Deep ConvNet object detectors</p><p>  OverFeat采用1种与早期神经网络人脸检测器相似的策略，其将1个卷积网络作为1个sliding window detector应用于图像金字塔。</p><p>  R-CNN采用1种基于region proposal的策略，其中在使用卷积网络分类之前each proposal was scale-normalized。</p><p>  SPPNet表明这些基于region的detector可以更有效地应用于从单尺度图片提取出的特征图上。</p><p>  最近更加准确的Fast R-CNN和Faster R-CNN等算法提倡使用从单尺度图片计算得到的特征，因为这可以实现accuracy和speed的trade-off。</p><p>  <strong>Multi-scale detection仍然表现更佳，特别是对于小目标</strong>。</p></li><li><p>Methods using multiple layers</p><p>  最近大量方法利用卷积网络中的不同层提高了检测和分割的性能。FCN在多个尺度上计算每个category的的partial score以得到语义分割，Hypercolumns将类似方法应用于object instance segmentation。HyperNet、ParseNet和ION等方法在计算结果前将多层特征拼接，这等价于对转换后的特征求和。SSD和MS-CNN在多个特征层分别预测结果，并没有将多层特征结合。</p><p>  最近有很多方法在探索可以将低级特征和高级特征融合的lateral/skip connections，包括用于segmentation的U-Net和SharpMask、用于人脸检测的Recombinator networks、用于关键点预测的Stacked Hourglass networks。Ghiasi等人实现了在FCN上实现了1个Laplacian pyramid presentation，可以逐渐优化分割结果。即使这些方法采用了金字塔形状的结构，<strong>它们并不像featurized image pyramids一样在所有层独立预测结果</strong>，如图2所示，实际上<strong>这些方法还需要image pyramids以识别多尺度的目标</strong>。</p></li></ul><h1 id="3-Feature-Pyramid-Networks"><a href="#3-Feature-Pyramid-Networks" class="headerlink" title="3. Feature Pyramid Networks"></a>3. Feature Pyramid Networks</h1><p>FPN的目标是构造1个各层都具有较强高级语义信息的特征金字塔。FPN is general-purpose（多用途的），本文将其应用于RPN和Fast R-CNN，在Sec. 6中将其generalize到instance segmentation proposals。</p><p>FPN通过全卷积的方式，以任意大小的单张图片为输入，在多个尺度输出对应比例大小的特征图。该过程独立于骨干网络的具体架构，本文展示了基于ResNet的结果。FPN的构建包括1个bottom-up路径、1个top-down路径和lateral connections。</p><ul><li><p>Bottom-up pathway</p><p>  Bottom-up pathway就是骨干网络的feedforward，<strong>每层间下采样比例为2</strong>。网络中经常有连续几个层输出的特征图尺寸相同，我们称这些层位于同1个stage。在FPN中，为每个stage定义1个金字塔层。取每个stage中最后1层的输出代表该stage，因为每个stage中最深的层应该具有最强的特征。</p><p>  对于ResNet，使用后4个stage（相对于输入的步长分别为4、8、16、32）的输出，并不将第1个stage的输出包含到FPN中因为<strong>其内存占用量比较大</strong>。</p></li><li><p>Top-down pathway and lateral connections</p><p>  top-down pathway将金字塔中空间信息粗糙、语义信息更强的高层特征图上采样生成尺寸较大的特征图，然后通过lateral connections用bottom-up路径中的特征对这些特征进行增强。每个lateral connection将bottom-up路径和top-down路径中相同尺寸的特征图融合。bottom-up路径中的特征图具有较低级别的语义信息，但是<strong>由于其下采样次数较少</strong>所以其可以更准确地定位。</p><p>  <strong>图3</strong>展示了创建top-down路径中特征图的building block。将top-down路径中coarser-resolution的特征图<strong>上采样（比例为2）</strong>，将bottom-up路径中的特征图<strong>通过1×1卷积减少通道数</strong>，然后将两者<strong>相加（element-wise）</strong>。这个过程一直迭代到生成最大的特征图。在开始top-down路径之前会在bottom-up路径顶层<strong>使用1×1卷积生成尺度最小的特征图</strong>。在每个相加操作之后<strong>使用3×3卷积减少上采样带来的混淆效应</strong>（aliasing effect）。</p><p>  因为各个金字塔层都和传统的featurized image pyramid一样使用共享的classifier/regressor，所以<strong>将所有额外卷积层的输出通道数设置为256</strong>。在这些额外的层中，并不存在non-linearities，但我们凭经验发现其影响很小。</p><p>  simplicity对FPN非常重要，我们发现FPN对很多设计选择具有鲁棒性。我们使用更sophisticated的block（比如使用multilayer residual blocks作为连接）进行实验并观察到了略胜一筹的结果。设计更优的connection并非本文的重点，所以我们采用了上述的简单设计。</p></li></ul><h1 id="4-Applications"><a href="#4-Applications" class="headerlink" title="4. Applications"></a>4. Applications</h1><p>略……</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FPN网络图解&quot;&gt;&lt;a href=&quot;#FPN网络图解&quot; class=&quot;headerlink&quot; title=&quot;FPN网络图解&quot;&gt;&lt;/a&gt;FPN网络图解&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4bda90f7c75b31
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="FPN" scheme="https://chouxianyu.github.io/tags/FPN/"/>
    
  </entry>
  
  <entry>
    <title>ResNet50网络结构图及结构详解</title>
    <link href="https://chouxianyu.github.io/2021/02/26/ResNet50%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%9B%BE%E5%8F%8A%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/"/>
    <id>https://chouxianyu.github.io/2021/02/26/ResNet50网络结构图及结构详解/</id>
    <published>2021-02-26T14:23:59.000Z</published>
    <updated>2021-03-17T12:32:32.765Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>之前我读了ResNet的论文Deep Residual Learning for Image Recognition，也做了<a href="https://zhuanlan.zhihu.com/p/353228657" target="_blank" rel="noopener">论文笔记</a>，笔记里记录了ResNet的理论基础（核心思想、基本Block结构、Bottleneck结构、ResNet多个版本的大致结构等等），看本文之间可以先看看打打理论基础。</p><p>一个下午的时间，我用PPT纯手工做了一张图片详细说明ResNet50的具体结构，本文将结合该图片详细介绍ResNet50。</p><p>这张图和这篇文章估计全网最详细了（狗头）。</p><p>废话不多说，先放图片（<strong>文末有图片和PPT源文件的下载链接</strong>）。</p><p><img src="https://pic1.zhimg.com/80/v2-b1ac9497249c5de6b812b1af729f4c44_720w.jpg" alt="img"></p><p>上图（称为<strong>本图</strong>）可划分为左、中、右3个部分，三者内容分别如下</p><ol><li>ResNet50整体结构</li><li>ResNet50各个Stage具体结构</li><li>Bottleneck具体结构</li></ol><p>接下来为正文内容，本文<strong>先后介绍了本图从左到右的3个部分，并对Bottleneck进行了简要分析</strong>。</p><h1 id="ResNet50整体结构"><a href="#ResNet50整体结构" class="headerlink" title="ResNet50整体结构"></a>ResNet50整体结构</h1><p>首先需要声明，这张图的内容是ResNet的Backbone部分（即图中没有ResNet中的全局平均池化层和全连接层）。</p><p>如本图所示，输入<code>INPUT</code>经过ResNet50的5个阶段（<em>Stage 0</em>、<em>Stage 1</em>、……）得到输出<code>OUTPUT</code>。</p><p>下面附上ResNet原文展示的ResNet结构，大家可以结合着看，看不懂也没关系，只看本文也可以无痛理解的。</p><p><img src="https://pic1.zhimg.com/80/v2-c4d2be9eb4ec809fded093a341efeab5_720w.png" alt="img"></p><p>上图描述了ResNet多个版本的具体结构，本文描述的“ResNet50”中的50指有50个层。和上图一样，本图描述的ResNet也分为5个阶段。</p><h1 id="ResNet各个Stage具体结构"><a href="#ResNet各个Stage具体结构" class="headerlink" title="ResNet各个Stage具体结构"></a>ResNet各个Stage具体结构</h1><p>如本图所示，ResNet分为5个stage（阶段），其中<em>Stage 0</em>的结构比较简单，可以视其为对<code>INPUT</code>的预处理，后4个Stage都由<em>Bottleneck</em>组成，结构较为相似。<em>Stage 1</em>包含3个<em>Bottleneck</em>，剩下的3个stage分别包括4、6、3个<em>Bottleneck</em>。</p><p>现在对<em>Stage 0</em>和<em>Stage 1</em>进行详细描述，同理就可以理解后3个Stage。</p><h2 id="Stage-0"><a href="#Stage-0" class="headerlink" title="Stage 0"></a>Stage 0</h2><ul><li><p><code>(3,224,224)</code>指输入<code>INPUT</code>的通道数(channel)、高(height)和宽(width)，即<code>(C,H,W)</code>。现假设输入的高度和宽度相等，所以用<code>(C,W,W)</code>表示。</p></li><li><p>该stage中第1层包括3个先后操作</p><ol><li><p><code>CONV</code></p><p> <code>CONV</code>是卷积（Convolution）的缩写，<code>7×7</code>指卷积核大小，<code>64</code>指卷积核的数量（即该卷积层输出的通道数），<code>/2</code>指卷积核的步长为2。</p></li><li><p><code>BN</code></p><p> <code>BN</code>是Batch Normalization的缩写，即常说的BN层。</p></li><li><p><code>RELU</code></p><p> <code>RELU</code>指ReLU激活函数。</p></li></ol></li><li><p>该stage中第2层为<code>MAXPOOL</code>，即最大池化层，其kernel大小为<code>3×3</code>、步长为<code>2</code>。</p></li><li><p><code>(64,56,56)</code>是该stage输出的通道数(channel)、高(height)和宽(width)，其中<code>64</code>等于该stage第1层卷积层中卷积核的数量，<code>56</code>等于<code>224/2/2</code>（步长为2会使输入尺寸减半）。</p></li></ul><p>总体来讲，在<em>Stage 0</em>中，形状为<code>(3,224,224)</code>的输入先后经过卷积层、BN层、ReLU激活函数、MaxPooling层得到了形状为<code>(64,56,56)</code>的输出。</p><h2 id="Stage-1"><a href="#Stage-1" class="headerlink" title="Stage 1"></a>Stage 1</h2><p>在理解了<em>Stage 0</em>以及熟悉图中各种符号的含义之后，可以很容易地理解<em>Stage 1</em>。理解了<em>Stage 1</em>之后，剩下的3个stage就不用我讲啦，你自己就能看懂。</p><p><em>Stage 1</em>的输入的形状为<code>(64,56,56)</code>，输出的形状为<code>(64,56,56)</code>。</p><p>下面介绍<em>Bottleneck</em>的具体结构（难点），把<em>Bottleneck</em>搞懂后，你就懂<em>Stage 1</em>了。</p><h1 id="Bottleneck具体结构"><a href="#Bottleneck具体结构" class="headerlink" title="Bottleneck具体结构"></a>Bottleneck具体结构</h1><p>现在让我们把目光放在本图最右侧，最右侧介绍了2种<em>Bottleneck</em>的结构。</p><p>“BTNK”是<em>BottleNeck</em>的缩写（本文自创，请谨慎使用）。</p><p>2种<em>Bottleneck</em>分别对应了2种情况：输入与输出通道数相同（<code>BTNK2</code>）、输入与输出通道数不同（<code>BTNK1</code>），这一点可以结合ResNet原文去看喔。</p><h2 id="BTNK2"><a href="#BTNK2" class="headerlink" title="BTNK2"></a>BTNK2</h2><p>我们首先来讲<code>BTNK2</code>。</p><p><code>BTNK2</code>有2个可变的参数<code>C</code>和<code>W</code>，即输入的形状<code>(C,W,W)</code>中的<code>c</code>和<code>W</code>。</p><p>令形状为<code>(C,W,W)</code>的输入为$x$，令<code>BTNK2</code>左侧的3个卷积块（以及相关BN和RELU）为函数$F(x)$，两者相加（$F(x)+x$）后再经过1个ReLU激活函数，就得到了<code>BTNK2</code>的输出，该输出的形状仍为<code>(C,W,W)</code>，即上文所说的<code>BTNK2</code>对应输入$x$与输出$F(x)$通道数相同的情况。</p><h2 id="BTNK1"><a href="#BTNK1" class="headerlink" title="BTNK1"></a>BTNK1</h2><p><code>BTNK1</code>有4个可变的参数<code>C</code>、<code>W</code>、<code>C1</code>和<code>S</code>。</p><p>与<code>BTNK2</code>相比，<code>BTNK2</code>多了1个右侧的卷积层，令其为函数$G(x)$。<code>BTNK1</code>对应了输入$x$与输出$F(x)$通道数不同的情况，也正是这个添加的卷积层将$x$变为$G(x)$，起到匹配输入与输出维度差异的作用（$G(x)$和$F(x)$通道数相同），进而可以进行求和$F(x)+G(x)$。</p><h2 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h2><p>可知，ResNet后4个stage中都有<code>BTNK1</code>和<code>BTNK2</code>。</p><ul><li><p>4个stage中<code>BTNK2</code>参数规律相同</p><p>  4个stage中<code>BTNK2</code>的参数全都是1个模式和规律，只是输入的形状<code>(C,W,W)</code>不同。</p></li><li><p><em>Stage 1</em>中<code>BTNK1</code>参数的规律与后3个stage不同</p><p>  然而，4个stage中<code>BTNK1</code>的参数的模式并非全都一样。具体来讲，后3个stage中<code>BTNK1</code>的参数模式一致，<em>Stage 1</em>中<code>BTNK1</code>的模式与后3个stage的不一样，这表现在以下2个方面：</p><ol><li><p>参数<code>S</code>：<code>BTNK1</code>左右两个1×1卷积层是否下采样</p><p> <em>Stage 1</em>中的<code>BTNK1</code>：步长<code>S</code>为1，没有进行下采样，输入尺寸和输出尺寸相等。</p><p> 后3个stage的<code>BTNK1</code>：步长<code>S</code>为2，进行了下采样，输入尺寸是输出尺寸的2倍。</p></li><li><p>参数<code>C</code>和<code>C1</code>：<code>BTNK1</code>左侧第一个1×1卷积层是否减少通道数</p><p> <em>Stage 1</em>中的<code>BTNK1</code>：输入通道数<code>C</code>和左侧1×1卷积层通道数<code>C1</code>相等（<code>C=C1=64</code>），即左侧1×1卷积层没有减少通道数。</p><p> 后3个stage的<code>BTNK1</code>：输入通道数<code>C</code>和左侧1×1卷积层通道数<code>C1</code>不相等（<code>C=2*C1</code>），左侧1×1卷积层有减少通道数。</p></li></ol></li><li><p>为什么<em>Stage 1</em>中<code>BTNK1</code>参数的规律与后3个stage不同？（个人观点）</p><ul><li><p>关于<code>BTNK1</code>左右两个1×1卷积层是否下采样</p><p>  因为<em>Stage 0</em>中刚刚对网络输入进行了卷积和最大池化，还没有进行残差学习，此时直接下采样会损失大量信息；而后3个stage直接进行下采样时，前面的网络已经进行过残差学习了，所以可以直接进行下采样。</p></li><li><p>关于<code>BTNK1</code>左侧第一个1×1卷积层是否减少通道数</p><p>  根据ResNet原文可知，<em>Bottleneck</em>左侧两个1×1卷积层的主要作用分别是减少通道数和恢复通道数，这样就可以使它们中间的3×3卷积层的输入和输出的通道数都较小，因此效率更高。</p><p>  <em>Stage 1</em>中<code>BTNK1</code>的输入通道数<code>C</code>为64，它本来就比较小，因此没有必要通过左侧第一个1×1卷积层减少通道数。</p></li></ul></li></ul><h1 id="福利"><a href="#福利" class="headerlink" title="福利"></a>福利</h1><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" alt="img"></p><p>扫码关注微信公众号后回复<code>resnet</code>即可直接获取图片和PPT源文件的下载链接。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://www.bilibili.com/read/cv2051292" target="_blank" rel="noopener">https://www.bilibili.com/read/cv2051292</a></p><p><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">https://arxiv.org/abs/1512.03385</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;之前我读了ResNet的论文Deep Residual Learning for Image Recognitio
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ResNet" scheme="https://chouxianyu.github.io/tags/ResNet/"/>
    
  </entry>
  
  <entry>
    <title>ResNet论文阅读笔记</title>
    <link href="https://chouxianyu.github.io/2021/02/26/ResNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://chouxianyu.github.io/2021/02/26/ResNet论文阅读笔记/</id>
    <published>2021-02-26T13:33:20.000Z</published>
    <updated>2021-03-17T12:34:45.326Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><ul><li><p>论文名称</p><p>  Deep Residual Learning for Image Recognition</p></li><li><p>作者</p><p>  Kaiming He</p><p>  Microsoft Research</p></li><li><p>发表时间</p><p>  2015年</p></li><li><p>来源</p><p>  CVPR2016</p></li></ul><h1 id="主要收获"><a href="#主要收获" class="headerlink" title="主要收获"></a>主要收获</h1><ul><li>知识<ul><li>较深的神经网络难以训练</li><li><strong>网络的深度</strong>对于许多视觉识别任务至关重要<ul><li>152层的ResNet，<strong>8× deeper than VGG</strong>，但却有<strong>更低的计算复杂度</strong>，在ImageNet测试集上错误率为3.57%，获ILSVRC 2015中图像分类任务的第1名。</li><li>ResNet在COCO目标检测数据集上获得了<strong>28％</strong>的相对改进，在其它几个数据集和任务上也取得第1名。</li></ul></li><li><strong>假设</strong>多个非线性层可以渐近地逼近复杂函数（该假设还有待讨论，详见引文），则等效于假设它们可以渐近地近似残差函数。</li><li>理论基础：假设目标函数为H(x)，可将其表示为H(x)=F(x)+x。若最优解是identity mapping，则此时F(x)为0，<strong>使参数为0比学习H(x)更加容易</strong>。</li><li>F(x)+x可以通过<strong>shortcut connections</strong>实现，不需额外参数，仅需微小计算量（element-wise addition）。</li><li>基础网络（Plain Network）采用VGGNet的设计思路，主要使用3×3卷积并遵守2个设计原则：①若输出特征图的尺寸不变，则通道数也应不变；②若输出特征的尺寸减半，则通道数应增1倍以保留时间复杂度。</li><li><a href="https://zhuanlan.zhihu.com/p/353235794" target="_blank" rel="noopener">ResNet50网络结构图解以及Bottleneck结构图解</a></li></ul></li><li>未知点<ul><li>residual：并不只是ResNet中的residual，在其它领域和算法中也有residual的概念，有待了解。</li><li>inception：《Going deeper with convolutions》</li><li>highway networks：《Highway networks》、《Training very deep networks》</li><li>VGGNet的设计思想</li><li>bacth normalization</li><li>mini-batch</li></ul></li></ul><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul><li>较深的神经网络难以训练，本文提出一个residual learning framework训练较深的神经网络。</li><li>We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions.</li><li>通过大量empirical实验证明，本文中提出的残差网络<strong>更易优化</strong>，并可以从大量增加的网络深度中获取<strong>准确性</strong>。用<strong>152层（8× deeper than VGG）</strong>，但却有<strong>更低的计算复杂度</strong>，在ImageNet测试集上错误率为3.57%(top5)，获ILSVRC 2015中图像分类任务的第1名。</li><li>网络的深度对于许多视觉识别任务至关重要。ResNet在COCO目标检测数据集上获得了<strong>28％</strong>的相对改进，在其它几个数据集和任务上也取得第1名。</li></ul><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li><p>背景/问题</p><ul><li><p><strong>深度网络以1种end-to-end的多层的方式，自然地集成了low/mid/high-level features和classifiers[引]，并且features的“levels”可以通过堆叠层数（深度）来enrich。</strong></p></li><li><p>最近有研究[引]证明网络的深度十分重要，ImageNet上的领先结果[引]都使用了”very deep” model[引]（16到30层），较深的网络在其它视觉识别任务中也有好的效果。</p></li><li><p>既然深度如此重要，那有个问题是：<strong>Is learning better networks as easy as stacking more layers</strong>。要回答这个问题，1个障碍是<strong>梯度消失/爆炸</strong>（会影响模型收敛），该问题已通过<strong>normalized initialization</strong>[引]和<strong>intermediate normalization layers</strong>[引]得到很大的解决，可以使数十层的网络通过SGD收敛。</p></li><li><p>深度模型收敛之后，又遇到了<strong>the degradation problem：随着网络深度增加，准确率变得饱和然后迅速下降</strong>，并且实验结果说明这种下降并不是过拟合导致的。相关研究[引]指出<strong>给1个层数合适的网络添加更多的层会导致训练误差增高</strong>，本文图1和图4也彻底证明了这一点。</p><p>  考虑1个shallower architecture并基于此添加一些层形成1个deeper counterpart，如果添加的这些层是identity mapping，那这个deeper counterpart则等同于这个shallower architecture。这说明<strong>1个deeper model的训练误差应不高于其shallower counterpart</strong>。但实验证明，目前的模型并没有达到这个效果。</p></li></ul></li><li><p>本文所提方法的原理及优点</p><ul><li><p>本文提出1个deep residual learning framework来解决degradation问题。each few stacked layers并不直接拟合1个desired underlying mapping：$H(x)$，而是拟合1个residual mapping：$F(x)=H(x)-x$，即原先想要的underlying mapping为$H(x)=F(x)+x$。</p></li><li><p>我们假定该residual mapping比原先的mapping更易优化。<strong>在极端情况下如果identity mapping是最优的，使residual为0比拟合1个identity mapping更加容易。</strong></p><p>  $F(x)+x$可以<strong>通过shortcut connections实现</strong>，在本方法中其仅需进行identity mapping和相加，如原文图2所示。<strong>这种identity shortcut connections不需要额外参数和计算量</strong>。整个网络仍可以通过SGD进行end-to-end训练，并易于通过Caffe等开源库实现。</p></li></ul></li><li><p>实验与结果</p><ul><li>本文在ImageNet上进行了全面实验以说明degradation问题和评估本文的方法。<ol><li>Our extremely deep residual nets are <strong>easy to optimize</strong>, but the counterpart “plain” nets (that simply stack layers) exhibit <strong>higher training error when the depth increases</strong>.</li><li>Our deep residual nets can <strong>easily enjoy accuracy gains from greatly increased depth</strong>, producing results <strong>substantially better than previous networks</strong>.</li></ol></li><li>在CIFAR-10上进行实验也出现了类似现象，说明degradation问题和<strong>本文方法并不只适用于特定数据集</strong>。我们训练了超过100层的网络，还尝试了超过1000层的网络。</li><li>在ImageNet上，我们的<strong>152层</strong>网络是最深的，但其<strong>比VGG计算复杂度更低</strong>，在ImageNet测试集上错误率为3.57%(top5)，获ILSVRC 2015中图像分类任务的第1名。在其它识别任务中也有出色表现，有多项第1名（略）。这说明the residual learning principle is generic，我们猜想<strong>本方法也适用于其它视觉和非视觉问题</strong>。</li></ul></li></ul><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><ul><li><p><strong>Residual Representations</strong></p><ul><li><p>image recognition</p><p>  VLAD[引]、Fisher Vector[引]、encoding residual vectors[引]</p></li><li><p>low-level vision and computer graphics</p><p>  Multigrid method[引]、hierarchical basis preconditioning[引]、</p></li></ul></li><li><p><strong>Shortcut Connections</strong></p><ul><li><p>some practices and theories of shortcut connections</p><p>  具体看引文</p></li><li><p>comparison with the shortcut connections with gating functions（shortcut connections with gating functions）</p></li></ul></li></ul><h1 id="3-Deep-Residual-Learning"><a href="#3-Deep-Residual-Learning" class="headerlink" title="3. Deep Residual Learning"></a>3. Deep Residual Learning</h1><h2 id="3-1-Residual-Learning"><a href="#3-1-Residual-Learning" class="headerlink" title="3.1. Residual Learning"></a>3.1. Residual Learning</h2><p>假设某几个连续的层（并非必须是整个网络）要拟合的目标是函数H(x)，x是其中第1层的输入。<strong>假设</strong>多个非线性层可以渐近地逼近复杂函数（该假设还有待讨论，详见引文），则等效于假设它们可以渐近地近似残差函数，即F(x)=H(x)-x（假设输入和输出的维数相同）。<strong>虽然H(x)和F(x)+x形式相同， 但学习成本是不同的。</strong>这种重构的思路来源于原文图1所示的the degradation problem，其指出深度模型在通过多个层拟合identity mappings时遇到了问题。通过重构，训练师使参数趋于0会更容易。</p><p>在真实情况中，<strong>虽然identity mappings并不一定是最优解，但该思路还是可能对the degradation problem进行了precondition</strong>。相对于1个zero mapping，如果最优解更接近于identity mappings，那么参考identity mappings做扰动应该比从头学习1个新的函数要更容易。本文通过<strong>实验（图7）</strong>表明，学习到的残差函数通常具有较小的响应（small responses），这表明identity mappings提供了合理的precondition。</p><h2 id="3-2-Identity-Mapping-by-Shortcuts"><a href="#3-2-Identity-Mapping-by-Shortcuts" class="headerlink" title="3.2. Identity Mapping by Shortcuts"></a>3.2. Identity Mapping by Shortcuts</h2><p>每几个层都进行residual learning，形成1个具有多层的block（见原文图2）。图2所示的block有2层，其公式（式1）为$y=F(x,\{W_i\})+x=\sigma(W_2\sigma(W_1x+b_1)+b)$，其中$\sigma$是ReLU。</p><p>F(x)+x通过shortcut connection实现，即保存输入x然后和输出F(x)相加得到F(x)+x，并且使用的这种shortcut connection并不增加参数和计算量（仅增加了微不足道的element-wise addition）。</p><p>在式1中，F(x)和x的通道数必须是一样的，否则就需要在shortcut connections中对x进行1个线性投影（<strong>linear projection</strong>）以匹配维度，即式2：$y=F(x,\{W_i\})+W_sx$，其中$W_s$仅被用来匹配F(x)的维度。</p><p>每个block中可以有更多层，比如3（如图5所示的BottleNeck），但如果每个block中只有1层的话，公式就变成了1个线性层$y = W_1x+x$。</p><p>这种block也适用于卷积层，其中F(x)+x是每个维度对应位置元素相加。</p><h2 id="3-3-Network-Architectures"><a href="#3-3-Network-Architectures" class="headerlink" title="3.3. Network Architectures"></a>3.3. Network Architectures</h2><ul><li><p><strong>Plain Network</strong></p><p>  根据VGG网络的理论，主要使用3×3卷积并遵守2个设计原则：①若输出特征图的尺寸不变，则通道数也应不变；②若输出特征的尺寸减半，则通道数应增1倍以保留时间复杂度。</p><p>  本文直接通过步长为2的卷积层进行下采样，网络尾部是1个global average pooling layer和1个1000-way fully-connected layer with softmax，共有34层权重（图3中间的网络）。</p><p>  该模型中的通道比VGG网络更少，有更低的复杂度，FLOPS是VGG19的18%。</p></li><li><p><strong>Residual Network</strong></p><p>  基于上述Plain Network，添加shortcut connections（图3右边的网络），形成ResNet34。</p><p>  对于identity shortcut，当输出和输入的通道数相同时（<strong>实线</strong>），就直接每个通道对应位置元素相加；</p><p>  当输出的通道数大于输入时（<strong>虚线</strong>），有2个方法：①The shortcut still performs identity mapping, with extra zero entries padded for increasing dimensions. ②通过式2表示的projection shortcut匹配通道（以1×1卷积实现）。对于这2个方法，当输出和输入的尺寸不同时，这是通过步长为2实现（尺寸减半，通道数对应增加1倍）的。</p></li></ul><h2 id="3-4-Implementation"><a href="#3-4-Implementation" class="headerlink" title="3.4. Implementation"></a>3.4. Implementation</h2><p>在ImageNet上</p><p>按照引文41，将图片根据短边随机缩放到[256,480]。随机224×224 crop，随机水平翻转，减去像素均值。</p><p>按照引文21，每个卷积后和每个激活函数前使用bacth normalization。</p><p>按照引文13，初始化模型参数。</p><p>从头训练，SGD，mini-batch大小为256，学习率从0.1开始当loss稳定时除以10，训练了60W个iteration。</p><p>weight decay 0.0001，momentum 0.9。</p><p>不使用dropout。</p><h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h1><h2 id="4-1-ImageNet-Classification"><a href="#4-1-ImageNet-Classification" class="headerlink" title="4.1. ImageNet Classification"></a>4.1. ImageNet Classification</h2><ul><li><p><strong>Plain Networks</strong></p><p>  略</p></li><li><p><strong>Residual Networks</strong></p><p>  略</p></li><li><p><strong>Deeper Bottleneck Architectures</strong></p><p>  考虑到可接受的训练时长，使用Bottleneck（图5所示），每个block中包含3个层：1×1卷积、3×3卷积、1×1卷积，其中2个1×1卷积分别用来减少和恢复维度，使得3×3卷积接收和输出更少的通道数。</p><p>  不需额外参数的identity shortcuts对于Bottleneck非常重要，如果把Bottleneck中的identity shortcut换成projection，模型的时间复杂度和参数量就会增加1倍，因为shortcut连接到了2个高维特征上。所以identity shortcuts使得基于Bottleneck的模型更加有效。</p></li><li><p><strong>50-layer ResNet</strong></p><p>  ResNet50，将ResNet34中包含2层的block换成Bottleneck，就得到了ResNet50。当输出的通道数大于输入时，使用第2种方法（式2）。</p></li><li><p>略……</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;论文名称&lt;/p&gt;
&lt;p&gt;  Deep Residual Learning for
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="论文笔记" scheme="https://chouxianyu.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ResNet" scheme="https://chouxianyu.github.io/tags/ResNet/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-6.4学习率调整方法</title>
    <link href="https://chouxianyu.github.io/2021/02/15/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-6-4%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E6%95%B4%E6%96%B9%E6%B3%95/"/>
    <id>https://chouxianyu.github.io/2021/02/15/李宏毅机器学习课程笔记-6-4学习率调整方法/</id>
    <published>2021-02-15T04:18:25.000Z</published>
    <updated>2021-02-15T04:19:24.329Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>2013年Hinton在Coursera提出。</p><ul><li><p>背景</p><p>  RMSProp是Adagrad的升级版。</p><p>  在训练神经网络时，损失函数不一定是凸函数（局部最小值即为全局最小值），可能是各种各样的函数，有时需要较大的学习率，有时需要较小的学习率，而Adagrad并不能实现这种效果，因此产生了RMSProp。</p></li><li><p>定义</p><script type="math/tex; mode=display">  w^{t+1}=w^t-\frac{\eta}{\sigma^t}g^t\\  \sigma^0=g^0,\sigma^t=\sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}</script><p>  其中$w$是某个参数；$\eta$是学习率；$g$是梯度；$\alpha$代表旧的梯度的重要性，值越小则旧的梯度越不重要。</p></li><li><p>神经网络中很难找到最优的参数吗？</p><p>  面临的问题有plateau、saddle point和local minima。</p><p>  |     英文     |    中文    |                  梯度                   |<br>  | :—————: | :————: | :——————————————————-: |<br>  |   plateau    |   停滞期   | $\frac{\partial L}{\partial w}\approx0$ |<br>  | saddle point |    鞍点    |    $\frac{\partial L}{\partial w}=0$    |<br>  | local minima | 局部最小值 |    $\frac{\partial L}{\partial w}=0$    |</p><p>  2007年有人（名字读音好像是young la ken）指出神经网络的error surface是很平滑的，没有很多局部最优。</p><p>  假设有1000个参数，一个参数处于局部最优的概率是$p$，则整个神经网络处于局部最优的概率是$p^{1000}$，这个值是很小的。</p></li></ul><h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p>1986年提出</p><ul><li><p>如何处理停滞期、鞍点、局部最小值等问题？</p><p>  考虑现实世界中物体具有惯性、动量（Momentum）的特点，尽可能避免“小球”陷入error surface上的这几种位置。</p></li><li><p>定义</p><p>  如下图所示，不仅考虑当前的梯度，还考虑上一次的移动方向：$v^t=\lambda v^{t-1}-\eta g^t,v^0=0$，</p><p>  其中上标$t$是迭代次数；$v$指移动方向（movement），类似于物理中的速度；$g$是梯度（gradient）；$\lambda$用来控制惯性的重要性，值越大代表惯性越重要；$\eta$是学习率。</p><p>  <img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201216171725468-884779641.jpg" alt="Momentum"></p></li></ul><h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>RMSProp+Momentum+Bias Correction，2015年提出</p><h2 id="Adam-VS-SGDM"><a href="#Adam-VS-SGDM" class="headerlink" title="Adam VS SGDM"></a>Adam VS SGDM</h2><p>目前常用的就是Adam和SGDM。</p><p>Adam训练速度快，large generalization gap（在训练集和验证集上的性能差异大），但不稳定；SGDM更稳定，little generalization gap，更加converge（收敛）。</p><div class="table-container"><table><thead><tr><th style="text-align:center">领域</th><th style="text-align:center">技术/模型</th><th style="text-align:center">优化器</th></tr></thead><tbody><tr><td style="text-align:center">Q&amp;A、文意理解、文章生成</td><td style="text-align:center">BERT</td><td style="text-align:center">Adam</td></tr><tr><td style="text-align:center">BERT的Backbone、翻译</td><td style="text-align:center">Transformer</td><td style="text-align:center">Adam</td></tr><tr><td style="text-align:center">语音生成</td><td style="text-align:center">Tacotron</td><td style="text-align:center">Adam</td></tr><tr><td style="text-align:center">目标检测</td><td style="text-align:center">YOLO</td><td style="text-align:center">SGDM</td></tr><tr><td style="text-align:center">目标检测</td><td style="text-align:center">Mask R-CNN</td><td style="text-align:center">SGDM</td></tr><tr><td style="text-align:center">图片分类</td><td style="text-align:center">ResNet</td><td style="text-align:center">SGDM</td></tr><tr><td style="text-align:center">图片生成</td><td style="text-align:center">Big-GAN</td><td style="text-align:center">Adam</td></tr><tr><td style="text-align:center">元学习</td><td style="text-align:center">MAML</td><td style="text-align:center">Adam</td></tr></tbody></table></div><p>SGDM适用于计算机视觉，Adam适用于NLP、Speech Synthesis、GAN、Reinforcement Learning。</p><h2 id="SWATS"><a href="#SWATS" class="headerlink" title="SWATS"></a>SWATS</h2><p>2017年提出，尝试把Adam和SGDM结合，其实就是前一段时间用Adam，后一段时间用SGDM，但在切换时需要解决一些问题。</p><h2 id="尝试改进Adam"><a href="#尝试改进Adam" class="headerlink" title="尝试改进Adam"></a>尝试改进Adam</h2><ul><li><p>AMSGrad</p><ul><li><p>Adam的问题</p><blockquote><p>Non-informative gradients contribute more than informative gradients.</p></blockquote><p>  在Adam中，之前所有的梯度都会对第$t$步的movement产生影响。然而较早阶段(比如第1、2步)的梯度信息是相对无效的，较晚阶段（比如$t-1$、$t-2$步）的梯度信息是相对有效的。在Adam中，可能发生较早阶段梯度相对于较晚阶段梯度比重更大的问题。</p></li><li><p>提出AMSGrad</p><p>  2018年提出</p></li></ul></li><li><p>AdaBound</p><p>  2019年提出，目的也是改进Adam。</p></li><li><p>Adam需要warm up吗？需要</p><p>  warm up：开始时学习率小，后面学习率大。</p><p>  因为实验结果说明在刚开始的几次（大概是10次）迭代中，参数值的分布比较散乱（distort），因此梯度值就比较散乱，导致梯度下降不稳定。</p></li><li><p>RAdam</p><p>  2020年提出</p></li><li><p>Lookahead</p><p>  2019年提出，像一个wrapper一样套在优化器外面，适用于Adam、SGDM等任何优化器。</p><p>  迭代几次后会回头检查一下。</p></li><li><p>Nadam</p><p>  2016年提出，把NAG的概念应用到Adam上。</p></li><li><p>AdamW</p><p>  2017年提出，这个优化器还是有重要应用的（训练出了某个BERT模型）。</p></li></ul><h2 id="尝试改进SGDM"><a href="#尝试改进SGDM" class="headerlink" title="尝试改进SGDM"></a>尝试改进SGDM</h2><ul><li><p>LR range test</p><p>  2017年提出</p></li><li><p>Cyclical LR</p><p>  2017年提出</p></li><li><p>SGDR</p><p>  2017年提出，模拟Cosine但并不是Cosine</p></li><li><p>One-cycle LR</p><p>  2017年提出，warm-up+annealing+fine-tuning</p></li><li><p>SGDW</p><p>  2017年提出，</p></li></ul><h2 id="改进Momentum"><a href="#改进Momentum" class="headerlink" title="改进Momentum"></a>改进Momentum</h2><ul><li><p>背景</p><p>如果梯度指出要停下来，但动量说要继续走，这样可能导致坏的结果。</p></li><li><p>NAG（Nesterov accelerated gradient）</p><p>  1983年提出，会预测下一步。</p></li></ul><h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h2><p>如果学习率调整得较好，随着迭代次数增加，神经网络在训练集上的loss会越来越小，但因为验证集（Validation set）和训练集不完全一样，所以神经网络在验证集上的loss可能不降反升，所以我们应该在神经网络在验证集上loss最小时停止训练。</p><p><a href="https://keras.io/getting_started/faq/#how-can-i-interrupt-training-when-the-validation-loss-isnt-decreasing-anymore" target="_blank" rel="noopener">Keras文档</a>中就有关于Early stopping的说明。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RMSProp&quot;&gt;&lt;a href=&quot;#RMSProp&quot; class=&quot;headerlink&quot; title=&quot;RMSProp&quot;&gt;&lt;/a&gt;RMSProp&lt;/h2&gt;&lt;p&gt;2013年Hinton在Coursera提出。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;背景&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="学习率" scheme="https://chouxianyu.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-6.3常用激活函数</title>
    <link href="https://chouxianyu.github.io/2021/02/15/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-6-3%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>https://chouxianyu.github.io/2021/02/15/李宏毅机器学习课程笔记-6-3常用激活函数/</id>
    <published>2021-02-15T03:59:27.000Z</published>
    <updated>2021-02-15T04:01:05.856Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h2 id="梯度消失（Vanishing-Gradient-Problem）"><a href="#梯度消失（Vanishing-Gradient-Problem）" class="headerlink" title="梯度消失（Vanishing Gradient Problem）"></a>梯度消失（Vanishing Gradient Problem）</h2><ul><li><p>定义</p><p>  1980年代常用的激活函数是sigmoid函数。以MNIST手写数字识别为例，在使用sigmoid函数时会发现随着神经网络层数增加，识别准确率逐渐下降，这个现象的原因并不是过拟合（原因见上文），而是梯度消失。</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201117115824VanishingGradientProblem.jpg" alt="VanishingGradientProblem"></p><p>  如上图所示，当神经网络层数很多时，靠近输入层的参数的梯度会很小，靠近输出层的参数的梯度会很大。当每个参数的学习率相同时，靠近输入层的参数会更新得很慢，靠近输出层的几层参数会更新得很快。所以，当靠近输入层的参数几乎还是随机数时，靠近输出层的参数已经收敛了。</p></li><li><p>原因</p><p>  按照反向传播的式子，这确实是会发生的。</p><p>  直观感觉上，sigmoid函数输入的范围是无穷大，但输出的范围是[0,1]，也就是说sigmoid函数减弱了输入变化导致输出变化的幅度。那为什么靠近输出层的参数的梯度更大呢？sigmoid函数是一层层叠起来的，不断地减弱靠近输入层的参数的变化导致输出变化的幅度，所以更靠后的参数的梯度越大。</p></li><li><p>解决方法</p><p>  Hinton提出无监督逐层训练方法以解决这个问题，其基本思想是每次训练一层隐节点。</p><p>  后来Hinton等人提出修改激活函数，比如换成ReLU。</p></li></ul><h2 id="ReLU-Rectified-Linear-Unit"><a href="#ReLU-Rectified-Linear-Unit" class="headerlink" title="ReLU(Rectified Linear Unit)"></a>ReLU(Rectified Linear Unit)</h2><ul><li><p>定义</p><p>  当输入小于等于0时，输出为0；当输入大于0时，输出等于输入。</p></li><li><p>优点</p><p>  相比于sigmoid函数，它有以下优点</p><ol><li>运算更快</li><li>更符合生物学</li><li>等同于无穷多个bias不同的sigmoid函数叠加起来</li><li>可以解决梯度消失问题</li></ol></li><li><p>如何解决梯度消失问题</p><p>  当ReLU输出为0时该激活函数对神经网络不起作用，所以在神经网络中生效的激活函数都是输出等于输入，所以就不会出现sigmoid函数导致的减弱输入变化导致输出变化的幅度的情况。</p></li><li><p>ReLU会使整个神经网络变成线性的吗？</p><p>  可知有效的激活函数都是线性的，但整个神经网络还是非线性的。当输入改变很小、不改变每个激活函数的Operation Region（操作区域，大概意思就是输入范围）时，整个神经网络是线性的；当输入改变很大、改变了Operation Region时，整个神经网络就是非线性的。==目前我是凭直觉理解这一点，还未细究==</p></li><li><p>ReLU可以做微分吗？</p><p>  不用处理输入为0的情况，当输入小于0时，微分就是0，当输入大于0时微分就是1。</p></li></ul><h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h2><p>当输入小于等于0时，输出为输入的0.01倍；当输入大于0时，输出等于输入。</p><h2 id="Parametric-ReLU"><a href="#Parametric-ReLU" class="headerlink" title="Parametric ReLU"></a>Parametric ReLU</h2><p>当输入小于等于0时，输出为输入的$\alpha$倍；当输入大于0时，输出等于输入。</p><p>其中$\alpha$是通过梯度下降学习到的参数</p><h2 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h2><ul><li><p>定义</p><p>  通过学习得到一个激活函数，人为将每层输出的多个值分组，然后输出每组值中的最大值。（跟maxpooling一模一样）</p></li><li><p>ReLU是Maxout的一个特例</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201216075138Maxout1.png" alt="Maxout1"></p></li><li><p>Maxout比ReLU包含了更多的函数</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201216075144Maxout2.jpg" alt="Maxout2"></p></li><li><p>Maxout可以得到任意的分段线性凸函数（piecewise linear convex），有几个分段取决于每组里有几个值</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201216075148Maxout3.jpg" alt="Maxout3"></p></li><li><p>如何训练Maxout</p><p>  Maxout只是选择输出哪一个线性函数的值而已，因此Maxout激活函数还是线性的。</p><p>  因为在多个值中只选择最大值进行输出，所以会形成一个比较瘦长/窄深的神经网络。</p><p>  在多个值中只选择最大值进行输出，这并不会导致一些参数无法被训练：因为输入不同导致一组值中的最大值不同，所以各个参数都可能被训练到。</p><p>  当输入不同时，形成的也是不同结构的神经网络。</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h2 id=&quot;梯度消失（Vanishing-Gradient-Problem）&quot;&gt;&lt;a href=&quot;#梯度消失（Vanishing-Gradient-Problem）&quot; class=&quot;headerlink&quot; title=&quot;梯度消失（Vanishing 
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="梯度消失" scheme="https://chouxianyu.github.io/tags/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/"/>
    
      <category term="激活函数" scheme="https://chouxianyu.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-6.2神经网络精度低不一定是因为过拟合</title>
    <link href="https://chouxianyu.github.io/2021/02/10/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-6-2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B2%BE%E5%BA%A6%E4%BD%8E%E4%B8%8D%E4%B8%80%E5%AE%9A%E6%98%AF%E5%9B%A0%E4%B8%BA%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    <id>https://chouxianyu.github.io/2021/02/10/李宏毅机器学习课程笔记-6-2神经网络精度低不一定是因为过拟合/</id>
    <published>2021-02-10T04:59:34.000Z</published>
    <updated>2021-02-10T05:00:13.727Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>相比于决策树等方法，神经网络更不容易过拟合。</p><p>  K近邻、决策树等方法在训练集上更容易得到100%等很高的正确率，神经网络一般不能，训练神经网络首先遇到的问题一般是在训练集上的精度不高。</p></li><li><p>不要总是把精度低归咎于过拟合</p><p>  如果模型在训练集上精度高，对于K近邻、决策树等方法我们可以直接判断为过拟合，但对于神经网络来说我们还需要检查神经网络在测试集上的精度。<strong>如果神经网络在训练集上精度高但在测试集上精度低，这才说明神经网络过拟合了</strong>。</p><p>  如果56层的神经网络和20层的神经网络相比，56层网络在测试集上的精度低于20层网络，这还不能判断为56层网络包含了过多参数导致过拟合。一般来讲，56层网络优于20层网络，但如果我们发现56层网络在训练集上的精度本来就低于20层网络，那原因可能有很多而非过拟合，比如56层网络没训练好导致一个不好的局部最优、虽然56层网络的参数多但结构有问题等等。</p><p>  感兴趣可以看看ResNet论文<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a>，这篇论文可能与该问题有关。</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;相比于决策树等方法，神经网络更不容易过拟合。&lt;/p&gt;
&lt;p&gt;  K近邻、决策树等方法在训练集上更容易得到100%等很高的正确率，神经网络一般不能，训练神经网络首先遇到的问题一般是在训练集上的精度不高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;不要总是把精度低归咎
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="过拟合" scheme="https://chouxianyu.github.io/tags/%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-6.1神经网络训练问题与解决方案</title>
    <link href="https://chouxianyu.github.io/2021/02/09/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-6-1%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://chouxianyu.github.io/2021/02/09/李宏毅机器学习课程笔记-6-1神经网络训练问题与解决方案/</id>
    <published>2021-02-09T10:36:07.000Z</published>
    <updated>2021-02-09T10:56:28.190Z</updated>
    
    <content type="html"><![CDATA[<h2 id="明确问题类型及其对应方法"><a href="#明确问题类型及其对应方法" class="headerlink" title="明确问题类型及其对应方法"></a>明确问题类型及其对应方法</h2><p>在深度学习中，一般有两种问题：</p><ol><li>在训练集上性能不好</li><li>在测试集上性能不好。</li></ol><p>当一个方法被提出时，它往往是针对这两个问题其中之一的，比如dropout方法是用来处理在测试集上性能不好的情况。</p><h2 id="处理神经网络在训练集上性能不好的情况的方法"><a href="#处理神经网络在训练集上性能不好的情况的方法" class="headerlink" title="处理神经网络在训练集上性能不好的情况的方法"></a>处理神经网络在训练集上性能不好的情况的方法</h2><ul><li><p>修改神经网络架构，比如换成更好的激活函数</p><p>  sigmoid函数会导致梯度消失，可以换成ReLU、Leaky ReLU、Parametric ReLU、Maxout</p></li><li><p>调整学习率</p><p>  比如RMSProp、Momentum、Adam</p></li></ul><h2 id="处理神经网络在测试集上性能不好的情况的方法"><a href="#处理神经网络在测试集上性能不好的情况的方法" class="headerlink" title="处理神经网络在测试集上性能不好的情况的方法"></a>处理神经网络在测试集上性能不好的情况的方法</h2><ul><li><p>Early Stopping、Regularization，这两个是比较传统的方法，不只适用于深度学习</p></li><li><p>Dropout，比较有深度学习的特色</p></li></ul><h2 id="一些性能优化方法的简介"><a href="#一些性能优化方法的简介" class="headerlink" title="一些性能优化方法的简介"></a>一些性能优化方法的简介</h2><p>下面3点都是在增加模型的随机性，鼓励模型做更多的exploration。</p><ul><li><p>Shuffling</p><p>  输入数据的顺序不要固定，mini-batch每次要重新生成</p></li><li><p>Dropout</p><p>  鼓励每个神经元都学到东西，也可以广义地理解为增加随机性</p></li><li><p>Gradient noise</p><p>  2015年提出，计算完梯度后，加上Gaussian noise。</p><p>  随着迭代次数增加，noise应该逐渐变小。</p></li></ul><p>下面3点是关于学习率调整的技巧</p><ul><li><p>warm up</p><p>  开始时学习率较小，等稳定之后学习率变大</p></li><li><p>Curriculum learning</p><p>  2009年提出，先使用简单的数据训练模型（一方面此时模型比较弱，另一方面在clean data中更容易提取到核心特征），然后再用难的数据训练模型。</p><p>  这样可以提高模型的鲁棒性。</p></li><li><p>Fine-tuning</p></li></ul><p>下面3点是关于数据预处理的技巧，避免模型学习到太极端的参数</p><ul><li><p>Normalization</p><p>  有Batch Normalization、Instance Normalization、Group Normalization、Layer Normalization、Positional Normalization</p></li><li><p>Regularization</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;明确问题类型及其对应方法&quot;&gt;&lt;a href=&quot;#明确问题类型及其对应方法&quot; class=&quot;headerlink&quot; title=&quot;明确问题类型及其对应方法&quot;&gt;&lt;/a&gt;明确问题类型及其对应方法&lt;/h2&gt;&lt;p&gt;在深度学习中，一般有两种问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="正则化" scheme="https://chouxianyu.github.io/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
      <category term="学习率" scheme="https://chouxianyu.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%8E%87/"/>
    
      <category term="激活函数" scheme="https://chouxianyu.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
      <category term="Dropout" scheme="https://chouxianyu.github.io/tags/Dropout/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1055The World&#39;s Richest</title>
    <link href="https://chouxianyu.github.io/2021/02/05/PAT%E7%94%B2%E7%BA%A71055The-World-s-Richest/"/>
    <id>https://chouxianyu.github.io/2021/02/05/PAT甲级1055The-World-s-Richest/</id>
    <published>2021-02-05T11:32:24.000Z</published>
    <updated>2021-02-10T05:06:52.780Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805421066272768" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805421066272768</a></p></li><li><p>题目考点</p><p>  排序，重点在时间复杂度优化上</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><p>  给出N个人，请找出指定年龄范围内最有钱的M个人、</p></li><li><p>输入</p><ul><li>N：正整数，不超过100000，人的数量</li><li>K：正整数，不超过1000，查询的数量</li><li>N个人：每行包括名字（不包含空格、最多8个字符的字符串）、年龄（范围<code>(0,200]</code>）、净值（范围为±1e6）</li><li>K次查询：M（筛选最有钱的几个人，不超过100）、年龄范围<code>[Amin,Amax]</code></li></ul></li><li><p>输出</p><p>  对于每1个查询，输出是第几个查询（从1到K），然后按净值非增序输出指定年龄范围内最有钱的M个人的信息，如果有重复则按年龄非降序输出，如果还有重复则按名字非降序输出。如果指定年龄范围内没人，就输出<code>None</code>。</p></li></ul><h1 id="题解一"><a href="#题解一" class="headerlink" title="题解一"></a>题解一</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>关于指定年龄范围，只要在输出时进行年龄判断即可。</p><p>  也可以考虑在结构体比较函数中进行年龄判断，当有不符合年龄限制的人时，将其往后放。</p></li><li><p>关于最有钱的人的数量，排序后只输出前M个符合年龄范围的人即可。</p></li><li><p><strong>用这个思路，测试点1和2会超时</strong>，因为这个算法的时间复杂度为$O(k\cdot n)$，最大为1e8（耗时约1秒）。</p><p>  M最大值为100，N最大值为100000，N和M差距很大，在N个人中寻找符合条件的M个人非常耗时。</p></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1055</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805421066272768</span></span><br><span class="line"><span class="comment">// Tags: 排序</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> ageMin, ageMax;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">    <span class="keyword">int</span> age, wealth;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">personCmp</span><span class="params">(Person&amp; p1, Person&amp; p2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p1.age&lt;ageMin || p1.age&gt;ageMax)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (p2.age&lt;ageMin || p2.age&gt;ageMax)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span> (p1.wealth == p2.wealth)&#123;</span><br><span class="line">        <span class="keyword">if</span> (p1.age == p2.age)</span><br><span class="line">            <span class="keyword">return</span> p1.name &lt; p2.name;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> p1.age &lt; p2.age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> p1.wealth &gt; p2.wealth;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n,k;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d %d"</span>, &amp;n, &amp;k);</span><br><span class="line">    <span class="built_in">vector</span>&lt;Person&gt; people(n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; people[i].name &gt;&gt; people[i].age &gt;&gt; people[i].wealth;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> x=<span class="number">1</span>, m; x&lt;=k; x++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d%d%d"</span>, &amp;m, &amp;ageMin, &amp;ageMax);</span><br><span class="line">        sort(people.begin(), people.end(), personCmp);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Case #%d:\n"</span>, x);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n &amp;&amp; count&lt;m; i++)</span><br><span class="line">            <span class="keyword">if</span> (people[i].age&gt;=ageMin &amp;&amp; people[i].age&lt;=ageMax)&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"%s %d %d\n"</span>, people[i].name.c_str(), people[i].age, people[i].wealth);</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"None\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="题解二"><a href="#题解二" class="headerlink" title="题解二"></a>题解二</h1><h2 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li>年龄范围是<code>(0,200]</code>，每次最多找100个人（M不超过100），那我们取出每个年龄的前100名，这样最多有20000个人。在这20000个人中查找M个人，还是快的（时间复杂度从题解一的1e8到现在的2e7），就不会超时了。</li></ul><h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1055</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805421066272768</span></span><br><span class="line"><span class="comment">// Tags: 排序</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> ageMin, ageMax;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">    <span class="keyword">int</span> age, wealth;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">personCmp</span><span class="params">(Person&amp; p1, Person&amp; p2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p1.wealth == p2.wealth)&#123;</span><br><span class="line">        <span class="keyword">if</span> (p1.age == p2.age)</span><br><span class="line">            <span class="keyword">return</span> p1.name &lt; p2.name;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> p1.age &lt; p2.age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> p1.wealth &gt; p2.wealth;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n,k, selectedNum[<span class="number">201</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d %d"</span>, &amp;n, &amp;k);</span><br><span class="line">    <span class="built_in">vector</span>&lt;Person&gt; people(n), selectedPeople;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; people[i].name &gt;&gt; people[i].age &gt;&gt; people[i].wealth;</span><br><span class="line">    sort(people.begin(), people.end(), personCmp);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="keyword">if</span> (selectedNum[people[i].age] &lt; <span class="number">100</span>)&#123;</span><br><span class="line">            selectedPeople.push_back(people[i]);</span><br><span class="line">            selectedNum[people[i].age]++;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> x=<span class="number">1</span>, m; x&lt;=k; x++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d%d%d"</span>, &amp;m, &amp;ageMin, &amp;ageMax);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Case #%d:\n"</span>, x);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;selectedPeople.size() &amp;&amp; count&lt;m; i++)</span><br><span class="line">            <span class="keyword">if</span> (selectedPeople[i].age&gt;=ageMin &amp;&amp; selectedPeople[i].age&lt;=ageMax)&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"%s %d %d\n"</span>, selectedPeople[i].name.c_str(), selectedPeople[i].age, selectedPeople[i].wealth);</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"None\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/liuchuo/article/details/52225204" target="_blank" rel="noopener">https://blog.csdn.net/liuchuo/article/details/52225204</a></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
      <category term="排序" scheme="https://chouxianyu.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1028List Sorting</title>
    <link href="https://chouxianyu.github.io/2021/02/05/PAT%E7%94%B2%E7%BA%A71028List-Sorting/"/>
    <id>https://chouxianyu.github.io/2021/02/05/PAT甲级1028List-Sorting/</id>
    <published>2021-02-05T07:07:53.000Z</published>
    <updated>2021-02-05T07:10:13.346Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805468327690240" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805468327690240</a></p></li><li><p>题目考点</p><p>  结构体排序，就超简单……</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><p>  Excel可以按照某一列进行排序，要求实现这个函数。</p></li><li><p>输入</p><ul><li>N：整数，不超过100000，记录的数量</li><li>C：整数，按照C这1列进行排序</li><li>N个学生：每行包括学生ID（6位数字），名字（不包含空格、不超过8个字符的字符串），分数（范围[0,100]）</li></ul></li><li><p>输出</p><p>  输出N个学生。如果C=1则按照ID升序排列；如果C=2则按照名字非降序排列；如果C=3则按照分数非降序。如果名字或分数重复就按ID增序排列。</p></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li>啊这（问号脸，这么简单？），学生放在vector里，写个结构体排序函数（把C定义成全局变量，在排序函数里根据C选取排序规则），调用STL里的sort就好了。</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1028</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805468327690240</span></span><br><span class="line"><span class="comment">// Tags: </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> c;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> id, name;</span><br><span class="line">    <span class="keyword">int</span> grade;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">studentCmp</span><span class="params">(Student&amp; s1, Student&amp; s2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (c==<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> s1.id &lt; s2.id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(c==<span class="number">2</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> s1.name==s2.name? s1.id &lt; s2.id : s1.name &lt; s2.name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s1.grade==s2.grade? s1.id &lt; s2.id : s1.grade &lt; s2.grade;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d%d"</span>, &amp;n, &amp;c);</span><br><span class="line">    <span class="built_in">vector</span>&lt;Student&gt; students(n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; students[i].id &gt;&gt; students[i].name &gt;&gt; students[i].grade;</span><br><span class="line">    sort(students.begin(), students.end(), studentCmp);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> it=students.begin(); it!=students.end(); it++)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%s %s %d\n"</span>, it-&gt;id.c_str(), it-&gt;name.c_str(), it-&gt;grade);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
      <category term="排序" scheme="https://chouxianyu.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1025PAT Ranking</title>
    <link href="https://chouxianyu.github.io/2021/02/02/PAT%E7%94%B2%E7%BA%A71025PAT-Ranking/"/>
    <id>https://chouxianyu.github.io/2021/02/02/PAT甲级1025PAT-Ranking/</id>
    <published>2021-02-02T13:47:56.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805474338127872" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805474338127872</a></p></li><li><p>题目考点</p><p>  排序、模拟。排序是简单的结构体排序，模拟也不难。这题比较简单（我竟然没看题解做出来了，捂脸）</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><p>  汇总PAT各个考场的ranklist，生成最后的rank</p></li><li><p>输入</p><ul><li><p>N：正数，不超过100，考场的数量</p></li><li><p>N个ranklist：</p><p>  1个ranklist包括：第1个数字是K（正整数，不超过300，考生数量），然后K行，每行包括注册号（13位数字）和考生总分</p></li></ul></li><li><p>输出</p><ul><li><p>考生总数</p></li><li><p>最终的ranklist：包括注册号、final rank、考场号（索引为<code>[1,N]</code>）、考场中排名</p><p>  先按final rank非降序输出，再按注册号非降序输出。</p></li></ul></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>每读取1个考场的考生数据，就将其存入该考场的vector，然后排序计算local rank，再存入保存所有考生的vector，最后把所有考生排序，计算final rank，输出。</p></li><li><p>要根据分数排序，输出时还要根据排名和注册号排序</p><p>  后者已经包括了前者，因为rank升序就是分数降序，所以写一个排序函数就行了。</p></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1025</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805474338127872</span></span><br><span class="line"><span class="comment">// Tags: 排序 模拟</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Testee</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> id;</span><br><span class="line">    <span class="keyword">int</span> location, score, rank[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">    Testee()&#123;&#125;</span><br><span class="line">    Testee(<span class="built_in">string</span> id_, <span class="keyword">int</span> location_, <span class="keyword">int</span> score_)&#123;</span><br><span class="line">        id = id_;</span><br><span class="line">        location = location_;</span><br><span class="line">        score = score_;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; id;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">" %d %d %d\n"</span>, rank[<span class="number">1</span>], location, rank[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">testeeCmp</span><span class="params">(Testee&amp; a, Testee&amp; b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a.score==b.score ? a.id&lt;b.id : a.score&gt;b.score ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">calcRank</span><span class="params">(<span class="built_in">vector</span>&lt;Testee&gt;&amp; testees,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">    testees[<span class="number">0</span>].rank[j] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i &lt; testees.size(); i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (testees[i].score == testees[i<span class="number">-1</span>].score)</span><br><span class="line">            testees[i].rank[j] = testees[i<span class="number">-1</span>].rank[j];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            testees[i].rank[j] = i+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 定义变量</span></span><br><span class="line">    <span class="keyword">int</span> n, k, score;</span><br><span class="line">    <span class="built_in">string</span> id;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;n);</span><br><span class="line">    <span class="built_in">vector</span>&lt;Testee&gt; allTestees;</span><br><span class="line">    <span class="comment">// 读取输入，并计算local rank，将不同考场的考生保存到同1个vector里</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; i++)&#123; <span class="comment">// 遍历考场</span></span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;k);</span><br><span class="line">        <span class="built_in">vector</span>&lt;Testee&gt; localTestees(k);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;k; j++)&#123; <span class="comment">// 读取考生信息</span></span><br><span class="line">            <span class="built_in">cin</span> &gt;&gt; localTestees[j].id &gt;&gt; localTestees[j].score;</span><br><span class="line">            localTestees[j].location = i;</span><br><span class="line">        &#125;</span><br><span class="line">        sort(localTestees.begin(), localTestees.end(), testeeCmp);</span><br><span class="line">        calcRank(localTestees, <span class="number">0</span>); <span class="comment">// 计算该考场考生的local rank</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;k; j++) <span class="comment">// 将不同考场的考生保存到一个vector里</span></span><br><span class="line">            allTestees.push_back(localTestees[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算final rank</span></span><br><span class="line">    sort(allTestees.begin(), allTestees.end(), testeeCmp);</span><br><span class="line">    calcRank(allTestees, <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 输出结果</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, allTestees.size());</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; allTestees.size(); i++)&#123;</span><br><span class="line">        allTestees[i].display();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
      <category term="排序" scheme="https://chouxianyu.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1016Phone Bills</title>
    <link href="https://chouxianyu.github.io/2021/02/02/PAT%E7%94%B2%E7%BA%A71016Phone-Bills/"/>
    <id>https://chouxianyu.github.io/2021/02/02/PAT甲级1016Phone-Bills/</id>
    <published>2021-02-02T05:00:04.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805493648703488" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805493648703488</a></p></li><li><p>题目考点</p><p>map、排序、模拟。map是简单地用了一下，排序也不难，重在模拟。</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><ul><li>长途电话每分钟收取一定费用，收费金额取决于拨打电话的时间。每次电话的开始时间和结束时间都会被记录，给出一系列通话记录，请生成每个月的账单。</li></ul></li><li><p>输入</p><ul><li>1行24个非负整数：00:00 - 01:00、01:00 - 02:00，以此类推一天中每个小时的收费金额（单位是<code>cents/minute</code>）</li><li>N：正整数，不超过1000，通话记录的数量</li><li>N行通话记录：1行的内容包括客户名称（最多20个字符的字符串，不包含空格）、日期和时间（<code>MM:dd:HH:mm</code>）、1个词（<code>on-line</code>或<code>off-line</code>），这些通话记录都是同一个月的。1个<code>on-line</code>记录与同1客户的时间顺序上的1个<code>off-line</code>记录配对，没有形成pair的通话记录会被忽略。输入中至少会有1个pair。假设同1客户不会有2条时间相同的记录。输入中时间的格式为24小时制。</li></ul></li><li><p>输出</p><p>  按客户名称的字母表顺序为每1个客户输出账单。对于每1个客户来说，要输出其名字、账单的月份、每条通话记录（包括开始时间、结束时间、通话分钟数、收费金额，要按时间顺序输出多条通话记录）、账单总金额</p></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>找到pair，生成通话记录</p><p>  先根据时间排序，然后判断是否形成pair（时间顺序、同用户、onLine和offLine）</p></li><li><p><strong>计算1次通话的费用，还有总费用</strong></p><p>  可以从0开始计算（需要先对收费金额进行处理），这样计算更容易。<code>on-line</code>和<code>off-line</code>2个时间点，计算0点到这2个时间点一直通话的收费，取差额即为应该支付的费用。</p></li><li><p>确定月份</p><p>  输出时取第1个记录的月份</p></li><li><p>客户名字字典序</p><p>  map实现（也可以通过结构体排序实现）</p></li><li><p>Record时间序输出</p><p>  通过结构体排序实现</p></li><li><p><strong>读取输入时不一定要保存原信息</strong></p><p>  比如时间本身是string，我们可以直接记录<code>month</code>、<code>day</code>等，把<code>:</code>等分隔符去除。<code>on-line</code>和<code>off-line</code>是字符串，我们可以用bool表示。</p></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1016</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805493648703488</span></span><br><span class="line"><span class="comment">// Tags: map 排序</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> charge[<span class="number">25</span>];</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Record</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">    <span class="keyword">bool</span> status;</span><br><span class="line">    <span class="keyword">int</span> month, day, hour, minute, time;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setStatus</span><span class="params">(<span class="built_in">string</span>&amp; status)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (status == <span class="string">"on-line"</span>)</span><br><span class="line">            <span class="keyword">this</span>-&gt;status = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;status = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">calcTime</span><span class="params">()</span></span>&#123; <span class="comment">// 以月初为零点的时间</span></span><br><span class="line">        time = day * <span class="number">24</span> * <span class="number">60</span> + hour * <span class="number">60</span> + minute;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">pairWith</span><span class="params">(Record&amp; r)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name == r.name &amp;&amp; status==<span class="literal">true</span> &amp;&amp; r.status==<span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">calcCostFromZero</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">double</span> cost = day * <span class="number">60</span> * charge[<span class="number">24</span>] + minute * charge[hour]; <span class="comment">// 天、分钟</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;hour; i++)&#123; <span class="comment">// 小时</span></span><br><span class="line">            cost += <span class="number">60</span> * charge[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cost / <span class="number">100.0</span>; <span class="comment">// cent换算成美元</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%02d:%02d:%02d "</span>, day, hour, minute);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">recordCmp</span><span class="params">(Record&amp; a, Record&amp; b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a.name == b.name ? a.time &lt; b.time : a.name &lt; b.name;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 读取输入并处理数据</span></span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">24</span>; i++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, charge + i);</span><br><span class="line">        charge[<span class="number">24</span>] += charge[i]; <span class="comment">// charge[24]是1整天都在通话时1天的收费</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;n);</span><br><span class="line">    <span class="built_in">vector</span>&lt;Record&gt; records(n);</span><br><span class="line">    <span class="built_in">string</span> status;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; records[i].name;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d:%d:%d:%d"</span>, &amp;records[i].month, &amp;records[i].day, &amp;records[i].hour, &amp;records[i].minute);</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; status;</span><br><span class="line">        records[i].setStatus(status);</span><br><span class="line">        records[i].calcTime(); <span class="comment">// 以月初为0点</span></span><br><span class="line">    &#125;</span><br><span class="line">    sort(records.begin(), records.end(), recordCmp);</span><br><span class="line">    <span class="comment">// 为每个客户记录订单</span></span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="built_in">vector</span>&lt;Record&gt;&gt; customers;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (records[i<span class="number">-1</span>].pairWith(records[i]))&#123;</span><br><span class="line">            customers[records[i].name].push_back(records[i<span class="number">-1</span>]);</span><br><span class="line">            customers[records[i].name].push_back(records[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> customer=customers.begin(); customer!=customers.end(); customer++)&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; customer-&gt;first;</span><br><span class="line">        records = customer-&gt;second;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">" %02d\n"</span>, records[<span class="number">0</span>].month);</span><br><span class="line">        <span class="keyword">double</span> totalCost = <span class="number">0</span>, cost;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;records.size(); i+=<span class="number">2</span>)&#123;</span><br><span class="line">            cost = records[i].calcCostFromZero() - records[i<span class="number">-1</span>].calcCostFromZero();</span><br><span class="line">            totalCost += cost;</span><br><span class="line">            records[i<span class="number">-1</span>].print();</span><br><span class="line">            records[i].print();</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d "</span>, records[i].time - records[i<span class="number">-1</span>].time);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"$%.02f\n"</span>, cost);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Total amount: $%.02f\n"</span>, totalCost);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/liuchuo/article/details/52294397" target="_blank" rel="noopener">https://blog.csdn.net/liuchuo/article/details/52294397</a></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
      <category term="排序" scheme="https://chouxianyu.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="map" scheme="https://chouxianyu.github.io/tags/map/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1012The Best Rank</title>
    <link href="https://chouxianyu.github.io/2021/01/31/PAT%E7%94%B2%E7%BA%A71012The-Best-Rank/"/>
    <id>https://chouxianyu.github.io/2021/01/31/PAT甲级1012The-Best-Rank/</id>
    <published>2021-01-31T03:09:50.000Z</published>
    <updated>2021-02-03T07:25:45.376Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805502658068480" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805502658068480</a></p></li><li><p>题目考点</p><p>  排序、模拟，重点在模拟而非排序</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><p>  给出多个学生的C语言（C）、数学（M）、英语成绩（E），要求四舍五入计算3门课的均分（A），请在这4个成绩中输出指定同学的best rank。</p></li><li><p>输入</p><ul><li>N：学生的数量，不超过2000</li><li>M：查询的数量，不超过2000</li><li>N个学生的成绩：每行包括学生ID（6个数字组成的string）、C语言成绩、数学成绩、英语成绩</li><li>M个要查询的学生ID</li></ul></li><li><p>输出</p><ul><li>对于要查询的每一个学生，在一行中输出其best rank以及此rank对应的科目</li><li>rank方法为A<code>&gt;</code>C<code>&gt;</code>M<code>&gt;</code>E，如果有1个学生有多个best rank相同，则输出优先级高的那个</li><li>如果查询的学生不存在，输出N/A。</li></ul></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>需要解决的问题</p><ul><li><p>如何求出best rank？</p><p>  要求best rank，就需要先求出每个学生每个科目的rank，然后取最优。</p></li><li><p>ID是6位数字，严格来讲需要用string保存，那如何定义索引进而通过索引获取学生信息？</p></li><li><p>如何实现rank方法的优先级？</p></li><li><p>如何判断学生是否存在？</p></li></ul></li><li><p>注意点</p><ul><li><p>淦，自己的思路卡在怎么处理ID了。大神的思路真的妙，我咋这么笨……</p><p>  思路：<strong>如果ID作为索引并不方便，用map或者数组将ID映射到索引是更好的方法</strong>。</p></li><li><p>关于best rank，我开始想的是进行多次排序，每次排序后更新best rank。</p><p>  如果这么做，因为rank有优先级就需要按照A、C、M、E的顺序排序，这样也是可行的。</p><p>  但我没想到用数组保存多个分数，这样可以通过index来循环，就不用重复写几次排序和rank更新，同时可以在存储/遍历的时候就按照ACME的顺序存储/遍历以简化程序逻辑。这里的关键点是<strong>用数组和循环的方式实现一个操作的多次重复</strong>。</p></li><li><p>排名不能是<code>1,1,2,3,4</code>，应该是<code>1,1,3,4,5</code>。</p></li></ul></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1012</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805502658068480</span></span><br><span class="line"><span class="comment">// Tags: 排序</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> s; <span class="comment">// 课程（Subject）的索引，[0,3]，studentCmp需要使用</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> id;</span><br><span class="line">    <span class="keyword">int</span> score[<span class="number">4</span>]; <span class="comment">// A C M E</span></span><br><span class="line">    <span class="keyword">int</span> rank[<span class="number">4</span>];</span><br><span class="line">    <span class="keyword">int</span> bestSubject;</span><br><span class="line">&#125; students[<span class="number">2000</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">studentCmp</span><span class="params">(Student&amp; a, Student &amp; b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a.score[s] &gt; b.score[s]; <span class="comment">// 从大到小排序</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 读取数据</span></span><br><span class="line">    <span class="keyword">int</span> n, m;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d %d"</span>, &amp;n, &amp;m);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; students[i].id;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d %d %d"</span>, &amp;students[i].score[<span class="number">1</span>], &amp;students[i].score[<span class="number">2</span>], &amp;students[i].score[<span class="number">3</span>]);</span><br><span class="line">        students[i].score[<span class="number">0</span>] = (students[i].score[<span class="number">1</span>] + students[i].score[<span class="number">2</span>] + students[i].score[<span class="number">3</span>])/<span class="number">3.0</span> + <span class="number">0.5</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算每个学生4个成绩的rank</span></span><br><span class="line">    <span class="keyword">for</span> (s=<span class="number">0</span>; s &lt; <span class="number">4</span>; s++)&#123;</span><br><span class="line">        <span class="comment">// 按不同科目的成绩排序，s用以选择科目</span></span><br><span class="line">        sort(students, students+n, studentCmp);</span><br><span class="line">        students[<span class="number">0</span>].rank[s] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (students[i].score[s] == students[i<span class="number">-1</span>].score[s]) <span class="comment">// 同分则rank相同</span></span><br><span class="line">                students[i].rank[s] = students[i<span class="number">-1</span>].rank[s];</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                students[i].rank[s] = i+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算每个学生的best rank</span></span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; mm; <span class="comment">// 至此，学生数组students中学生的索引不再变化，将学生ID映射到索引</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123; <span class="comment">// 遍历学生</span></span><br><span class="line">        mm[students[i].id] = i + <span class="number">1</span>; <span class="comment">// map中索引是int，默认值为0，所以索引需要+1避免和0混淆</span></span><br><span class="line"></span><br><span class="line">        students[i].bestSubject = <span class="number">0</span>; <span class="comment">// 计算该学生的best rank（记录best rank对应科目的索引）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;<span class="number">4</span>; j++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (students[i].rank[j] &lt; students[i].rank[students[i].bestSubject])</span><br><span class="line">                students[i].bestSubject = j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出查询结果</span></span><br><span class="line">    <span class="keyword">char</span> symbol[] = &#123;<span class="string">'A'</span>, <span class="string">'C'</span>, <span class="string">'M'</span>, <span class="string">'E'</span>&#125;;</span><br><span class="line">    <span class="built_in">string</span> studentID;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>, index, bestSubject; i&lt;m; i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; studentID;</span><br><span class="line">        <span class="keyword">if</span> (mm[studentID] != <span class="number">0</span>)&#123;</span><br><span class="line">            index = mm[studentID] - <span class="number">1</span>;</span><br><span class="line">            bestSubject = students[index].bestSubject;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d %c\n"</span>, students[index].rank[bestSubject], symbol[bestSubject]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"N/A\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/liuchuo/article/details/52202171" target="_blank" rel="noopener">https://blog.csdn.net/liuchuo/article/details/52202171</a></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
      <category term="排序" scheme="https://chouxianyu.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1056Mice and Rice</title>
    <link href="https://chouxianyu.github.io/2021/01/30/PAT%E7%94%B2%E7%BA%A71056Mice-and-Rice/"/>
    <id>https://chouxianyu.github.io/2021/01/30/PAT甲级1056Mice-and-Rice/</id>
    <published>2021-01-30T13:25:37.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805419468242944" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805419468242944</a></p></li><li><p>题目考点</p><p>  队列、模拟。重点在模拟，队列只用到了建立、入队、出队、清空（需要自己实现，创建新的队列然后赋值或者<code>swap</code>）。</p></li><li><p>题目难度</p><p>  PAT甲级25分</p></li><li><p>题目大意</p><ul><li>给定1个图，每个玩家控制1只老鼠移动，每个老鼠的目标是尽可能多地吃大米变成Fat Mouse。</li><li>$N_P$个玩家的顺序是随机的，每$N_G$个玩家分成1组进行比赛。每轮的获胜者继续每$N_G$个玩家分成一组进行比赛，直到最后1只老鼠。</li><li>每组中最快的老鼠获胜并进入下一轮，一轮中失败的老鼠的rank（排名）相同。</li><li>假设每只老鼠的重量是固定的，给出所有大米的重量和玩家初始顺序，请输出每个玩家的rank。</li></ul></li><li><p>输入</p><ul><li>$N_P$：玩家的数量，正整数，不超过1000</li><li>$N_G$：每组中最多有几个玩家（如果剩下的老鼠不够$N_G$只，这几只就形成最后一组），正整数，不超过1000</li><li>$W_i$：$N_P$个老鼠的重量，互异的非负数</li><li>$N_P$个玩家的顺序，玩家索引为$[0,N_P-1]$</li></ul></li><li><p>输出</p><ul><li>按玩家索引顺序最终所有玩家的rank</li></ul></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>两个队列：一个保存本轮玩家，一个保存下轮玩家，一直循环到结束（队列里只有1个人）。</p></li><li><p>关于rank，起初我的想法是通过比赛轮数得到rank，然而发现不行，因为rank要看人数，而不是由在几轮失败决定。</p><p>  怎么算rank我也想了挺久，后来看了题解才知道：5个人比赛，2个人晋级，那这失败的3个人的rank就是3（即2+1）妙啊。</p></li><li><p>除了rank，其它部分就比较简单了。</p></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1056</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805419468242944</span></span><br><span class="line"><span class="comment">// Tags: </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> playerNum, playerMaxNumInAGroup; <span class="comment">// 玩家数量，1组最多多少玩家</span></span><br><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; nowPlayers, nextPlayers;     <span class="comment">// 本轮玩家的索引和下轮玩家的索引</span></span><br><span class="line"><span class="keyword">int</span> weight[<span class="number">1002</span>]; <span class="comment">// 老鼠的重量</span></span><br><span class="line"><span class="keyword">int</span> rrank[<span class="number">1002</span>]; <span class="comment">// 玩家的排名</span></span><br><span class="line"><span class="keyword">int</span> groupNum; <span class="comment">// 本轮比赛有多少组</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*一组玩家进行比赛*/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findFatMouse</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> maxWeight = weight[nowPlayers.front()], fatMouse = nowPlayers.front();</span><br><span class="line">    rrank[nowPlayers.front()] = groupNum + <span class="number">1</span>;</span><br><span class="line">    nowPlayers.pop();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i &lt; playerMaxNumInAGroup &amp;&amp; !nowPlayers.empty(); i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (weight[nowPlayers.front()] &gt; maxWeight)&#123;</span><br><span class="line">            maxWeight = weight[nowPlayers.front()];</span><br><span class="line">            fatMouse = nowPlayers.front();</span><br><span class="line">        &#125;</span><br><span class="line">        rrank[nowPlayers.front()] = groupNum + <span class="number">1</span>;</span><br><span class="line">        nowPlayers.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    nextPlayers.push(fatMouse);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*计算本轮比赛有几组*/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">calcGroupNum</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> nowPlayerNum = nowPlayers.size();</span><br><span class="line">    <span class="keyword">if</span> (nowPlayerNum % playerMaxNumInAGroup == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> nowPlayerNum / playerMaxNumInAGroup;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> nowPlayerNum / playerMaxNumInAGroup + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 读取变量</span></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d%d"</span>, &amp;playerNum, &amp;playerMaxNumInAGroup);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; playerNum; i++)</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, weight+i);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>, player; i &lt; playerNum; i++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;player);</span><br><span class="line">        nowPlayers.push(player);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行比赛</span></span><br><span class="line">    <span class="keyword">while</span>(nowPlayers.size() &gt; <span class="number">1</span>)&#123;</span><br><span class="line">        nextPlayers = <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt;(); <span class="comment">// 清空下一轮比赛的玩家队列</span></span><br><span class="line">        groupNum = calcGroupNum();  <span class="comment">// 计算本轮比赛有几组，本轮失败的玩家的rank即为groupNum + 1</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; groupNum; i++) <span class="comment">// 进行本轮的groupNum组比赛</span></span><br><span class="line">            findFatMouse(); <span class="comment">// 一组玩家进行比赛</span></span><br><span class="line">        nowPlayers = nextPlayers; <span class="comment">// 进行下一轮比赛，更新玩家队列</span></span><br><span class="line">    &#125;</span><br><span class="line">    rrank[nowPlayers.front()] = <span class="number">1</span>; <span class="comment">// 剩下的1个人就是最终的第1名</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出排名</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d"</span>, rrank[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; playerNum; i++)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">" %d"</span>, rrank[i]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/liuchuo/article/details/54427590" target="_blank" rel="noopener">https://blog.csdn.net/liuchuo/article/details/54427590</a></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="队列" scheme="https://chouxianyu.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
  </entry>
  
  <entry>
    <title>PAT甲级1014Waiting in Line</title>
    <link href="https://chouxianyu.github.io/2021/01/28/PAT%E7%94%B2%E7%BA%A71014Waiting-in-Line/"/>
    <id>https://chouxianyu.github.io/2021/01/28/PAT甲级1014Waiting-in-Line/</id>
    <published>2021-01-28T13:38:59.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<h1 id="题目介绍"><a href="#题目介绍" class="headerlink" title="题目介绍"></a>题目介绍</h1><ul><li><p>题目链接</p><p>  <a href="https://pintia.cn/problem-sets/994805342720868352/problems/994805498207911936" target="_blank" rel="noopener">https://pintia.cn/problem-sets/994805342720868352/problems/994805498207911936</a></p></li><li><p>题目考点</p><p>  队列和模拟，重难点在于模拟而非队列</p></li><li><p>题目难度</p><p>  PAT甲级30分</p></li><li><p>题目大意</p><ul><li>有N个窗口，每个窗口最多允许M个人站在黄线前排队，剩下的客户在黄线外等候。</li><li>客户进入黄线时会选择人数最少的窗口排队，如果有重复，就选择索引最小的窗口</li><li>客户$C_i$办理业务需要$T_i$分钟。</li><li>前N个客户在8:00开始服务。</li><li>请计算某个客户结束服务的时间。</li></ul></li><li><p>输入</p><ul><li>N：正整数，不超过20，服务窗口的数量</li><li>M：正整数，不超过10，每个服务窗口前最多有几个人等待</li><li>K：正整数，不超过1000，顾客的数量，顾客索引为[1,K]</li><li>Q：要查询的顾客服务完成时间的数量</li><li>K个正整数：每个顾客完成服务需要几分钟</li><li>Q个正整数：需要查询的Q个顾客</li></ul></li><li><p>输出</p><p>  按<code>HH:MM</code>的格式输出Q个顾客完成服务的时间，如果在17:00之前还没有开始服务，则输出Sorry。</p></li></ul><h1 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h1><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ul><li><p>题目中有一个信息并没有十分明确地表达出来：黄线外的客户进入黄线以内时，索引小的人优先。根据这一点，所以从1到K遍历客户就可以。</p></li><li><p>整体思路：计算出所有客户完成服务的时间，最后进行Q个查询并根据分钟数输出完成服务的时间（或sorry）</p></li><li><p>如何计算出所有客户完成服务的时间？其实是个模拟题，<strong>核心在于入队，入队分2个阶段</strong>。</p></li><li><p>为什么核心是入队？<strong>某客户完成服务的时间取决于它前面1个客户完成服务的时间。而在某客户入队时，该客户前面就是队尾客户，所以该客户完成服务的时间=队尾客户完成服务的时间+该客户的服务时长。如果入队时队伍是空的，那该客户完成服务的时间就等于其服务所需时长。</strong></p></li><li><p>入队第1阶段是前N×M个客户入队</p><p>  无需等待黄线，只需按照客户索引顺序依次入队，其中前N个客户是在8:00开始服务。</p><p>  如何让这些客户正确地排队呢？用2层循环。内循环：在n个窗口中选择窗口（从1到N）入队。外循环：使内循环重复m次达到n×m的效果。这样就实现了“选择人数最少、索引最小的窗口”的要求。</p><p>  在客户入队时，我们需要不断更新客户索引，所以当已经没有客户时（即客户索引超过K时）要停止入队；另外所有窗口排满时也要停止入队，这通过双循环的判断条件实现。</p></li><li><p>入队第2阶段是剩下的客户入队</p><p>  假如还有剩下的客户（即客户索引还未超过K时），那就要找出队伍最短的窗口，让下一个客户入队。</p><p>  如何找到队伍最短的窗口呢？在该方法中，并不是通过比较n个窗口的排队长度。因为如果还剩有客户就说明每个窗口都是满的，那队伍最短就没有意义了。而最快有客户结束服务的窗口（如果有重复，就选索引最小的窗口）就是队伍最短的窗口，也就是找到哪个窗口队首客户完成服务的时间最早。</p></li><li><p>其它</p><ul><li><p>关于题目</p><p>  好久没做题目了，脑子和手都很生疏。看到这道题，我就想起来数学建模里做过的题、排队论什么的。思路很乱，我很自闭，这份题解的核心在于抓住了入队的规律。如果是更复杂的排队论问题，也许就需要模拟，模拟出一个时钟，然后某一分钟遍历所有窗口？这种思路确实可以，但效率不高。</p></li><li><p>关于算法题</p><p>  脱离这道题来讲，模拟题（可能大多数算法题也是）都是<strong>找规律</strong>，然后用规律去求结果。</p></li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Problem: PAT Advanced 1014</span></span><br><span class="line"><span class="comment">// URL: https://pintia.cn/problem-sets/994805342720868352/problems/994805498207911936</span></span><br><span class="line"><span class="comment">// Tags: 队列</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; window[<span class="number">20</span>]; <span class="comment">// n个窗口，每个窗口是一个排队队列</span></span><br><span class="line"><span class="keyword">int</span> processingTime[<span class="number">1001</span>]; <span class="comment">// k个客户需要的分钟数，index为[1,k]</span></span><br><span class="line"><span class="keyword">int</span> finishTime[<span class="number">1001</span>]; <span class="comment">// k个客户结束服务的时间，index为[1,k]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 变量定义并初始化</span></span><br><span class="line">    <span class="keyword">int</span> customerIndex = <span class="number">1</span>; <span class="comment">// 客户索引，后面用来遍历客户</span></span><br><span class="line">    <span class="keyword">int</span> n, m, k, q; <span class="comment">// 窗口个数、单个窗口队伍最大长度、客户数量、查询数量</span></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d %d %d %d"</span>, &amp;n, &amp;m, &amp;k, &amp;q);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i &lt;= k; i++)</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, processingTime+i);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理前n×m个客户（内循环：在n个窗口中选择1个窗口入队。外循环：使内循环重复m次达到n×m的效果）</span></span><br><span class="line">    <span class="keyword">while</span>(m--)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j &lt; n &amp;&amp; customerIndex &lt;= k; j++)&#123; <span class="comment">// 客户优先选择队伍最短、索引最小的窗口</span></span><br><span class="line">            <span class="keyword">if</span> (window[j].empty())&#123; <span class="comment">// 如果队伍是空的，那该客户在8:00开始服务，其完成服务的时间就等于其服务时长</span></span><br><span class="line">                finishTime[customerIndex] = processingTime[customerIndex];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                finishTime[customerIndex] = finishTime[window[j].back()] + processingTime[customerIndex]; <span class="comment">// 该客户完成服务的时间=队尾客户完成服务的时间+该客户的服务时长</span></span><br><span class="line">            &#125;</span><br><span class="line">            window[j].push(customerIndex); <span class="comment">// 当前客户入队</span></span><br><span class="line">            customerIndex++; <span class="comment">// 更新客户索引（考虑下一位客户）</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果还剩有客户的话，处理剩下的客户</span></span><br><span class="line">    <span class="keyword">while</span>(customerIndex &lt;= k)&#123;</span><br><span class="line">        <span class="keyword">int</span> quickestFinishTime = finishTime[window[<span class="number">0</span>].front()], quickestWindow = <span class="number">0</span>; <span class="comment">// 找出队伍最短的窗口</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (finishTime[window[i].front()] &lt; quickestFinishTime)&#123;</span><br><span class="line">                quickestFinishTime = finishTime[window[i].front()];</span><br><span class="line">                quickestWindow = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        finishTime[customerIndex] = finishTime[window[quickestWindow].back()] + processingTime[customerIndex]; <span class="comment">// 记录当前客户结束服务的时间</span></span><br><span class="line">        window[quickestWindow].pop();</span><br><span class="line">        window[quickestWindow].push(customerIndex);</span><br><span class="line">        </span><br><span class="line">        customerIndex++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> query_customer;</span><br><span class="line">    <span class="keyword">while</span>(q--)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;query_customer);</span><br><span class="line">        <span class="keyword">if</span> (finishTime[query_customer] - processingTime[query_customer] &lt; <span class="number">540</span>)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%02d:%02d\n"</span>, finishTime[query_customer]/<span class="number">60</span>+<span class="number">8</span>, finishTime[query_customer]%<span class="number">60</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"Sorry\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/liuchuo/article/details/54561626" target="_blank" rel="noopener">https://blog.csdn.net/liuchuo/article/details/54561626</a></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;题目介绍&quot;&gt;&lt;a href=&quot;#题目介绍&quot; class=&quot;headerlink&quot; title=&quot;题目介绍&quot;&gt;&lt;/a&gt;题目介绍&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;题目链接&lt;/p&gt;
&lt;p&gt;  &lt;a href=&quot;https://pintia.cn/problem-sets
      
    
    </summary>
    
    
      <category term="算法" scheme="https://chouxianyu.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="队列" scheme="https://chouxianyu.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
      <category term="PAT" scheme="https://chouxianyu.github.io/tags/PAT/"/>
    
  </entry>
  
  <entry>
    <title>python批量处理邮件：poplib和email快速上手教程</title>
    <link href="https://chouxianyu.github.io/2021/01/27/python%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86%E9%82%AE%E4%BB%B6%EF%BC%9Apoplib%E5%92%8Cemail%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%95%99%E7%A8%8B/"/>
    <id>https://chouxianyu.github.io/2021/01/27/python批量处理邮件：poplib和email快速上手教程/</id>
    <published>2021-01-27T13:16:36.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><ul><li><p><code>poplib</code>是一个python第三方库，基于它我们可以连接POP3服务器。</p></li><li><p><code>email</code>是一个python内置的模块，基于它我们可以管理邮箱中的邮件。</p></li><li><p>Some Story</p><p>  我现在需要下载很多邮件的附件。我之前有一份相同功能的代码（<a href="https://www.cnblogs.com/chouxianyu/p/11270101.html" target="_blank" rel="noopener">点击这里</a>），发布出来之后博客访问量也挺高。然而，当时由于时间原因我对那份代码只是一知半解，运行起来后就没具体研究。所以趁这个机会我又写了一份代码，原因有很多：一是于己我要把代码细节给搞懂，二是针对这次的需求进行修改，三是水一篇博客（bushi，<strong>这份代码十分简要并且注释十分详细</strong>）。</p></li></ul><h1 id="快速上手代码"><a href="#快速上手代码" class="headerlink" title="快速上手代码"></a>快速上手代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> poplib</span><br><span class="line"><span class="keyword">import</span> email</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    需求：消息标题、附件名称（存在header中）都是以字节为单位进行传输的，中文内容需要解码</span></span><br><span class="line"><span class="string">    功能：对header进行解码</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(header: str)</span>:</span></span><br><span class="line">    value, charset = email.header.decode_header(header)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> charset:</span><br><span class="line">        <span class="keyword">return</span> str(value, encoding=charset)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    功能：下载某一个消息的所有附件</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_attachment</span><span class="params">(msg)</span>:</span></span><br><span class="line">    subject = decode(msg.get(<span class="string">'Subject'</span>))  <span class="comment"># 获取消息标题</span></span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> msg.walk():  <span class="comment"># 遍历整个msg的内容</span></span><br><span class="line">        <span class="keyword">if</span> part.get_content_disposition() == <span class="string">'attachment'</span>:</span><br><span class="line">            attachment_name = decode(part.get_filename())  <span class="comment"># 获取附件名称</span></span><br><span class="line">            attachment_content = part.get_payload(decode=<span class="keyword">True</span>)  <span class="comment"># 下载附件</span></span><br><span class="line">            attachment_file = open(<span class="string">'./'</span> + attachment_name, <span class="string">'wb'</span>) <span class="comment"># 在指定目录下创建文件，注意二进制文件需要用wb模式打开</span></span><br><span class="line">            attachment_file.write(attachment_content)  <span class="comment"># 将附件保存到本地</span></span><br><span class="line">            attachment_file.close()</span><br><span class="line">    print(<span class="string">'Done………………'</span>, subject)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""连接到POP3服务器"""</span></span><br><span class="line">    server = poplib.POP3(host=<span class="string">'pop.163.com'</span>)  <span class="comment"># 创建一个POP3对象，参数host是指定服务器</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""身份验证"""</span></span><br><span class="line">    server.user(<span class="string">'xxxx@163.com'</span>)  <span class="comment"># 参数是你的邮箱地址</span></span><br><span class="line">    server.pass_(<span class="string">'xxxxx'</span>)  <span class="comment"># 参数是你的邮箱密码，如果出现poplib.error_proto: b'-ERR login fail'，就用开启POP3服务时拿到的授权码</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""获取邮箱中消息（邮件）数量"""</span></span><br><span class="line">    msg_count, _ = server.stat()</span><br><span class="line"></span><br><span class="line">    <span class="string">"""遍历消息并保存附件"""</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(msg_count):</span><br><span class="line">        <span class="string">"""获取消息内容：POP3.retr(which)检索index为which的整个消息，并将其设为已读"""</span></span><br><span class="line">        _, lines, _ = server.retr(</span><br><span class="line">            i+<span class="number">1</span>)  <span class="comment"># 3个结果分别是响应结果（1个包含是否请求成功和该消息大小的字符串），消息内容（一个字符串列表，每个元素是消息内容的一行），消息大小（即有多少个octets，octet特指8bit的字节）</span></span><br><span class="line"></span><br><span class="line">        <span class="string">"""将bytes格式的消息内容拼接"""</span></span><br><span class="line">        msg_bytes_content = <span class="string">b'\r\n'</span>.join(lines)</span><br><span class="line"></span><br><span class="line">        <span class="string">"""将字符串格式的消息内容转换为email模块支持的格式（&lt;class 'email.message.Message'&gt;）"""</span></span><br><span class="line">        msg = email.message_from_bytes(msg_bytes_content)</span><br><span class="line"></span><br><span class="line">        <span class="string">"""下载消息中的附件"""</span></span><br><span class="line">        download_attachment(msg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><p><a href="https://docs.python.org/zh-cn/3/library/poplib.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/poplib.html</a></p></li><li><p><a href="https://docs.python.org/zh-cn/3/library/email.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/email.html</a></p><p>  <strong>自定义修改</strong>：如果需要对上面的代码进行修改，比如需要获取邮件正文而非邮件附件，则可以进一步去看文档（特别是<a href="https://docs.python.org/zh-cn/3/library/email.message.html#module-email.message" target="_blank" rel="noopener"><code>email.message</code></a>）。</p><p>  我注释的一些代码也很重要，建议读者自己写几封测试邮件，把代码看懂，然后再去看文档，就可以啦！</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;poplib&lt;/code&gt;是一个python第三方库，基于它我们可以连接POP3服务
      
    
    </summary>
    
    
      <category term="python" scheme="https://chouxianyu.github.io/tags/python/"/>
    
      <category term="下载邮件附件" scheme="https://chouxianyu.github.io/tags/%E4%B8%8B%E8%BD%BD%E9%82%AE%E4%BB%B6%E9%99%84%E4%BB%B6/"/>
    
      <category term="poplib" scheme="https://chouxianyu.github.io/tags/poplib/"/>
    
      <category term="email" scheme="https://chouxianyu.github.io/tags/email/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-5.3神经网络中的反向传播算法</title>
    <link href="https://chouxianyu.github.io/2021/01/27/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-5-3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/"/>
    <id>https://chouxianyu.github.io/2021/01/27/李宏毅机器学习课程笔记-5-3神经网络中的反向传播算法/</id>
    <published>2021-01-27T03:37:36.000Z</published>
    <updated>2021-02-03T07:26:19.810Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="链式法则（Chain-Rule）"><a href="#链式法则（Chain-Rule）" class="headerlink" title="链式法则（Chain Rule）"></a>链式法则（Chain Rule）</h1><ul><li>$z=h(y),y=g(x)\to\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$</li><li>$z=k(x,y),x=g(s),y=h(s)\to\frac{dz}{ds}=\frac{dz}{dx}\frac{dx}{ds}+\frac{dz}{dy}\frac{dy}{ds}$</li></ul><h1 id="反向传播算法（Backpropagation）"><a href="#反向传播算法（Backpropagation）" class="headerlink" title="反向传播算法（Backpropagation）"></a>反向传播算法（Backpropagation）</h1><h2 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h2><p>如下图所示，设神经网络的输入为$x^n$，该输入对应的label是$\hat y^n$，神经网络的参数是$\theta$，神经网络的输出是$y^n$。</p><p>整个神经网络的Loss为$L(\theta)=\sum_{n=1}^{N}C^n(\theta)$。假设$\theta$中有一个参数$w$，那$\frac{\partial L(\theta)}{\partial w}=\sum^N_{n=1}\frac{\partial C^n(\theta)}{\partial w}$。</p><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201104063357Backpropagation1.png" alt="Backpropagation1"></p><h2 id="一个神经元的情况"><a href="#一个神经元的情况" class="headerlink" title="一个神经元的情况"></a>一个神经元的情况</h2><p>如下图所示，$z=x_1w_1+x_2w_x+b$，根据链式法则可知$\frac{\partial C}{\partial w}=\frac{\partial z}{\partial w}\frac{\partial C}{\partial z}$，其中为所有参数$w$计算$\frac{\partial z}{\partial w}$是Forward Pass、为所有激活函数的输入$z$计算$\frac{\partial C}{\partial z}$是Backward Pass。</p><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201104064536Backpropagation2.png" alt="Backpropagation2.png"></p><h2 id="Forward-Pass"><a href="#Forward-Pass" class="headerlink" title="Forward Pass"></a>Forward Pass</h2><p>Forward Pass是为所有参数$w$计算$\frac{\partial z}{\partial w}$，它的方向是从前往后算的，所以叫Forward Pass。</p><p>以一个神经元为例，因为$z=x_1w_1+x_2w_x+b$，所以$\frac{\partial z}{\partial w_1}=x_1,\frac{\partial z}{\partial w_2}=x_2$，如下图所示。</p><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201108071142ForwardPass1.jpg" alt="Forward Pass1"></p><p>规律是：该权重乘以的那个输入的值。所以当有多个神经元时，如下图所示。</p><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201108071151ForwardPass2.jpg" alt="Forward Pass2"></p><h2 id="Backward-Pass"><a href="#Backward-Pass" class="headerlink" title="Backward Pass"></a>Backward Pass</h2><p>Backward Pass是为所有激活函数的输入$z$计算$\frac{\partial C}{\partial z}$，它的方向是从后往前算的，要先算出输出层的$\frac{\partial C}{\partial z}$，再往前计算其它神经元的$\frac{\partial C}{\partial z}$，所以叫Backward Pass。</p><p><img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201108074342BackwardPass1.jpg" alt="BackwardPass1"></p><p>如上图所示，令$a=\sigma(z)$，根据链式法则，可知$\frac{\partial C}{\partial z}=\frac{\partial a}{\partial z}\frac{\partial C}{\partial a}$，其中$\frac{\partial a}{\partial z}=\sigma’(z)$是一个常数，因为在Forward Pass时$z$的值就已经确定了，而$\frac{\partial C}{\partial a}=\frac{\partial z’}{\partial a}\frac{\partial C}{\partial z’}+\frac{\partial z’’}{\partial a}\frac{\partial C}{\partial z’’}=w_3\frac{\partial C}{\partial z’}+w_4\frac{\partial C}{\partial z’’}$，所以$\frac{\partial C}{\partial z}=\sigma’(z)[w_3\frac{\partial C}{\partial z’}+w_4\frac{\partial C}{\partial z’’}]$。</p><p>对于式子$\frac{\partial C}{\partial z}=\sigma’(z)[w_3\frac{\partial C}{\partial z’}+w_4\frac{\partial C}{\partial z’’}]$，我们可以发现两点：</p><ol><li><p>$\frac{\partial C}{\partial z}$的计算式是递归的，因为在计算$\frac{\partial C}{\partial z}$的时候需要计算$\frac{\partial C}{\partial z’}$和$\frac{\partial C}{\partial z’’}$。</p><p> 如下图所示，输出层的$\frac{\partial C}{\partial z’}$和$\frac{\partial C}{\partial z’’}$是容易计算的。</p><p> <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201108075906BackwardPass3.jpg" alt="BackwardPass3"></p></li><li><p>$\frac{\partial C}{\partial z}$的计算式$\frac{\partial C}{\partial z}=\sigma’(z)[w_3\frac{\partial C}{\partial z’}+w_4\frac{\partial C}{\partial z’’}]$是一个神经元的形式</p><p> 如下图所示，只不过没有嵌套sigmoid函数而是乘以一个常数$\sigma’(z)$，每个$\frac{\partial C}{\partial z}$都是一个神经元的形式，所以可以通过神经网络计算$\frac{\partial C}{\partial z}$。</p><p> <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201108075902BackwardPass2.jpg" alt="BackwardPass2"></p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>通过Forward Pass，为所有参数$w$计算$\frac{\partial z}{\partial w}$；</li><li>通过Backward Pass，为所有激活函数的输入$z$计算$\frac{\partial C}{\partial z}$；</li><li>最后$\frac{\partial C}{\partial w}=\frac{\partial C}{\partial z}\frac{\partial z}{\partial w}$，也就求出了梯度。</li></ol><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;链式法则（Chain-Rule）&quot;&gt;&lt;a href=&quot;#链式法则（Chain-Rule）&quot; class=&quot;headerlink&quot; title=&quot;链式法则（Chain Rule）&quot;&gt;&lt;/a&gt;链式法则（Chain Rule）&lt;/h1&gt;&lt;ul&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="反向传播算法" scheme="https://chouxianyu.github.io/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-5.2神经网络为什么要是深度的</title>
    <link href="https://chouxianyu.github.io/2021/01/27/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-5-2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%98%AF%E6%B7%B1%E5%BA%A6%E7%9A%84/"/>
    <id>https://chouxianyu.github.io/2021/01/27/李宏毅机器学习课程笔记-5-2神经网络为什么要是深度的/</id>
    <published>2021-01-27T03:36:51.000Z</published>
    <updated>2021-02-03T07:26:18.925Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="为什么是“深度”神经网络？"><a href="#为什么是“深度”神经网络？" class="headerlink" title="为什么是“深度”神经网络？"></a>为什么是“深度”神经网络？</h1><h2 id="问题与答案"><a href="#问题与答案" class="headerlink" title="问题与答案"></a>问题与答案</h2><ul><li><p>矮胖的神经网络和高瘦的神经网络，假设它们参数量相同，哪一个更好呢？</p><p>  2011年有一个实验，证明在参数量相当的情况下，高瘦的神经网络（即深度神经网络）的准确度更高，因为深度可以实现模块化。</p></li><li><p>只用一个神经元足够多的隐藏层，这个模型就包括了任意函数，那为什么不这么做呢？</p><p>  这样确实可以包括任意函数，但实现的效率不高。</p><p>  相关网址<a href="http://neuralnetworksanddeeplearning.com/chap4.html，也可以通过谷歌等找找其它答案。" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/chap4.html，也可以通过谷歌等找找其它答案。</a></p></li></ul><h2 id="“深度”的好处"><a href="#“深度”的好处" class="headerlink" title="“深度”的好处"></a>“深度”的好处</h2><ul><li><p><strong>模块化（Modularization）</strong></p><ul><li><p>就像写程序一样，我们不能把所有代码写在main函数里，而需要通过定义函数等方式将程序模块化。</p><p>  如下图所示，假如要做一个图片的四分类，两个维度分别是头发长短和性别，如果使用矮胖的神经网络会遇到一个问题，就是短头发的女生样本和长头发的男生样本会比较少，那这两个类别的分类器就会比较差。</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201110021709WhyDeepModularization1.png" alt="WhyDeepModularization1" style="zoom: 33%;"></p><p>  如下图所示，我们可以先定义各属性的分类器（Classifiers for the attributes），即先定义性别和头发长短的分类器，然后再做四分类。这样第一层分类器就不会遇到样本少的问题，第二层的分类器也容易训练，整体上也需要更少的训练集。</p><p>  <img src="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201110021748WhyDeepModularization2.png" alt="WhyDeepModularization2" style="zoom:33%;"></p></li><li><p>在深度神经网络中，每层网络都可以作为下一层网络使用的一个模块，并且这个模块化是通过机器学习自动得到的。</p><p>  常有“人工智能=机器学习+大数据”的说法，但实际上“深度”使得需要的数据更少，如果数据集无限大，根本就不需要机器学习，只要去数据库里拿就好了。深度学习也并不是通过大量参数暴力拟合出一个模型，反而是在通过模块化有效利用数据。</p><p>  这里只是一个图像分类的例子，“深度”产生的模块化在语音识别任务中也有体现，与逻辑电路也有相似的问题和结论，具体可以看<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=15" target="_blank" rel="noopener">李宏毅视频</a>。</p></li></ul></li><li><p><strong>端到端学习（End-to-end Learning）</strong></p><p>  深度神经网络模型就像是把一个个函数串接在一起，每个函数负责某个功能，每个函数负责什么功能是通过机器学习根据数据自动确定的。<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=15" target="_blank" rel="noopener">李宏毅视频</a>中有讲这一点在语音识别、CV任务中的体现。</p></li><li><p><strong>处理复杂任务</strong></p><p>  有时类似的输入要输出差别很大的结果，比如白色的狗和北极熊看起来差不多，但分类结果非常不同；有时差别很大的输入要输出相同的结果，比如火车正面和侧面的图片都应该被分类成火车。</p><p>  只有一个隐藏层的网络是无法处理这种任务的。<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=15" target="_blank" rel="noopener">李宏毅视频</a>中有讲这一点在语音识别、CV任务中的体现。</p></li><li><p>其它</p><p>  <a href="http://www.oalib.com/paper/4042915" target="_blank" rel="noopener">Do deep nets really need to be deep?</a></p><p>  <a href="https://www.bilibili.com/video/BV1JE411g7XF?p=15" target="_blank" rel="noopener">李宏毅视频</a>里也还有很多关于“深度”的探讨。</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;为什么是“深度”神经网络？&quot;&gt;&lt;a href=&quot;#为什么是“深度”神经网络？&quot; class=&quot;headerlink&quot; title=&quot;为什么是“深度”神经网络？&quot;&gt;&lt;/a&gt;为什么是“深度”神经网络？&lt;/h1&gt;&lt;h2 id=&quot;问题与答案&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
