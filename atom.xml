<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>臭咸鱼的缺氧瓶</title>
  
  <subtitle>快给我氧气！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://chouxianyu.github.io/"/>
  <updated>2021-05-01T22:40:07.243Z</updated>
  <id>https://chouxianyu.github.io/</id>
  
  <author>
    <name>臭咸鱼</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>李宏毅机器学习课程笔记-13.1模型压缩之网络剪枝</title>
    <link href="https://chouxianyu.github.io/2021/05/02/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-13-1%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9%E4%B9%8B%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"/>
    <id>https://chouxianyu.github.io/2021/05/02/李宏毅机器学习课程笔记-13-1网络压缩之网络剪枝/</id>
    <published>2021-05-01T22:24:53.000Z</published>
    <updated>2021-05-01T22:40:07.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>网络剪枝（Network Pruning）就是删除一个较大网络中的一些weight或neuron得到一个更小的网络。</p><p>我们相信，<strong>通常情况下我们训练出的神经网络是over-parameterized</strong>，即其中存在很多weight或neuron是没有用的(比如有些neuron的输出总是0、有些weight非常接近0) ，因此我们可以把这些没有用的weight或neuron剪掉。</p><p>在90年代，Yann Le Cun就提出了“网络剪枝”，paper名称为Optimal Brain Damage。</p><p>有个问题是：为什么不直接使用较小Network而是对较大Network进行剪枝？常见的解释是：较小的Network训练出来的结果一般都不好，而较大的Network更容易optimize（李老师这个视频有讲解为什么：<a href="https://www.youtube.com/watch?v=_VuWvQUMQVk）。在训练神经网络时可能会遇到local" target="_blank" rel="noopener">https://www.youtube.com/watch?v=_VuWvQUMQVk）。在训练神经网络时可能会遇到local</a> minima和saddle point的问题，但如果Network够大这种问题就会不那么严重，现在有很多文献甚至可以证明只要Network够大就可以用梯度下降找到global optimal。</p><h2 id="How-to-Prune-a-Network"><a href="#How-to-Prune-a-Network" class="headerlink" title="How to Prune a Network"></a>How to Prune a Network</h2><ol><li><p>训练出一个较大的Network</p></li><li><p>评估该Network中每个weight和neuron的重要性</p><p> 这一步有很多种做法</p><ul><li><p>weight的重要性</p><p>  比如：如果其值接近0，则说明该weight不重要，因此可以计算weight的L1或L2判断weight的重要性。</p></li><li><p>neuron的重要性</p><p>  比如：给定dataset，如果某个neural的输出都是0那么该neural是不那么重要的</p></li></ul></li><li><p>根据重要性将weight和neuron排序并删除那些不那么重要的weight和neuron</p><p> 删除一些weight和neuron后，Network会变小但精度一般也会变低，因此还需要进行fine-tune</p><p> 一次最好不要删除太多neuron或weight，否则Network的精度会无法通过fine-tune恢复，最好是每次只删除一小部分然后进行fine-tune并重复该过程</p></li><li><p>fine-tune</p><p> 训练剪枝得到的较小的网络</p></li></ol><p>熟悉YOLO的读者，可以根据这个仓库（<a href="https://github.com/tanluren/yolov3-channel-and-layer-pruning）感受一下剪枝和知识蒸馏。" target="_blank" rel="noopener">https://github.com/tanluren/yolov3-channel-and-layer-pruning）感受一下剪枝和知识蒸馏。</a></p><h2 id="Lottery-Ticket-Hypothesis"><a href="#Lottery-Ticket-Hypothesis" class="headerlink" title="Lottery Ticket Hypothesis"></a>Lottery Ticket Hypothesis</h2><p>论文链接：<a href="https://arxiv.org/abs/1803.03635，这是ICLR2019的一篇论文" target="_blank" rel="noopener">https://arxiv.org/abs/1803.03635，这是ICLR2019的一篇论文</a></p><p>如下图所示，现有一个较大网络A，随机初始化其参数并记该参数为W，训练该较大网络A并进行剪枝得到较小网络B。有个现象是：如果我们随机初始化较小网络B的参数并进行训练，得到的结果就不行；但如果使用参数W中的对应参数初始化，得到的结果就可以。</p><p><img src="https://pic4.zhimg.com/80/v2-6bbbbfc39567d8a138f36ac44ef94849_720w.png" alt="img"></p><h2 id="Rethinking-the-Value-of-Network-Pruning"><a href="#Rethinking-the-Value-of-Network-Pruning" class="headerlink" title="Rethinking the Value of Network Pruning"></a>Rethinking the Value of Network Pruning</h2><p>论文链接：<a href="https://arxiv.org/abs/1810.05270，这是ICLR2019的一篇论文" target="_blank" rel="noopener">https://arxiv.org/abs/1810.05270，这是ICLR2019的一篇论文</a></p><p>这篇论文的结论和Lottery Ticket Hypothesis一文相反：现有剪枝后的网络，将其参数随机初始化是可以训练出好的结果的。</p><p>ICLR2019的review是开放的，网上可以搜到两篇文章作者的讨论，知乎上也有关于这两篇论文的讨论，后续也有人做了相关研究。</p><h2 id="Some-Issue-in-Weight-Pruning"><a href="#Some-Issue-in-Weight-Pruning" class="headerlink" title="Some Issue in Weight Pruning"></a>Some Issue in Weight Pruning</h2><p>如果是weight pruning，那剪枝后的Network会变得不规则（比如有些neuron有2个weight而有些neuron有4个weight）。这样的不规则的Network是不好用keras等代码框架实现的，并且GPU只能对矩阵运算进行加速而无法加速这样的Network。比较常见的实做方法是将需要剪掉的weight设成0，因此仍然可以用GPU加速，但这样其实并没有使网络变小。</p><p>实际上做weight pruning是很麻烦的，通常都进行neuron pruning，因为比较容易用代码实现、也容易达到加速的目的。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;网络剪枝（Network Pruning）就是删除一个较大网络中的一些wei
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型压缩" scheme="https://chouxianyu.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="网络剪枝" scheme="https://chouxianyu.github.io/tags/%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.4对抗攻击代码实战</title>
    <link href="https://chouxianyu.github.io/2021/05/01/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-4%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/05/01/李宏毅机器学习课程笔记-12-4对抗攻击代码实战/</id>
    <published>2021-05-01T00:13:08.000Z</published>
    <updated>2021-05-01T00:29:31.272Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework6的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述</p><p>  选择一个Proxy Network实现<strong>Black Box</strong> Attack，通过FGSM(Fast Gradient Sign Method)实现Non-targeted Adversial Attack。</p></li><li><p>数据集描述</p><p>  有200张图片，命名格式为<code>编号.png</code>，尺寸为224×224。</p><p>  categories.csv：1000个类别，索引为[0,999]，</p><p>  labels.csv：每张图片的信息(包括类别索引)</p></li><li><p>评估指标</p><ul><li>所有输入图片$x^0$和攻击图片$x’$的L-infinity的平均值</li><li>攻击的成功率</li></ul></li><li><p>结果</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Original Proxy Network Accuracy: <span class="number">0.865</span></span><br><span class="line">After Attack(epsilon: <span class="number">0.1</span>) Accrucy: <span class="number">0.03</span></span><br><span class="line">Original Proxy Network Accuracy: <span class="number">0.865</span></span><br><span class="line">After Attack(epsilon: <span class="number">0.01</span>) Accrucy: <span class="number">0.27</span></span><br></pre></td></tr></table></figure><p>  使用预训练的VGG16作为Proxy Network，可知在攻击前Proxy Nerwork的准确率为0.865，而攻击后准确率为0.03(epsilon为0.1)、0.27(epsilon为0.01)</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework6的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.3对抗防御入门</title>
    <link href="https://chouxianyu.github.io/2021/04/30/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-3%E5%AF%B9%E6%8A%97%E9%98%B2%E5%BE%A1%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/30/李宏毅机器学习课程笔记-12-3对抗防御入门/</id>
    <published>2021-04-30T01:55:55.000Z</published>
    <updated>2021-05-01T00:17:37.833Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-is-Defense"><a href="#What-is-Defense" class="headerlink" title="What is Defense"></a>What is Defense</h2><p>有人说模型容易被攻破是因为过拟合，但其实并不是，因为weight regularization、dropout、model ensemble都不能抵挡Adversarial Attack，并且Attack可以攻击多个model。</p><p>Defense分为两类：</p><ul><li><p>Passive Defense</p><p>  不修改模型，而是在模型前加一个filter防止模型被攻击，其实这是Anomaly Detection的一个特例。</p></li><li><p>Proactive Defense</p><p>  训练模型时就对Attack进行防御</p></li></ul><p>如果攻击者知道Defense的具体实现，那攻击者一般仍然可以将Defense攻破。</p><h2 id="Passive-Defense"><a href="#Passive-Defense" class="headerlink" title="Passive Defense"></a>Passive Defense</h2><p>在模型前加一个filter防止模型被攻击，filter的作用就是扰动攻击信号$\Delta x$使其无效，这个filter并不需要很复杂，有时smoothing就可以，还有Gaussian Filter、Median Filter、Bilateral Filter等等。</p><ul><li><p>Feature Squeeze</p><p>  将图片输入模型得到输出P1，然后分别使用2个Squeezer对图片进行处理后再输入到模型得到输出P2、P3，如果P1和P2的差距、P2和P3的差距超过了某个值就判断该图片是攻击图片。</p><p>  详见：Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks(<a href="https://arxiv.org/abs/1704.01155" target="_blank" rel="noopener">https://arxiv.org/abs/1704.01155</a>)</p></li><li><p>Randomization at Inference Phase</p><p>  将图片随机稍微缩放然后随机padding，然后随机选择其中一个结果输入到模型。</p><p>  详见：Mitigating Adversarial Effects Through Randomization(<a href="https://arxiv.org/abs/1711.01991" target="_blank" rel="noopener">https://arxiv.org/abs/1711.01991</a>)</p></li></ul><h2 id="Proactive-Defense"><a href="#Proactive-Defense" class="headerlink" title="Proactive Defense"></a>Proactive Defense</h2><p>在训练模型时就找出模型的漏洞并进行改善。</p><p>首先用训练集训练模型，然后多次迭代，在每次迭代中使用某种攻击方法分别找到每个训练集样本对应的攻击样本$x’$，然后把这些攻击样本添加到训练集中进行训练(这有点像数据增强)，多次迭代的原因是基于新的训练集训练后模型可能会产生新的漏洞。</p><p>注意：假如在Proactive Defense时我们使用的攻击方法为A，那我们的模型也许可以防御他人的A攻击，但仍无法防御其它攻击方法。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;What-is-Defense&quot;&gt;&lt;a href=&quot;#What-is-Defense&quot; class=&quot;headerlink&quot; title=&quot;What is Defense&quot;&gt;&lt;/a&gt;What is Defense&lt;/h2&gt;&lt;p&gt;有人说模型容易被攻破是因为过拟合，但
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.2对抗攻击进阶</title>
    <link href="https://chouxianyu.github.io/2021/04/28/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-2%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E8%BF%9B%E9%98%B6/"/>
    <id>https://chouxianyu.github.io/2021/04/28/李宏毅机器学习课程笔记-12-2对抗攻击进阶/</id>
    <published>2021-04-28T02:35:42.000Z</published>
    <updated>2021-04-28T02:36:53.301Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h2><p>Attack可以是分别为每个输入$x^0$找到对应的攻击信号$\Delta x$，还可以是找到一个适用于所有输入的攻击信号$\Delta x$，这就是Universal Adversarial Attack，详见：Universal adversarial perturbations(<a href="https://arxiv.org/abs/1610.08401)。" target="_blank" rel="noopener">https://arxiv.org/abs/1610.08401)。</a></p><h2 id="One-Pixel-Attack"><a href="#One-Pixel-Attack" class="headerlink" title="One Pixel Attack"></a>One Pixel Attack</h2><p>One Pixel Attack就是攻击时的constraint为只能修改图片中一个pixel，即$d(x^0,x’)=||x^0-x’||_0=||\Delta x||_0\leq1$，其中可以将L0范数理解为非零元素的个数。</p><p>如何确定要攻击哪个像素呢？暴力求解速度会很慢。还有个问题是我们是否需要最佳的攻击方案？如果能够使用Loss梯度下降找到最佳的攻击方案，那当然是好的，但其实我们只需攻击成功即可，因为攻击的目标主要是使模型失效，只要可以攻击成功就行。比如原模型对某图片的分类结果是置信度为16.48%的Cup，我们能找到一个方案使模型分类结果是置信度为16.74%的Soup Bowl即可而不需要必须使得置信度为100%。同理，我们只要能找到某个可以击破的像素就行而并不需要找到最薄弱的像素。</p><p>那如何找到一个攻击方案呢？用Differential Evolution就行。Differential Evolution的好处是有较大的概率得到全局最优解并且不需要计算梯度也就不需要被攻击模型的参数。Differential Evolution与遗传算法非常类似，都包括变异、杂交和选择操作，但这些操作的具体定义与遗传算法有所不同。</p><p>详见One pixel attack for fooling deep neural networks(<a href="https://arxiv.org/abs/1710.08864)。" target="_blank" rel="noopener">https://arxiv.org/abs/1710.08864)。</a></p><h2 id="Adversarial-Reprogramming"><a href="#Adversarial-Reprogramming" class="headerlink" title="Adversarial Reprogramming"></a>Adversarial Reprogramming</h2><p>我们可以在不改变模型参数的情况下，通过Attack来修改模型的“功能”，比如将一个图片分类模型的功能改为方块计数(方块数量对应某种种类)，详见：</p><ul><li>Adversarial Reprogramming of Neural Networks(<a href="https://arxiv.org/abs/1806.11146v2" target="_blank" rel="noopener">https://arxiv.org/abs/1806.11146v2</a>)</li><li><a href="https://arxiv.org/abs/1705.09554" target="_blank" rel="noopener">https://arxiv.org/abs/1705.09554</a></li><li><a href="https://arxiv.org/abs/1707.05572" target="_blank" rel="noopener">https://arxiv.org/abs/1707.05572</a></li></ul><h2 id="Attack-in-the-Physical-World"><a href="#Attack-in-the-Physical-World" class="headerlink" title="Attack in the Physical World"></a>Attack in the Physical World</h2><p>有一个问题是，我们说的这些攻击在物理世界中会失效吗？比如相机等设备会不会像人一样无法识别那些攻击信号呢？答案是不一定。有人做了相关实验，将扰动得到的图片$x’$打印出来，然后用手机、相机等拍照再做分类或识别，仍然可以成功攻击模型，详见：Adversarial examples in the physical world(<a href="https://arxiv.org/abs/1607.02533v4)、https://www.youtube.com/watch?v=zQ_uMenoBCk&amp;feature=youtu.be" target="_blank" rel="noopener">https://arxiv.org/abs/1607.02533v4)、https://www.youtube.com/watch?v=zQ_uMenoBCk&amp;feature=youtu.be</a></p><p>攻击还可以用在人脸识别领域，比如我戴一个实体眼镜(用于攻击)之后可能就会被人脸识别系统识别为其他人，详见：<a href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf</a></p><p>攻击还可以用在自动驾驶中，假如汽车在自动驾驶时需要看红绿灯等标志物，那在这些标志物上贴一些攻击信号也许就会导致车辆“失控”，详见：<a href="https://arxiv.org/abs/1707.08945" target="_blank" rel="noopener">https://arxiv.org/abs/1707.08945</a></p><h2 id="Attack-Text-amp-Audio"><a href="#Attack-Text-amp-Audio" class="headerlink" title="Attack Text &amp; Audio"></a>Attack Text &amp; Audio</h2><p>攻击并不仅限于Image，还可以攻击Text，可参考：<a href="https://arxiv.org/pdf/1707.07328.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1707.07328.pdf</a></p><p>攻击并不仅限于Image和Text，还可以攻击Audio，可参考：</p><ul><li><a href="https://nicholas.carlini.com/code/audio_adversarial_examples" target="_blank" rel="noopener">https://nicholas.carlini.com/code/audio_adversarial_examples</a></li><li><a href="https://adversarial-attacks.net" target="_blank" rel="noopener">https://adversarial-attacks.net</a></li><li>现实中ASR可能会受到攻击，ASR指Automatic Speech Recognition(自动语音识别)，即语音转文字，详见：<a href="https://nicholas.carlini.com/code/audio_adversarial_examples/" target="_blank" rel="noopener">https://nicholas.carlini.com/code/audio_adversarial_examples/</a></li><li>ASV也可能会受到攻击，ASV指Automatic Speaker Verification，即识别是谁讲话，详见：<a href="https://arxiv.org/abs/1911.01840" target="_blank" rel="noopener">https://arxiv.org/abs/1911.01840</a></li></ul><h2 id="Hidden-Voice-Attack"><a href="#Hidden-Voice-Attack" class="headerlink" title="Hidden Voice Attack"></a>Hidden Voice Attack</h2><p>Hidden Voice Attack就是生成一段人类无法听懂的audio但仍然可以骗过你的模型，比如用一段人类听不懂但被模型判定为“Hey, Siri”的audio启动你的苹果手机。</p><p>详见：<a href="https://arxiv.org/abs/1904.05734" target="_blank" rel="noopener">https://arxiv.org/abs/1904.05734</a></p><p>如下图所示，处理audio的步骤为Preprocessing、Signal Processing、Model Inference，Hidden Voice Attack就是在Signal Processing阶段进行攻击。</p><p><img src="https://pic4.zhimg.com/80/v2-c9deeab05746a3649cacdad7f5ff7c91_720w.png" alt="img"></p><p>如下图所示，对audio的扰动方式有4种，具体不再详细介绍。</p><p><img src="https://pic1.zhimg.com/80/v2-57afffde6ff0ea8a468ce57bbd9b3f83_720w.png" alt="img"></p><h3 id="Time-Domain-Inversion"><a href="#Time-Domain-Inversion" class="headerlink" title="Time Domain Inversion"></a>Time Domain Inversion</h3><p>Time Domain Inversion简称TDI，它利用了magnitude FFT多对一的性质(两个不同的signal经过mFFT可以得到相同结果)，所以我们可以将time domain中的signal进行处理，处理之后会影响人听懂但不影响模型。</p><h3 id="Random-Phase-Generation"><a href="#Random-Phase-Generation" class="headerlink" title="Random Phase Generation"></a>Random Phase Generation</h3><p>FFT返回了一个复数$a+bi$，而$magnitude=\sqrt{a^2+b^2}$，不同的$a$和$b$可以计算得到相同的magnitude，所以可以对$a$和$b$进行修改，修改后会影响人听懂但不影响模型。</p><h3 id="High-Frequency-Addition"><a href="#High-Frequency-Addition" class="headerlink" title="High Frequency Addition"></a>High Frequency Addition</h3><p>High Frequency Addition简称HFA。</p><p>在Preprocessing过程中会使用low-pass filter过滤掉比人声高很多的频段以增加Voice Processing System的准确率，那我们就可以在audio中加入高频段audio，这样会影响人听懂但不影响模型。</p><h3 id="Time-Scaling"><a href="#Time-Scaling" class="headerlink" title="Time Scaling"></a>Time Scaling</h3><p>将audio缩短到model能正确辨识但人听不懂。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Universal-Adversarial-Attack&quot;&gt;&lt;a href=&quot;#Universal-Adversarial-Attack&quot; class=&quot;headerlink&quot; title=&quot;Universal Adversarial Attack&quot;&gt;&lt;/a&gt;Un
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-12.1对抗攻击入门</title>
    <link href="https://chouxianyu.github.io/2021/04/27/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-12-1%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/27/李宏毅机器学习课程笔记-12-1对抗攻击入门/</id>
    <published>2021-04-27T02:23:23.000Z</published>
    <updated>2021-04-27T03:13:03.268Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>我们希望我们的模型不仅仅是在大多数情况下可用的，还希望它能够应对来自外界的“攻击”，特别是在垃圾邮件分类、恶意软件检测、网络入侵检测等任务中。</p><p>这个领域为对抗攻击与防御（Adversarial Attack and Defense），目前攻击是比较容易的而防御比较困难。</p><h2 id="What-is-Attack"><a href="#What-is-Attack" class="headerlink" title="What is Attack"></a>What is Attack</h2><p>attack就是往原输入$x^0$中添加一些特别的噪声$\Delta x$(并不是随机生成的)得到一个稍微有些不同的输入$x’=x^0+\Delta x$，而模型却得到一个与原输出截然不同的输出。如下图所示，在图像分类任务中，对一张“Tiger Cat”图片添加一些特别的噪声$\Delta x$后，人类还能看出它是“Tiger Cat”，但模型却认为它是其它的类别。</p><p><img src="https://pic1.zhimg.com/80/v2-5610b9b55bf8893362a8526352810834_720w.png" alt="img"></p><h2 id="Loss-Function-For-Attack"><a href="#Loss-Function-For-Attack" class="headerlink" title="Loss Function For Attack"></a>Loss Function For Attack</h2><p>攻击可以分为两种：Non-targeted Attack和Targeted Attack。</p><h3 id="How-To-Train"><a href="#How-To-Train" class="headerlink" title="How To Train"></a>How To Train</h3><p>我们是这样训练一个普通的神经网络的：将输入$x^0$输入到模型后，我们希望<strong>模型的输出$y^0$和标签$y^{true}$越接近越好</strong>，则损失函数为$L_{train}(\theta)=C(y^0,y^{true})$。<strong>此时输入$x^0$是固定的，我们需要不断调整模型参数$\theta$</strong>，使得$L_{train}(\theta)$最小。</p><h3 id="Non-targeted-Attack"><a href="#Non-targeted-Attack" class="headerlink" title="Non-targeted Attack"></a>Non-targeted Attack</h3><p>如果是Non-targeted Attack，将输入$x’=x+\Delta x$输入到模型后，我们希望<strong>模型的输出$y’$和标签$y^{true}$的差异越大越好</strong>，则损失函数为$L_{Non-targeted\ Attack}(x’)=-C(y’,y^{true})$，比$L_{train}(\theta)$多了一个负号。<strong>此时模型参数$\theta$是固定的，我们需要不断调整输入$x’$</strong>，使$L_{Non-targeted\ Attack}(x’)$最小。</p><h3 id="Targeted-Attack"><a href="#Targeted-Attack" class="headerlink" title="Targeted Attack"></a>Targeted Attack</h3><p>如果是Targeted Attack，将输入$x’=x+\Delta x$输入到模型后，我们希望<strong>模型的输出$y’$和标签$y^{true}$的差异越大越好并且模型的输出$y’$与某个$y^{false}$越接近越好</strong>，其中$y^{false}$需要人为选择，则损失函数为$L_{Targeted\ Attack}(x’)=-C(y’,y^{true})+C(y’,y^{false})$。<strong>此时模型参数$\theta$是固定的，我们需要不断调整输入$x’$</strong>，使$L_{Targeted\ Attack}(x’)$最小。</p><h2 id="Constraint-For-Attack"><a href="#Constraint-For-Attack" class="headerlink" title="Constraint For Attack"></a>Constraint For Attack</h2><p>在Attack中，除了要使$L_{Non-targeted\ Attack}(x’)$和$L_{Targeted\ Attack}(x’)$最小之外，我们还希望<strong>$x^0$和$x’$之间的差异较小</strong>，即$d(x^0,x’)\leq\epsilon$，其中$\epsilon$需要人为选择，这样才能实现真正的Attack。</p><p>主要有两种计算$d(x^0,x’)$的方法，但在不同的任务中应该有不同的计算方法，因为其代表着人类视角下$x^0$和$x’$之间的差异。</p><h3 id="L2-norm"><a href="#L2-norm" class="headerlink" title="L2-norm"></a>L2-norm</h3><p>L2-norm为$x^0$和$x’$中每个像素之差的平方和，即$d(x^0,x’)=||x^0-x’||_2=||\Delta x||_2=(\Delta x_1)^2+(\Delta x_2)^2+(\Delta x_3)^2+\dots$</p><h3 id="L-infinity"><a href="#L-infinity" class="headerlink" title="L-infinity"></a>L-infinity</h3><p>L-infinity为$x^0$和$x’$中每个像素之差的最大值，即$d(x^0,x’)=||x^0-x’||_{\infin}=||\Delta x||_{\infty}=max\{\Delta x_1,\Delta x_2,\Delta_3,\dots\}$</p><p>对于图像中的pixel来讲，也许L-infinity是更有效的计算方法。</p><h2 id="How-to-Attack"><a href="#How-to-Attack" class="headerlink" title="How to Attack"></a>How to Attack</h2><p>我们在Attack时要训练的参数是输入$x’$而非模型参数$\theta$，在$d(x^0,x’)\leq\epsilon$的情况下使得$L(x’)$最小，即$x^*=arg\mathop{min}_\limits {d(x^0,x’)\leq\epsilon}L(x’)$。</p><p>关于如何训练输入$x’$而非模型参数$\theta$，可以参考下Explainable AI的代码部分，其实就是设置输入$x’$的梯度是可追踪的并在定义优化器时传入输入$x’$而非模型参数$\theta$。</p><p><img src="https://pic1.zhimg.com/80/v2-cabb0848c34eca5fe5f4009181b49e7b_720w.png" alt="img"></p><p>如上图所示，在训练时有两个关键点。第一点是输入$x’$应该用$x^0$初始化；第二点是在每个iteration中需要判断保证$d(x^0,x’)\leq\epsilon$，具体来讲就是当发现$d(x^0,x’)&gt;\epsilon$时就需要将$x’$修正为所有满足$d(x^0,x)&gt;\epsilon$的$x$中与$x’$最接近的那个。那要怎么找到所有满足$d(x^0,x)&gt;\epsilon$的$x$中与$x’$最接近的那个呢？下图中圆形和正方形中的$x$均满足$d(x^0,x)&gt;\epsilon$，所以中心$x^0$与$x’$连线与圆形或正方形的交点就是要修正的结果。</p><p><img src="https://pic2.zhimg.com/80/v2-163a5c710e5ed504d06debfb7c509493_720w.png" alt="img"></p><h2 id="Attack-Approaches"><a href="#Attack-Approaches" class="headerlink" title="Attack Approaches"></a>Attack Approaches</h2><ul><li>FGSM (<a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">https://arxiv.org/abs/1412.6572</a>)</li><li>Basic iterative method (<a href="https://arxiv.org/abs/1607.02533" target="_blank" rel="noopener">https://arxiv.org/abs/1607.02533</a>) </li><li>L-BFGS (<a href="https://arxiv.org/abs/1312.6199" target="_blank" rel="noopener">https://arxiv.org/abs/1312.6199</a>)</li><li>Deepfool (<a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">https://arxiv.org/abs/1511.04599</a>)</li><li>JSMA (<a href="https://arxiv.org/abs/1511.07528" target="_blank" rel="noopener">https://arxiv.org/abs/1511.07528</a>)</li><li>C&amp;W (<a href="https://arxiv.org/abs/1608.04644" target="_blank" rel="noopener">https://arxiv.org/abs/1608.04644</a>)</li><li>Elastic net attack (<a href="https://arxiv.org/abs/1709.04114" target="_blank" rel="noopener">https://arxiv.org/abs/1709.04114</a>)</li><li>Spatially Transformed (<a href="https://arxiv.org/abs/1801.02612" target="_blank" rel="noopener">https://arxiv.org/abs/1801.02612</a>) </li><li>One Pixel Attack (<a href="https://arxiv.org/abs/1710.08864" target="_blank" rel="noopener">https://arxiv.org/abs/1710.08864</a>)</li><li>……</li></ul><p>虽然有很多方法都可以进行attack，但它们的主要区别在于使用了不同的constraint或者使用了不同的optimization method。</p><h2 id="FGSM"><a href="#FGSM" class="headerlink" title="FGSM"></a>FGSM</h2><p>FGSM即Fast Gradient Sign Method，本次homework(hw6_AdversarialAttack)就使用了FGSM。</p><p>FGSM中输入的更新规则为$x^*=x^0-\epsilon\Delta x$。它首先计算出损失$L$关于$x$的每个维度的梯度，如果梯度大于0则修改为+1、小于0则修改为-1，也就是说$x^0$的所有维要么$+\epsilon$是要么是$-\epsilon$。</p><p>假设FGSM使用L-infinity计算$d(x^0,x^<em>)$，如果梯度指向左下角那么$x^</em>$就在方框的右上角；如果gradient指向左上角那么$x^<em>$就在方框的右下角；因此在FGSM中我们只在意梯度方向而不在意其大小。我们可以认为FGSM使用一个非常大的学习率使$x$飞出正方形，但因为要保证$d(x^0,x’)\leq\epsilon$所以$x^</em>$就会被限制到方形区域内部。所以就像是“一拳超人”，只攻击一次就达到好的效果。</p><p><img src="https://pic1.zhimg.com/80/v2-8c2bf52f38a95de4070288719e1eed4c_720w.png" alt="img"></p><h2 id="Black-Box-Attack"><a href="#Black-Box-Attack" class="headerlink" title="Black Box Attack"></a>Black Box Attack</h2><p>Attack可以分为White Box和Black Box。White Box Attack指<strong>模型参数$\theta$是已知的</strong>，Black Box Attack指<strong>模型参数$\theta$是未知的</strong>。</p><p>在Black Box Attack中，我们不知道Black Network的参数$\theta$。现假设我们知道Black Network的训练集，那我们就可以使用这份训练集自行训练出一个Proxy Network，然后基于Proxy Network和训练集就可以得到$x’$，这个$x’$一般也可以成功攻击Black Network。如果Black Network是一个在线API，我们既不知道Black Network的参数也不知道它的训练集，那上传大量输入后就可以得到大量对应的输出，并以这些输入输出对为训练集得到Proxy Network和$x’$。</p><p>有相关实验证明，Black Box Attack是非常有可能攻击成功的，详见：Delving into Transferable Adversarial Examples and Black-box Attacks(<a href="https://arxiv.org/abs/1611.02770" target="_blank" rel="noopener">https://arxiv.org/abs/1611.02770</a>)</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;p&gt;我们希望我们的模型不仅仅是在大多数情况下可用的，还希望它能够应对来自外界的“
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗攻击与防御" scheme="https://chouxianyu.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.5基于PyTorch的Explainabe AI实战</title>
    <link href="https://chouxianyu.github.io/2021/04/25/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-5%E5%9F%BA%E4%BA%8EPyTorch%E7%9A%84Explainabe-AI%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/04/25/李宏毅机器学习课程笔记-11-5基于PyTorch的Explainabe-AI实战/</id>
    <published>2021-04-25T01:48:58.000Z</published>
    <updated>2021-04-25T01:56:27.641Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework5的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><h1 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h1><p>在homework3中我们通过CNN实现了食物图片分类，详见我之前的文章《李宏毅机器学习课程笔记-7.4基于CNN和PyTorch的食物图片分类》，这次作业的任务就是探究这个CNN的可解释性，具体如下</p><ol><li><p><strong>Saliency Map</strong></p><p> 按照《Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps》，计算每个像素对最终分类结果的重要性。</p><p> 我們把一张图片输入到model，将model的输出与label进行对比计算得到loss，因此与loss相关的变量有image、model parameter和label这3者。</p><p> 通常情況下，我們训练模型时希望找到一组好的model parameter来拟合image和label，因此loss在backward时我们只在乎loss关于model parameter的梯度。但在数学上image本身也是continuous tensor，我们可以<strong>在model parameter和label都固定的情况下计算loss关于image的梯度，这个梯度代表稍微改变image的某个pixel value会对loss产生什么影响，我们习惯把这个影响的程度解读为该pixel对于结果的重要性（每个pixel都有自己的梯度）</strong>。</p><p> 因此将loss关于一张图片中每个pixel的梯度计算并画出来，就可以看出该图中哪些像素是model在计算结果时的重要依据。那如何用代码实现我们的这个想法呢？非常简单，在一般训练中我们都是在forward后计算模型输出与标签之间的loss，然后进行loss的backward，其实在PyTorch中这个backword计算的是loss对<strong>model parameter</strong>的梯度，因此我們只需要用一行代码<code>images.requires_grad_()</code>使得<strong>image</strong>也要被计算梯度。</p></li><li><p><strong>Filter Visualization</strong></p><p> 基于Gradient Ascent，实现Activation maximization，找到最能够激活某个filter的图片，以观察模型学到了什么。</p><p> 这里我们想要知道某一个filter到底学习到了什么，我们需要做两件事情：<strong>①Filter Visualization：挑几张图片看看某个filter的输出；②Filter Activation：看看什么图片可以最大程度地activate该filter</strong>。</p><p> 在代码实现方面，我们一般是直接把图片输入到model，然后直接forward，那要如何取出model中某层的输出呢？虽然我们可以直接修改model的forward函数使其返回某层的输出，但这样比较麻烦，还可能会因此改动其它部分的代码。因此PyTorch提供了方便的解决方法：<strong>hook</strong>。</p></li><li><p><strong>LIME</strong></p><p> 绿色代表一个component和结果正相关，红色则代表该component和结果负相关。</p><p> 《”Why Should I Trust You?”: Explaining the predictions of Any Classifier》</p><p> 注：根据助教的示例，我遇到了一个BUG<code>KeyError: &#39;Label not in explanation&#39;</code>，暂未解决……</p></li></ol><h1 id="数据集描述"><a href="#数据集描述" class="headerlink" title="数据集描述"></a>数据集描述</h1><p>使用homework3使用的数据集以及训练出的CNN模型。</p><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><p><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations" target="_blank" rel="noopener">https://github.com/utkuozbulak/pytorch-cnn-visualizations</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework5的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.4模型无关的局部解释(LIME)</title>
    <link href="https://chouxianyu.github.io/2021/04/24/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-4%E6%A8%A1%E5%9E%8B%E6%97%A0%E5%85%B3%E7%9A%84%E5%B1%80%E9%83%A8%E8%A7%A3%E9%87%8A-LIME/"/>
    <id>https://chouxianyu.github.io/2021/04/24/李宏毅机器学习课程笔记-11-4模型无关的局部解释-LIME/</id>
    <published>2021-04-24T02:36:52.000Z</published>
    <updated>2021-04-24T02:37:44.740Z</updated>
    
    <content type="html"><![CDATA[<p>模型无关的局部解释（Local Interpretable Model-Agnostic Explanations，LIME）指<strong>使用一个Interpretable Model拟合一个Uninterpretable Model的局部</strong>，比如使用Linear Model或者Decision Tree模拟Neural Network。</p><p>具体来讲，对于局部范围内的相同输入，我们希望两个模型的输出尽可能接近。这里要重点强调局部范围的概念，因为实际上Linear Model并不能模拟整个Neural Network但却可以模拟其中的一个Local Region，这也是LIME可行的原因。</p><h2 id="案例：使用Linear-Model拟合Neural-Network"><a href="#案例：使用Linear-Model拟合Neural-Network" class="headerlink" title="案例：使用Linear Model拟合Neural Network"></a>案例：使用Linear Model拟合Neural Network</h2><ol><li><p>定位：确定需要解释的data point(下图5个蓝点中最中间的蓝点)</p></li><li><p>取样：在上一步确定的data point周围sample获得更多的data point(下图5个蓝点)</p><p> sample的<strong>范围</strong>需要根据情况调整，一般范围小则拟合得更准确</p><p> sample的<strong>方法</strong>不同，结果也会不同</p></li><li><p>拟合：使用Linear Model模拟上一步确定的data point及其对应的Neural Network输出</p></li><li><p>解释：对Linear Model进行解释，进而解释Neural Network的局部</p></li></ol><p><img src="https://pic1.zhimg.com/80/v2-a29bafdc2312575cab096090938493b2_720w.png" alt="img"></p><h2 id="案例：LIME-For-Image-Classification"><a href="#案例：LIME-For-Image-Classification" class="headerlink" title="案例：LIME For Image Classification"></a>案例：LIME For Image Classification</h2><p>如何将LIME应用到Image Classification呢？假设有一张图片被分类为frog，下面只讲一些关键点。</p><ul><li><p>如何进行sample？</p><p>  首先可以将图片分成多个segment：$\{s_1,s_2,\dots,s_n\}$，随机去除其中的一些segment就可以得到该图片“周围”的一些图片</p></li><li><p>将LIME应用于图片时，一般要进行Feature Extraction，那如何做呢？</p><p>  使用$x_i$表示图片中的每个segment是否被删除，其中$i=1,…,n$，若$x_i$为1则表示该segment被删除，否则表示该segment未被删除</p></li><li><p>如何解释Linear Model？</p><p>  设Linear Model为$y=w_1x_1+..+w_nx_n$，$w_i$的值有以下3种情况</p><ul><li>$w_i\approx 0$表示$s_i$对分类为frog没有影响；</li><li>$w_i&gt; 0$表示$s_i$对分类为frog具有正面影响，即这个segment使得模型倾向于将图片分类为frog</li><li>$w_i&lt;0$表示$s_i$对分类为frog具有负面影响，即这个segment使得模型倾向于认为该图片不是frog类别</li></ul></li></ul><h2 id="Tree-Regularization"><a href="#Tree-Regularization" class="headerlink" title="Tree Regularization"></a>Tree Regularization</h2><p><strong>理论上可以用无深度限制的Decision Tree拟合完整的Neural Network，但Decision Tree的深度不可能没有限制</strong>，因此在使用Decision Tree拟合Neural Network时需要对Decision Tree的复杂度进行约束。</p><p>设Neural Network的参数为$\theta$、Decision Tree的参数为$T_\theta$，使用Decision Tree的平均深度表示其参数$T_\theta$的复杂度$O(T_\theta)$。在使用Decision Tree拟合Neural Network时，不仅要使两者输出相近还要使$O(T_\theta)$最小化，因此优化目标为$\theta^*=arg\ {\rm min}\ L(\theta) + \lambda O(T_\theta)$。</p><p>因此我们<strong>在训练神经网络时就可以使用Tree Regularization使得训练出的神经网络更具有可解释性</strong>，$O(T_\theta)$不能微分，解决方法详见《Beyond Sparsity: Tree Regularization of Deep Models for Interpretability》。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;模型无关的局部解释（Local Interpretable Model-Agnostic Explanations，LIME）指&lt;strong&gt;使用一个Interpretable Model拟合一个Uninterpretable Model的局部&lt;/strong&gt;，比如使用
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
      <category term="LIME" scheme="https://chouxianyu.github.io/tags/LIME/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.3Explainable AI(Global Explanation)</title>
    <link href="https://chouxianyu.github.io/2021/04/23/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-3Explainable-AI-Global-Explanation/"/>
    <id>https://chouxianyu.github.io/2021/04/23/李宏毅机器学习课程笔记-11-3Explainable-AI-Global-Explanation/</id>
    <published>2021-04-23T03:33:37.000Z</published>
    <updated>2021-04-23T03:34:13.996Z</updated>
    
    <content type="html"><![CDATA[<p>假定在图片分类任务中，<strong>Global Explanation要求机器说明它认为一个类别(比如“cat”)是什么样子，而非针对一张图片进行解释。</strong></p><h2 id="Activation-maximization"><a href="#Activation-maximization" class="headerlink" title="Activation maximization"></a>Activation maximization</h2><p>在<a href="https://zhuanlan.zhihu.com/p/361283328" target="_blank" rel="noopener">李宏毅机器学习课程笔记-7.2CNN学到了什么</a>一文中，我们已讲过Activation maximization，不再复述，这里讲一些相关的新知识。</p><ol><li>在Activation maximization的MNIST手写数字识别案例中，我们观察到机器学习到的数字在人类看来完全就是噪音，由此可以想到：将机器认为是数字(或其它事物)的内容作为噪声添加到其它数据中，也许这样就可以实现Attack。</li><li>在使用Activation maximization观察模型学习到的内容时，我们可能需要使用大量<strong>Regularization(保证“可解释性”)</strong>以及暴调超参数，详见《Understanding Neural Networks Through Deep Visualization》。</li></ol><h2 id="“Regularization”-From-Generator"><a href="#“Regularization”-From-Generator" class="headerlink" title="“Regularization” From Generator"></a>“Regularization” From Generator</h2><p><strong>除了使用人工设置的Regularization来告诉机器什么是一张正常的输出(比如image)，还可以使用Generator进行Regularization</strong>。</p><p>Image Generator的输入是一个低维向量$z$，其输出为一张图片$x$，即$x=G(z)$。通常这个低维向量$z$是从某个已知的distribution(比如高斯分布、正态分布)中sample出来的，我们可以收集很多图片并使用GAN或者VAE训练这个Generator。</p><p>那如何使用Image Generator生成对图片的限制呢？以图片分类为例，将Generator输出的图片$x$输入到Image Classifier中得到输出分类结果$y_i$，目标是找到一个$z^<em>$使得图片$x$属于对应类别$i$的可能性$y_i$最大，即$z^</em>=arg \ max y_i$。得到$z^<em>$之后将其输入至Image Generator就可以得到一个图片$x$。如果通过$x^</em>=arg \ max y_i$直接得到图片呢，则不能保证结果的“可解释性”，因而需要对结果进行“可解释性”的约束，上述过程中Generator的作用就是对图片进行约束以确保生成的图片$x$是“可解释”的。</p><p>注：在进行$z^*=arg \ max y_i$时，Image Generator和Classifier的参数是不参与本次训练的。</p><p>那使用Generator能得到什么样的结果呢？结果挺好的，详见《Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space》。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假定在图片分类任务中，&lt;strong&gt;Global Explanation要求机器说明它认为一个类别(比如“cat”)是什么样子，而非针对一张图片进行解释。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;Activation-maximization&quot;&gt;&lt;a href=&quot;#Ac
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.2Explainable AI(Local Explanation)</title>
    <link href="https://chouxianyu.github.io/2021/04/22/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-2Explainable-AI-Local-Explanation/"/>
    <id>https://chouxianyu.github.io/2021/04/22/李宏毅机器学习课程笔记-11-2Explainable-AI-Local-Explanation/</id>
    <published>2021-04-22T00:40:25.000Z</published>
    <updated>2021-04-22T00:41:07.591Z</updated>
    
    <content type="html"><![CDATA[<p>假定在图片分类任务中有一张图片，<strong>Local Explanation</strong>则要求机器说明为什么它认为这张图片是某个类别(比如“cat”)。</p><p>Explainable AI(<strong>Local Explanation</strong>)的目标是，知道每个component对于最终结果的重要性。我们可以通过remove或者modify其中一个component，看decision会有什么变化。</p><h2 id="基于梯度判断Component重要性"><a href="#基于梯度判断Component重要性" class="headerlink" title="基于梯度判断Component重要性"></a>基于梯度判断Component重要性</h2><p>假设输入是$x$，它有很多component $\{x_1,x_2,\dots,x_N\}$组成。如果输入是image，则component一般是pixel、segment或patch等；如果输入是text，则component一般是word。对于图片，我们可以在图片上“放置”一个灰块以覆盖图像的一小部分，观察其对结果的影响，见《<strong>Visualizing <em>and</em> Understanding Convolutional Networks</strong>》。注：component的选取、remove或者modify也是需要研究的。</p><p>还有另一种方法是，输入为$\{x_1,…,x_n\}$，对某个pixel $x_n$加上$\Delta x$，用$\frac{\Delta y}{\Delta x}$来表示扰动$\Delta x$对结果$y$的影响，即通过$\frac{\partial y_k}{\partial x_n}$的绝对值表示某个pixel对$y_k$的影响，见《<strong>Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</strong>》。</p><p>还有很多其它<strong>基于梯度来判断Component重要性</strong>的方法：</p><ul><li><p>Grad-CAM</p></li><li><p>SmoothGrad</p></li><li><p>Layer-wise Relevance Propagation(LRP)</p><p>  Redistribute the output, Backward propagation until reaching input</p></li><li><p>Guided Backpropagation</p></li></ul><h2 id="梯度饱和"><a href="#梯度饱和" class="headerlink" title="梯度饱和"></a>梯度饱和</h2><p>基于梯度来判断component重要性的方法也存在着局限性：<strong>梯度饱和(Gradient Saturation)和Noisy Gradient</strong>。</p><p>考虑$\frac{\partial大象}{\partial鼻子长度}$，可知在一定范围内，鼻子越长，则判定为大象的概率就越大，但随着鼻子长度增加到一定数值后，鼻子长度对于判定大象的影响几乎为0，这时就出现了梯度饱和，如下图所示。</p><p><img src="https://pic4.zhimg.com/80/v2-ccef0f3a481afd976ed03ce3e6a12484_720w.png" alt="img"></p><p>那如何解决梯度饱和的问题呢？解决方法就是<strong>Global Explanation</strong>，可以参考Integrated gradient和DeepLIFT。</p><p>相对于梯度饱和，另外一个问题就是<strong>Noisy Gradient</strong>，即Gradient变化非常大，解决方法是<strong>SmoothGrad</strong>（在计算梯度时添加噪声以扰动生成多个样本，并计算平均梯度）</p><h2 id="Attack-Interpretation"><a href="#Attack-Interpretation" class="headerlink" title="Attack Interpretation"></a>Attack Interpretation</h2><p>向输入中加入一些细微的噪声，这样并不影响视觉效果和模型的输出，但这样可以<strong>攻击explanation</strong>，如下图所示，详见《Interpretation of Neural Networks is Fragile》。</p><p><img src="https://pic2.zhimg.com/80/v2-704a838681754edb670b33ef0c228987_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假定在图片分类任务中有一张图片，&lt;strong&gt;Local Explanation&lt;/strong&gt;则要求机器说明为什么它认为这张图片是某个类别(比如“cat”)。&lt;/p&gt;
&lt;p&gt;Explainable AI(&lt;strong&gt;Local Explanation&lt;/stron
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-11.1Explainable AI引言</title>
    <link href="https://chouxianyu.github.io/2021/04/21/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-11-1Explainable-AI%E5%BC%95%E8%A8%80/"/>
    <id>https://chouxianyu.github.io/2021/04/21/李宏毅机器学习课程笔记-11-1Explainable-AI引言/</id>
    <published>2021-04-21T01:48:40.000Z</published>
    <updated>2021-04-21T01:58:47.017Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Explainable-AI是什么"><a href="#Explainable-AI是什么" class="headerlink" title="Explainable AI是什么"></a>Explainable AI是什么</h2><p>我们希望，机器不仅要知道“是什么”还要知道“为什么”，或者说<strong>机器不仅要给出答案还要给出explanation</strong>。</p><p>Explanation可以分为两类：</p><ol><li><p><strong>Local Explanation</strong></p><p> 假定在图片分类任务中有一张图片，要求机器说明<strong>为什么它认为这张图片是某个类别(比如“cat”)</strong>。</p></li><li><p><strong>Global Explanation</strong></p><p> 假定在图片分类任务中，要求机器说明<strong>它认为一个类别(比如“cat”)是什么样子</strong>，而非针对一张图片进行解释。</p></li></ol><h2 id="Explainable-AI有什么用"><a href="#Explainable-AI有什么用" class="headerlink" title="Explainable AI有什么用"></a>Explainable AI有什么用</h2><p>在使用机器挑选简历时，我们需要知道机器为什么选择某份简历(性别?还是实力)。</p><p>在使用机器判定罪犯是否可以假释时，我们需要知道机器为什么判定是或否(实证?还是肤色)。</p><p>在使用机器判定是否给某人贷款时，我们需要知道机器为什么判定是或否。</p><p>通过Explainable AI，我们可以知道模型学到了什么从而进行模型诊断，对模型进行改进和调整。我们不仅只关注模型在数据集上的精确度，还需要进行模型诊断，因为有可能精确度很高但实际上机器什么都没学到。</p><h2 id="Explainable-AI是否有必要"><a href="#Explainable-AI是否有必要" class="headerlink" title="Explainable AI是否有必要"></a>Explainable AI是否有必要</h2><p>李宏毅老师认为Explainable AI的目标并非完全理解模型是如何work的，而是为了让人感到comfortable。</p><p>因为深度学习是一个黑盒所以有些人认为深度学习不可信，这有些因噎废食。人脑等很多事物对现在的人类来讲都也还是黑盒，完全理解模型的work机理不是必要的，因为某些东西是黑盒就不使用它也不行。</p><p>Explainable AI其实就是为了使老板、客户、自己等感到comfortable，甚至对不同人也应该有不同的解释。</p><h2 id="Interpretable-VS-Powerful"><a href="#Interpretable-VS-Powerful" class="headerlink" title="Interpretable VS Powerful"></a>Interpretable VS Powerful</h2><p>决策树既是interpretable又是powerful的，但当分支特别多的时候决策树的表现也会很差，这时可以使用Random Forest或者XGBoost，但它们虽然powerful但不interpretable。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Explainable-AI是什么&quot;&gt;&lt;a href=&quot;#Explainable-AI是什么&quot; class=&quot;headerlink&quot; title=&quot;Explainable AI是什么&quot;&gt;&lt;/a&gt;Explainable AI是什么&lt;/h2&gt;&lt;p&gt;我们希望，机器不仅要
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ExplainableAI" scheme="https://chouxianyu.github.io/tags/ExplainableAI/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.4基于Smoothness假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-4%E5%9F%BA%E4%BA%8ESmoothness%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/19/李宏毅机器学习课程笔记-10-4基于Smoothness假设的半监督学习/</id>
    <published>2021-04-19T00:27:39.000Z</published>
    <updated>2021-04-19T00:29:53.557Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Smoothness假设"><a href="#Smoothness假设" class="headerlink" title="Smoothness假设"></a>Smoothness假设</h2><h3 id="Smoothness假设的定义"><a href="#Smoothness假设的定义" class="headerlink" title="Smoothness假设的定义"></a>Smoothness假设的定义</h3><p>基于Smoothness假设的半监督学习的基本思路是“近朱者赤近墨者黑”，即<strong>相似的$x$具有相同的$\hat y$</strong>，其具体<strong>定义</strong>为：</p><ol><li>$x$的<strong>分布不平均</strong>，在某些地方(high density region)很集中，在某些地方很分散</li><li>如果$x^1$和$x^2$在一个<strong>high density region</strong>中距离非常近，则$x^1$和$x^2$通过1个<strong>high density path</strong>相连、$\hat y^1=\hat y^2$。</li></ol><p>举一个例子，如下图所示，$x^1,x^2,x^3$是3个样本，如果单纯地看它们之间的相似度，显然$x^2$和$x^3$更接近一些。但对于smoothness assumption来说，$x^1$和$x^2$是位于同一个high density region中，它们之间有high density path；而$x^2$与$x^3$之间则是“断开”的，没有high density path，因此$x^1$与$x^2$更“像”。</p><p><img src="https://pic1.zhimg.com/80/v2-a45cf1b179557c638d294edf952053a2_720w.png" alt="img"></p><h3 id="手写数字识别举例"><a href="#手写数字识别举例" class="headerlink" title="手写数字识别举例"></a>手写数字识别举例</h3><p>再举一个手写数字识别和人脸识别的例子，如下图所示，最左侧的2、最右侧的2和最右侧的3，从<strong>pixel角度</strong>来看明显是最右侧的2和3更加相似(尽管两者并非是同一个数字)，但如果考虑最左侧的2朝着最右侧的2的演化过程，可以发现产生了一种“<strong>间接相似性</strong>”(high density path)。根据Smoothness假设，由于这6个2之间存在间接的相似而这6个2和最右侧的3之间不存在high density path，因此这6个2是彼此相似的；而最右侧的3和这6个2是不相似的。</p><p><img src="https://pic4.zhimg.com/80/v2-c8fd736cc00ef0209e973b93b62b2541_720w.png" alt="img"></p><h3 id="文章分类举例"><a href="#文章分类举例" class="headerlink" title="文章分类举例"></a>文章分类举例</h3><p>假设对天文学(astronomy)和旅行(travel)的文章进行分类，它们有各自的专属词汇，此时如果unlabeled data与label data的词汇是相同或重合(overlap)的，那么就很容易分类；但真实情况中unlabeled data和labeled data之间可能没有任何重复的word，因为世界上的词汇太多了，sparse的分布中overlap难以发生。</p><p>但如果unlabeled data足够多，就会以一种<strong>相似传递</strong>的形式，建立起文档之间相似的桥梁。</p><h2 id="cluster-and-then-label"><a href="#cluster-and-then-label" class="headerlink" title="cluster and then label"></a>cluster and then label</h2><p>如何实现基于Smoothness假设的半监督学习呢？在具体实现上，最简单的方式是cluster and then label。</p><p>cluster and then label就是先<strong>把所有样本(包括有标签样本和无标签样本)分成几个cluster，然后根据每个cluster中各类别有标签样本的数量确定该cluster中所有样本的label，然后进一步用这些cluster学习得到分类器</strong>。</p><p>这种方法不一定会得到好的结果，因为该方法有个<strong>前提是我们能够把同类别的样本分到同一个cluster</strong>，而这并不容易。对图像分类来说，如果仅仅依据pixel-wise相似度来划分cluster，得到的结果一般都会很差。所以为了满足这个前提，我们需要设计较好的方法来描述一张图片(比如使用Deep Autoencoder提取图片特征feature)，以保证cluster时能够将同类别的样本分到同一个cluster。</p><h2 id="Graph-based-Approach"><a href="#Graph-based-Approach" class="headerlink" title="Graph-based Approach"></a>Graph-based Approach</h2><h3 id="high-density-path"><a href="#high-density-path" class="headerlink" title="high density path"></a>high density path</h3><p>如何实现基于Smoothness假设的半监督学习呢？我们可以将每个样本视为图中的1个点，<strong>通过图来表示connected by a high density path</strong>。Graph-based方法的基本思路是图中的有标注样本会影响与它们邻近的无标注样本并在图中产生“<strong>间接相似性</strong>”，即使某些无标注样本没有直接与有标注样本相连也仍然可以被判定为相似。如果想要让这种方法生效，<strong>收集到的数据一定要足够多</strong>，否则可能导致无法形成path、失去了information的传递效果。</p><h3 id="如何建立一张图"><a href="#如何建立一张图" class="headerlink" title="如何建立一张图"></a>如何建立一张图</h3><p>有时候点之间的边是比较好建立的(比如网页超链接、论文引用)，有时候需要我们自行建立点之间的边。图的好坏对最终结果的影响是非常关键的，但如何建图是一件heuristic的事情，需要我们凭经验和直觉来做，<strong>建图步骤</strong>如下：</p><ol><li><p>定义两个样本$x^i,x^j$之间的相似度计算方法$s(x^i,x^j)$</p><p> 如果是基于pixel-wise的相似度，那结果可能比较差，建议使用更好的方法(比如使用Autoencoder提取图片特征，并基于提取到的特征计算相似度)。</p><p> 推荐使用的相似度计算方法为高斯径向基函数(Gaussian Radial Basis Function)：$s(x^i,x^j)=exp(-\gamma||x^i-x^j||^2)$，其中$x^i,x^j$均为vector。经验上来说exp(exponential)通常是可以帮助提升性能的，因为它使得仅当$x^i,x^j$非常接近时similarity才会大、只要距离稍微远一点similarity就会迅速变小，也就是使用exponential可以做到<strong>只有非常近的两个点才能相连、稍微远一点就无法相连</strong>的效果。</p></li><li><p>建立点和点之间的边</p><ul><li><p>k-Nearest Neighbor(K近邻算法)</p><p>  在特征空间中，如果一个样本附近的k个最近样本的大多数属于某一类别，则该样本也属于这个类别</p></li><li><p>e-Neighborhood</p></li></ul></li><li><p>设置点和点之间边的权重</p><p> 一条边的权重应该和该边两个顶点的相似度成比例</p></li></ol><h3 id="如何定量地评估一个图符合Smoothness假设的程度"><a href="#如何定量地评估一个图符合Smoothness假设的程度" class="headerlink" title="如何定量地评估一个图符合Smoothness假设的程度"></a>如何定量地评估一个图符合Smoothness假设的程度</h3><p>那如何定量地评估一个图符合Smoothness假设的程度呢？</p><p><img src="https://pic1.zhimg.com/80/v2-db490c6a659a6fb1765c956d9f584cac_720w.png" alt="img"></p><p>如上图所示，我们定义1个图的<strong>Smoothness</strong>为$S=\frac{1}{2}\sum_{i,j}w_{i,j}(y^i-y^j)^2$并希望它<strong>越小越好</strong>，其中$i,j$为所有样本点的索引、$x^i$表示样本的特征、$y^j$表示样本的标注(有可能是伪标签)、$w_{i,j}$是2个样本之间边的权重、$\frac{1}{2}$只是为了方便计算。</p><p>上式Smoothness定义还可以表示为$S=y^TLy$，其中$y$是1个(R+U)-dim的vector：$y=[\dots,y^i,\dots,y^j,\dots]^T$、$L$是1个(R+U)×(R+U)的矩阵(名字叫做Graph Laplacian)。</p><p>Graph Laplacian的定义为$L=D-W$，其中$W_{i,j}$为2个样本点之间边的权重，把$W$每行元素之和放在该行对应的对角线上其它元素值为0即可得到$D$，如上图所示。在图神经网络(Spectral-based Convolution)中，有关于Graph Laplacian的介绍。</p><h3 id="如何训练"><a href="#如何训练" class="headerlink" title="如何训练"></a>如何训练</h3><p>Smoothness定义$S=y^TLy$中$y$是模型的输出(预测得到的类别)，它是取决于模型参数的，因此训练时仅需在有标注数据的损失函数上加上Smoothness即可：$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda S$，其中$\lambda S$可以被视为正则项。</p><p>由上可知，<strong>训练目标</strong>为：</p><ol><li>有标注数据的交叉熵越小越好，即模型的输出与标注越接近越好</li><li>所有数据的Smoothness越小越好，即不管是有标注数据还是无标注数据，模型输出都要符合Smoothness Assumption的假设</li></ol><p>注：训练时可以不仅仅要求整个模型的输出层要smooth，还可以对模型中任意一个隐藏层加上smooth的限制。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Smoothness假设&quot;&gt;&lt;a href=&quot;#Smoothness假设&quot; class=&quot;headerlink&quot; title=&quot;Smoothness假设&quot;&gt;&lt;/a&gt;Smoothness假设&lt;/h2&gt;&lt;h3 id=&quot;Smoothness假设的定义&quot;&gt;&lt;a href=
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.3基于Low-density Separation假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/18/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-3%E5%9F%BA%E4%BA%8ELow-density-Separation%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/18/李宏毅机器学习课程笔记-10-3基于Low-density-Separation假设的半监督学习/</id>
    <published>2021-04-18T07:17:34.000Z</published>
    <updated>2021-04-18T07:18:14.773Z</updated>
    
    <content type="html"><![CDATA[<p>按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即<strong>假设不同类别数据之间应该有1个很明显的boundary</strong>。</p><h3 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h3><p>最简单的基于Low-density Separation假设的半监督学习是Self-training。</p><ol><li><p>使用有标签的数据训练1个模型$f^*$，模型类型和训练方式没有限制，神经网络、深或浅、其它机器学习方法等等都可以</p></li><li><p>使用模型$f^<em>$生成未标注数据的伪标签(Pseudo-label)，即$y^u=f^</em>(x^u)$</p></li><li><p>取出一部分未标注数据将它们添加到有标签数据中，然后回到步骤1</p><p> 如何选择未标注数据仍然是一个open question，可以自行设计策略，比如给每个样本一个置信度。</p></li></ol><p>Self-training和<strong>生成模型中的半监督学习</strong>(见上1篇文章)还挺像的，它们的区别在于：</p><ol><li>Self-training使用<strong>hard label</strong>，即假定某个无标签样本一定属于某个类别(“非黑即白”)</li><li>生成模型使用<strong>soft label</strong>，即假定某个无标签样本有一定概率属于某类别(也可以理解为一个样本可以按照后验概率划分成多个部分，不同部分属于不同类别)</li></ol><p>Self-training使用了hard label，它并不适用于regression。</p><p>生成模型使用了soft label，它生成的伪标签在分类任务中是没有用的。因为把某个无标签样本(通过soft label生成伪标签)丢进模型重新训练模型，模型参数根本不会发生变化。</p><p>实际上，low-density separation就是<strong>通过hard label来提升分类效果</strong>的方法。</p><h3 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h3><p>该方法是Self-training的进阶版。</p><p>Self-training中使用的hard label还是有些武断和激进，Entropy-based Regularization对此进行了改进。</p><p><strong>在使用神经网络进行分类时，$y^u=f^<em>_{\theta^</em>}(x^u)$，其中$y_u$是1个one-hot编码。现在我们并不限制其必须是某个类别，而是将其看做1个分布，我们希望这个分布越集中越好(“非黑即白”)，因为分布越集中时它的含义就是样本$x^u$属于某类别的概率很大属于其它类别的概率很小</strong>。</p><p>我们可以使用Entropy评估分布$y^u$的集中程度$E(y^u)=-\sum_{m=1}^5y_m^uln(y_m^u)$，假设是5分类，其值越小则表示分布$y^u$越集中。</p><p>无监督分类的目标为有标签数据分类正确、无标签数据分类结果集中，所以损失函数则为$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda\sum_{x^u}E(y^u)$，其中第1项为有标签数据的交叉熵损失、第2项为无标签数据的entropy、$\lambda$表示无标签数据的损失权重，因为式中第2项的作用类似于regularization，所以该方法被称为Entropy-based Regularization。</p><h3 id="Semi-supervised-SVM"><a href="#Semi-supervised-SVM" class="headerlink" title="Semi-supervised SVM"></a>Semi-supervised SVM</h3><p>SVM为两个类别的数据找到一个boundary，该boundary与两个类别的margin最大、分类错误最小。</p><p>Semi-supervised SVM穷举所有无标签数据的类别并进行计算，最终选择与两个类别的margin最大、分类错误最小的boundary。</p><p>在数据量大的时候，Semi-supervised SVM难以穷举出所有情况，但还有一种求近似解的方法，其大致思路是初始化一些label，然后每次尝试改动1个样本的label并判断是否更优，如果更优则改变该样本的label，具体见Transductive Inference for Text Classification using Support Vector Machines。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即&lt;strong&gt;假设不同类别数据之间应该有1个很明显的boundary&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;Self-training&quot;&gt;&lt;a href=&quot;#Self-training&quot;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.2生成模型中的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/17/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-2%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/17/李宏毅机器学习课程笔记-10-2生成模型中的半监督学习/</id>
    <published>2021-04-17T02:46:22.000Z</published>
    <updated>2021-04-17T02:49:17.526Z</updated>
    
    <content type="html"><![CDATA[<p>生成模型中的半监督学习：Semi-supervised Learning for Generative Model</p><h2 id="有监督生成模型"><a href="#有监督生成模型" class="headerlink" title="有监督生成模型"></a>有监督生成模型</h2><p>有监督生成模型：Supervised Generative Model</p><p>如下图所示，在有监督生成模型中，得到$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$后，就可以计算出$x$属于类别$C_i$的概率$P(C_i|x)$。</p><p><img src="https://pic4.zhimg.com/80/v2-ee9b2801a6e660c4526a62103c10d2e0_720w.png" alt="img"></p><h2 id="半监督生成模型"><a href="#半监督生成模型" class="headerlink" title="半监督生成模型"></a>半监督生成模型</h2><p>半监督生成模型：Semi-supervised Generative Model</p><p>基于有监督生成模型，当有了无标签数据之后(下图中绿色圆点)，我们会明显发现有监督生成模型中的$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$并不够正确，比如2个类别的分布应该接近于下图中虚线圆圈、先验概率$P(C_1)$应该小于$P(C_2)$，所以应该使用无标签数据重新估计$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$。</p><p><img src="https://pic4.zhimg.com/80/v2-a334756241f389f2ca620c5f35ab5269_720w.png" alt="img"></p><h3 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h3><p>具体来讲，按照以下步骤进行计算：</p><ol><li><p>初始化参数：$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><p> 可以随机初始化，也可以用有标签数据估算</p></li><li><p>通过$\theta$计算每个样本$x^u$属于类别$C_i$的概率$P_\theta(C_i|x^u)$</p></li><li><p><strong>更新参数$\theta$</strong>（其实重点就是如何同时利用有标签数据和无标签数据实现半监督）</p><ul><li>$P(C_1)=\frac{N_1+\sum_{x^u}P(C_1|x^u)}{N}$，其中$N$是所有样本的数量、$N_1$是属于类别$C_1$的样本的数量。</li><li>$\mu^1=\frac{1}{N_1}\sum_{x^r\in C_1}x^r+\frac{1}{\sum_{x^u}P(C_1|x^u)}\sum_{x^u}P(C_1|x^u)x^u$，其中$x^r,x^u$分别指有标签的样本和无标签的样本</li></ul><p>同理可知其它参数的计算和更新方法</p></li><li><p>返回第2步</p></li></ol><p>理论上，上述步骤是可以收敛的，但参数$\theta$的初始化值会影响结果。其实上面的第2步是EM算法中的E，第3步是EM算法中的M。</p><h3 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h3><p>$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><ul><li><p>Maximum likelihood with labelled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)$最大(有一个Closed-form solution)，其中每个有标注样本$x^r$的$P_\theta(x^r,\hat y^r)=P_\theta(x^r|\hat y^r)P(\hat y^r)$。</p></li><li><p>Maximum likelihood with labelled &amp; unlabeled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)+\sum_{x^u}logP_\theta(x^u)$最大(该式并不是凹函数，所以需要迭代求解)，其中每个无标注样本$x^u$的$P_\theta(x^u)=P_\theta(x^u|C_1)P(C_1)+P_\theta(x^u|C_2)P(C_2)$</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生成模型中的半监督学习：Semi-supervised Learning for Generative Model&lt;/p&gt;
&lt;h2 id=&quot;有监督生成模型&quot;&gt;&lt;a href=&quot;#有监督生成模型&quot; class=&quot;headerlink&quot; title=&quot;有监督生成模型&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概率生成模型" scheme="https://chouxianyu.github.io/tags/%E6%A6%82%E7%8E%87%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.1半监督学习简介</title>
    <link href="https://chouxianyu.github.io/2021/04/16/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-1%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>https://chouxianyu.github.io/2021/04/16/李宏毅机器学习课程笔记-10-1半监督学习简介/</id>
    <published>2021-04-16T00:22:16.000Z</published>
    <updated>2021-04-16T00:50:25.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有监督学习-Supervised-Learning"><a href="#有监督学习-Supervised-Learning" class="headerlink" title="有监督学习(Supervised Learning)"></a>有监督学习(Supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R$，其中每组数据包括算法的输入与输出(标签)。</p><h2 id="半监督学习-Semi-supervised-Learning"><a href="#半监督学习-Semi-supervised-Learning" class="headerlink" title="半监督学习(Semi-supervised Learning)"></a>半监督学习(Semi-supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R+\{ x^u\}_{u=R+1}^{U+R}$，即其中部分数据有标签而大量数据没有标签($U&gt;&gt;R$)。</p><p>半监督学习可以分为以下2种情况</p><ol><li><p><strong>Transductive Learning</strong></p><p> unlabeled data is the testing data，只使用testing data中的feature，并没有使用testing data中的label，所以并没有cheating。</p><p> 适用于已知testing data的情况，比如kaggle比赛。</p></li><li><p><strong>Inductive Learning</strong></p><p> unlabeled data is not the testing data，完全不使用testing data。</p><p> 适用于testing data未知的情况，这是大多数情况。</p></li></ol><h2 id="为什么需要半监督学习"><a href="#为什么需要半监督学习" class="headerlink" title="为什么需要半监督学习"></a>为什么需要半监督学习</h2><p>其实缺的并不是数据，缺少的是有标签的数据。利用这些大量的没有标签的数据进行学习，这是非常有价值的。</p><h2 id="为什么半监督学习有用"><a href="#为什么半监督学习有用" class="headerlink" title="为什么半监督学习有用"></a>为什么半监督学习有用</h2><p>The <strong>distribution</strong> of the unlabeled data tell us something：无标注数据的分布可以告诉我们一些东西</p><p><img src="https://pic3.zhimg.com/80/v2-676d19916cb98d7f251ff22a08eec087_720w.png" alt="img"></p><p><strong>半监督学习往往伴随着假设，而该假设的合理与否决定了结果的好坏程度。</strong>如上图所示，在猫狗图片分类中一只狗被认为是一只猫，这很可能是由于这2张图片的背景都是绿色，因此假设的合理性至关重要。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;有监督学习-Supervised-Learning&quot;&gt;&lt;a href=&quot;#有监督学习-Supervised-Learning&quot; class=&quot;headerlink&quot; title=&quot;有监督学习(Supervised Learning)&quot;&gt;&lt;/a&gt;有监督学习(Supe
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.6基于RNN和PyTorch的文本情感分类</title>
    <link href="https://chouxianyu.github.io/2021/04/15/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-6%E5%9F%BA%E4%BA%8ERNN%E5%92%8CPyTorch%E7%9A%84%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/"/>
    <id>https://chouxianyu.github.io/2021/04/15/李宏毅机器学习课程笔记-9-6基于RNN和PyTorch的文本情感分类/</id>
    <published>2021-04-15T00:22:18.000Z</published>
    <updated>2021-04-15T00:45:28.163Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework4的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述</p><p>  通过RNN实现文本情感分类(Text Sentiment Classification)。</p></li><li><p>数据集描述</p><p>  输入是1个句子，输出是0(负面)或1(正面)。</p><p>  训练集：标注数据20万，无标注数据120万</p><p>  测试集：20万(无标注)</p></li><li><p>数据格式</p><ul><li>training_label.txt：<code>label +++$+++ sentence</code>，其中<code>+++$+++</code>只是分隔符</li><li>training_nolabel.txt：每一行就是一个句子，没有label</li><li>testing_data.txt：</li></ul></li><li><p>数据预处理</p><p>  一个句子(sentence)中有多个word，我们需要通过<strong>Word Embedding</strong>(我的其它文章里有介绍)用一个vector表示一个word， 然后使用RNN得到一个表示该sentence的vector。</p></li><li><p>半监督学习</p><p>  这里使用一种半监督学习方法：<strong>Self-Training</strong>(我的其它文章里有介绍)。使用有标签数据训练好模型，然后对无标签数据进行预测，并根据预测结果对无标签数据进行标注(“伪标签”)并继续训练模型</p></li><li><p>第三方库</p><p>  使用Python第三方库<code>gensim</code>实现word2vec模型，以进行Word Embedding。</p></li><li><p>代码</p><p>  <a href="https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw4_RNN" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw4_RNN</a></p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework4的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.5详解基于LSTM的RNN</title>
    <link href="https://chouxianyu.github.io/2021/04/14/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-5%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84RNN/"/>
    <id>https://chouxianyu.github.io/2021/04/14/李宏毅机器学习课程笔记-9-5详解基于LSTM的RNN/</id>
    <published>2021-04-14T02:38:35.000Z</published>
    <updated>2021-04-14T02:40:15.998Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1层LSTM神经元的架构"><a href="#1层LSTM神经元的架构" class="headerlink" title="1层LSTM神经元的架构"></a>1层LSTM神经元的架构</h2><p>根据上述内容，你可能看不出LSTM与RNN有什么关系，接下来具体介绍LSTM在RNN中的应用。</p><p>假设我们现在有一些LSTM（下图中白色部分）作为神经元，每个LSTM的memory cell里都存了一个scalar值（下图中红框中内容），把这些scalar连接起来就组成了1个vector $c^{t-1}$，即关于上个input（时间点为t-1）的memory。</p><p><img src="https://pic4.zhimg.com/80/v2-d96ed6d363d633b87729a22badf815a9_720w.png" alt="img"></p><p><strong>在时间点t，输入为1个vector $x^t$，它会经过4个线性的transform得到$z^f,z^i,z,z^o$，$z^f,z^i,z,z^o$这4个vector的dimension数量和LSTM神经元的数量相等，这4个vector的1个dimension即为1个LSTM神经元的输入（4个vector的第1个dimension为第1个LSTM神经元的输入）。</strong></p><h2 id="1个LSTM神经元的运算方法"><a href="#1个LSTM神经元的运算方法" class="headerlink" title="1个LSTM神经元的运算方法"></a>1个LSTM神经元的运算方法</h2><p>下图是单个LSTM神经元的运算方法，其4个input分别是$z$、$z^i$、$z^f$和$z^o$的其中1维（1维为1个神经元的输入）。每个LSTM神经元的input是各不相同的，但它们可以共同运算。</p><p>1个LSTM神经元的运算方法如下图所示。</p><p><img src="https://pic3.zhimg.com/80/v2-bc5c546a495db0ef197f4527f841562c_720w.png" alt="img"></p><p>$f(z^f)$与上一个时间点的memory $c^{t-1}$对应的cell值相乘，加上$g(z)$与$f(z^i)$的乘积，得到该时刻该cell中的值$c^t$，最终再乘以output gate的信号$f(z^o)$，得到输出$y^t$。</p><h2 id="1个LSTM神经元在相邻时刻时的运算方法"><a href="#1个LSTM神经元在相邻时刻时的运算方法" class="headerlink" title="1个LSTM神经元在相邻时刻时的运算方法"></a>1个LSTM神经元在相邻时刻时的运算方法</h2><p><img src="https://pic1.zhimg.com/80/v2-993d9ee86e0180e96e405e6b3248b41f_720w.png" alt="img"></p><p>上图是同1个LSTM神经元在2个相邻时刻的运算方法，其中与前文描述略有不同的是，这里还需要把当前时刻该神经元的输出$y^t$以及该神经元中cell保存的值$c^t$（peephole）都连接到下一时刻的输入上。因此在$t+1$时刻，神经元不只是考虑当前的输入$x^{t+1}$，还要看前一时刻该神经元的输出$h^t$和cell保存值$c^t$。</p><p>如何考虑结合$t+1$时刻的输入$x^{t+1}$和上一时刻该神经元的信息$h^t,c^t$呢？====&gt;<strong>把$x^{t+1}$、$h^t$和$c^t$这3个vector并在一起</strong>，乘上4个不同的转换矩阵，得到该神经元$t+1$时刻的4个输入$z$、$z^i$、$z^f$、$z^o$。</p><h2 id="多层LSTM在相邻时刻的运算方法"><a href="#多层LSTM在相邻时刻的运算方法" class="headerlink" title="多层LSTM在相邻时刻的运算方法"></a>多层LSTM在相邻时刻的运算方法</h2><p><img src="https://pic2.zhimg.com/80/v2-a6435474533a8871ad59ed5443055159_720w.png" alt="img"></p><p>上图中左边一列的2个LSTM代表2层LSTM，右边一列的2个LSTM则代表它们在下一时刻的状态。即横向是时间轴，纵向是层轴。</p><p>虽然看起来很复杂，感觉不一定work，但LSTM在RNN中已成为了标准做法。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1层LSTM神经元的架构&quot;&gt;&lt;a href=&quot;#1层LSTM神经元的架构&quot; class=&quot;headerlink&quot; title=&quot;1层LSTM神经元的架构&quot;&gt;&lt;/a&gt;1层LSTM神经元的架构&lt;/h2&gt;&lt;p&gt;根据上述内容，你可能看不出LSTM与RNN有什么关系，接下来
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.4LSTM入门</title>
    <link href="https://chouxianyu.github.io/2021/04/13/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-4LSTM%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/13/李宏毅机器学习课程笔记-9-4LSTM入门/</id>
    <published>2021-04-13T00:35:26.000Z</published>
    <updated>2021-04-13T00:47:38.903Z</updated>
    
    <content type="html"><![CDATA[<p>LSTM即Long Short-term Memory。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>前几篇文章提到的RNN都比较简单，可以任意读写memory，没有进一步对memory进行管理。<strong>现在常用的memory管理方式是LSTM</strong>。正如其名，LSTM是比较长的短期记忆，<code>-</code>是在short和term之间。<strong>前几篇提到的RNN在有新的输入时都会更新memory，这样的memory是非常短期的，而LSTM中可以有更久之前的memory</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-2d2d4f677d917a001fcf379e00472bbf_720w.png" alt="img"></p><p>如上图所示，LSTM中有3个gate、4个输入(3个gate控制信号和1个想要写入memory cell的值)和1个输出：</p><ul><li>input gate：当某个neuron的输出想要被写进memory cell，它要先经过input gate。如果input gate是关闭的，则任何内容都无法被写入。input gate的关闭与否、什么时候开闭是由神经网络学习到的。</li><li>output gate：output gate决定了外界是否可以从memory cell中读取数据。当output gate关闭的时候，memory里面的内容无法被读取。output gate的关闭与否、什么时候开闭也是由神经网络学习到的。</li><li>forget gate：forget gate决定什么时候需要把memory cell里存放的内容忘掉，什么时候要保存。这也是由神经网络学习到的。</li></ul><h2 id="LSTM计算式"><a href="#LSTM计算式" class="headerlink" title="LSTM计算式"></a>LSTM计算式</h2><p>下图展示了LSTM的计算式。</p><p><img src="https://pic1.zhimg.com/80/v2-de00669f5a90c477fb32b2fffb71571d_720w.png" alt="img"></p><ul><li>$z$是想要被存到memory cell里的值</li><li>$z_i$是input gate的控制信号</li><li>$z_o$是output gate的控制信号</li><li>$z_f$是forget gate的控制信号</li><li>$a$是综合上述4个输入得到的输出值</li></ul><p>$z$、$z_i$、$z_o$和$z_f$通过激活函数分别得到$g(z)$、$f(z_i)$、$f(z_o)$和$f(z_f)$，其中$z_i$、$z_o$和$z_f$的激活函数$f()$一般会选sigmoid函数，因为其输出在0~1之间，可表示gate的开启程度。</p><p>令$g(z)$与$f(z_i)$相乘得到$g(z)f(z_i)$，然后把原先存放在memory cell中的$c$与$f(z_f)$相乘得到$cf(z_f)$，两者相加得到存在memory cell中的新值$c’=g(z)f(z_i)+cf(z_f)$。</p><ul><li><p>若$f(z_i)=0$，则相当于并不使用输入$z$更新memory；若$f(z_i)=1$，则相当于直接输入$g(z)$。</p></li><li><p>若$f(z_f)=1$，则不忘记memory cell中的原值$c$；若$f(z_f)=0$，则原值$c$将被遗忘清除。</p><p>  可以看出，forget gate的逻辑与直觉是相反的，该控制信号打开表示记得原值，关闭却表示遗忘。这个gate取名为remember gate更好些。</p></li></ul><p>此后，$c’$通过激活函数得到$h(c’)$，与output gate的$f(z_o)$相乘，得到输出$a=h(c’)f(z_o)$。</p><h2 id="Apply-LSTM-to-NN"><a href="#Apply-LSTM-to-NN" class="headerlink" title="Apply LSTM  to NN"></a>Apply LSTM  to NN</h2><p>上述的LSTM应该如何应用于神经网络呢？其实直接把LSTM作为1个神经元就可以了。假设输入层有2个标量输入$x_1,x_2$，隐藏层中有2个神经元，每个神经元输出1个标量，则其结构如下图所示。</p><p><img src="https://pic3.zhimg.com/80/v2-af52398f38860c122b0741e07ebb3dbd_720w.png" alt="img"></p><ul><li><strong>标量输入$x_1,x_2$乘以4个参数得到4个值，这4个值作为LSTM的4个input</strong>。</li><li>在普通的神经元中，1个input对应1个output；而在LSTM中4个input才产生1个output，并且所有的input都是不相同的。</li><li>LSTM所需要的参数量是普通NN的4倍。</li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;LSTM即Long Short-term Memory。&lt;/p&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;前几篇文章提到的RNN都比较简单，可以任意读写mem
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.3RNN的应用</title>
    <link href="https://chouxianyu.github.io/2021/04/12/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-3RNN%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/12/李宏毅机器学习课程笔记-9-3RNN的应用/</id>
    <published>2021-04-12T00:54:54.000Z</published>
    <updated>2021-04-12T01:02:36.510Z</updated>
    
    <content type="html"><![CDATA[<p>在Slot Filling中，输入是1个word vector，输出是每个word的label，<strong>输入和输出是等长的</strong>。</p><p>然而，RNN还可以实现多对1、多对多…</p><h2 id="Many-to-One"><a href="#Many-to-One" class="headerlink" title="Many to One"></a>Many to One</h2><p>Many to One：输入是1个vector sequence，输出是1个vector</p><ul><li><p>Sentiment Analysis</p><p>  输入1篇文章或1句话等（1个vector sequence），输出其情感倾向（分类或者回归，比如超好、好、普通、差、超差、[-1,1]）。</p></li><li><p>Key Term Extraction</p><p>  输入是1篇文章等，输出是几个关键词。</p></li></ul><h2 id="Many-to-Many"><a href="#Many-to-Many" class="headerlink" title="Many to Many"></a>Many to Many</h2><p><strong>Many to Many：输入和输出都是sequence，但输出更短</strong></p><p>比如Speech Recognition。输入是1段声音信号，每隔1小段时间（通常很短，比如0.01秒）就用1个vector表示，输出是1段文字。因此输入是1个vector sequence，而输出是1个charactor sequence，并且<strong>输入序列要比输出序列短</strong>。</p><p>如果仍然使用Slot Filling的方法，就只能做到输入的每个vector对应输出1个character，输入1句“好棒”的语音后可能输出文字“好好棒棒棒”，但其实应该输出文字“好棒”。我们可以通过<strong>Trimming</strong>去除输出中相同的character，但语音“好棒”和语音“好棒棒”是不同的，应该如何区分呢？可以用<strong>CTC(Connectionist Temporal Classification)</strong>，其基本思路是可以在输出中填充NULL，最终输出时删除NULL即可。</p><p><img src="https://pic2.zhimg.com/80/v2-c135e0952e8aa68cf0831e64c0cb0105_720w.png" alt="img"></p><p>如上图所示，输入中vector的数量多于label中character的数量，那CTC应该怎么训练呢？答案是假设所有的可能性都是对的。</p><h2 id="Many-to-Many-1"><a href="#Many-to-Many-1" class="headerlink" title="Many to Many"></a>Many to Many</h2><p><strong><a href="http://www.oalib.com/paper/4068742" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a>：输入和输出都是sequence，但两者长度不确定。</strong></p><p>以机器翻译为例，RNN要将英文的word sequence翻译成中文的character sequence（并不知道哪个sequence更长或更短）。</p><p><img src="https://pic1.zhimg.com/80/v2-67cb0355203c2db204efaba8eff6b2f2_720w.png" alt="img"></p><p>如上图所示，假设RNN的输入“machine learning”，在2个时间点分别输入”machine”和”learning”，在最后1个时间点时memory中就存储了整个word sequence的信息。接下来让RNN输出，得到“机”，然后把“机”当做input（这1步有很多极技巧，这里省略），并读取memory中的信息，就会输出“器”，以此类推，RNN会一直输出但不知道什么时候停止。那怎么让RNN停止输出呢？可以添加1个symbol<code>===</code>标志停止，当RNN输出这个symbol时就停止输出。</p><h2 id="Seq2Seq-for-Syntatic-Parsing"><a href="#Seq2Seq-for-Syntatic-Parsing" class="headerlink" title="Seq2Seq for Syntatic Parsing"></a>Seq2Seq for Syntatic Parsing</h2><p><a href="http://arxiv.org/abs/1412.7449" target="_blank" rel="noopener">Grammar as a Foreign Langauage</a>： 输入为1个word sequence，输出1个语法树（可以用sequence表示）。</p><h2 id="Seq2Seq-Auto-encoder-for-Text"><a href="#Seq2Seq-Auto-encoder-for-Text" class="headerlink" title="Seq2Seq Auto-encoder for Text"></a>Seq2Seq Auto-encoder for Text</h2><p>如果用bag-of-word来表示1段文本，就容易丢失word之间的联系和语序上的信息。比如“白血球消灭了感染病”和“感染病消灭了白血球”这2段文本语义完全相反但bag-of-word是相同的。</p><p><a href="https://arxiv.org/abs/1506.01057" target="_blank" rel="noopener">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a>：可以使用Seq2Seq Autoencoder，在考虑语序的情况下把文章编码成vector，只需要将RNN作为编码器和解码器即可。</p><p><img src="https://pic2.zhimg.com/80/v2-58c2031f882fd46db6171384e461756d_720w.png" alt="img"></p><p>如上图所示，word sequence输入RNN后被编码成embedded vector，然后再通过另1个RNN解码，如果解码后能得到一模一样的句子，则编码得到的vector就表示了这个word sequence中最重要的信息。</p><p><img src="https://pic4.zhimg.com/80/v2-e67956b01d8f5c5c2bd4b209a9c816ff_720w.png" alt="img"></p><p>如上图所示，这个过程可以是分层的（hierarchical），可以将每1个sentence编码成1个vector然后将它们加起来得到表示整个document的vector，然后再通过它产生多个setence的vector，然后将多个setence的vector解码得到word sequence。这是1个4层的LSTM（word sequence-sentence sequence-document-sentence sequence-word sequence）。</p><p>Seq2Seq Auto-encoder比较容易得到文法的编码，而Skip Thought（输入1个句子，输出其下1句）更容易得到语义的意思。</p><h2 id="Seq2Seq-Auto-encoder-for-Speech"><a href="#Seq2Seq-Auto-encoder-for-Speech" class="headerlink" title="Seq2Seq Auto-encoder for Speech"></a>Seq2Seq Auto-encoder for Speech</h2><p><a href="https://arxiv.org/abs/1603.00982" target="_blank" rel="noopener">Audio Word2Vec: Unsupervised Learning of Audio Segment Representations using Sequence-to-sequence Autoencoder</a></p><p>Seq2Seq Auto-encoder还可以用在语音上，它可以把1个audio segment(word-level)编码成1个fixed-length vector。这有什么用处呢？它可以基于语音之间的相似度做语音搜索。</p><p><img src="https://pic1.zhimg.com/80/v2-ac9ee7ee9e1c47683525266543036146_720w.png" alt="img"></p><p>那如何基于语音之间的相似度做语音搜索呢？如上图所示，假如有1个语音的database，可将其划分为audio segments（长度可变），然后使用Seq2Seq Auto-encoder将其编码为1个fixed-length vector。对于1段需要搜索的语音，通过Seq2Seq Auto-encoder将其编码成1个fixed-length vector，计算其与database中audio segments的vector的相似度。</p><p><img src="https://pic1.zhimg.com/80/v2-286be450d67ee1a810c5dac8889deba1_720w.png" alt="img"></p><p>那如何把1个audio segment编码成1个fixed-length vector呢？如上图所示，首先把audio segment转换为acoustic feature sequence，然后输入至RNN。该RNN作为Encoder，在最后1个时间点其memory中的值就代表整个acoustic feature sequence，这就是我们想要的vector。但是只有这个作为Encoder的RNN我们没有办法训练，所以还要训练1个作为Decoder的RNN。该RNN作为Decoder，以Encoder在最后1个时间点时memory中的vector为输入，然后输出1个acoustic feature sequence，训练目标是输出的acoustic feature sequence和输入的acoustic feature sequence越接近越好。由此可知，该例中Encoder和Decoder是要同时训练的。</p><h2 id="Attention-based-Model"><a href="#Attention-based-Model" class="headerlink" title="Attention-based Model"></a>Attention-based Model</h2><blockquote><p>專家發現，小兒失憶現象是由於動物的大腦在神經新生的過程中，處於不斷重組的狀態，為減少太多訊息的干擾，會不斷清除舊記憶，從而增加對新事物的學習能力。年幼小鼠的記憶保留能力所以低下，乃因其高度活躍的神經再生所致，而成年小鼠保留記憶能力的增加，也由於其大腦相對成熟，海馬體的神經再生活力已經下降。腦科學家既然可以抑制年幼小鼠海馬體的高度活躍神經再生活力，又可刺激成年小鼠海馬體增加其神經再生活力。</p><p>——————引自<a href="http://henrylo1605.blogspot.com/2015/05/blog-post_56.html" target="_blank" rel="noopener">http://henrylo1605.blogspot.com/2015/05/blog-post_56.html</a></p></blockquote><p>现在除了RNN之外，Attention-based Model也用到了memory的思想。机器也可以有记忆，神经网络通过操控读/写头去读/写信息，这个就是Neural Turing Machine。</p><h2 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h2><p>Attention-based Model常常用在Reading Comprehension上，让机器读1篇document，再把每个setence变成代表语义的vector，接下来让用户向机器提问，神经网络就会去调用读写头，取出memory中与查询语句相关的信息，综合处理之后，可以给出正确的回答。</p><h2 id="Visual-Question-Answering"><a href="#Visual-Question-Answering" class="headerlink" title="Visual Question Answering"></a>Visual Question Answering</h2><h2 id="Speech-Question-Answering"><a href="#Speech-Question-Answering" class="headerlink" title="Speech Question Answering"></a>Speech Question Answering</h2><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Slot Filling中，输入是1个word vector，输出是每个word的label，&lt;strong&gt;输入和输出是等长的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而，RNN还可以实现多对1、多对多…&lt;/p&gt;
&lt;h2 id=&quot;Many-to-One&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.2如何训练RNN</title>
    <link href="https://chouxianyu.github.io/2021/04/11/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-2%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83RNN/"/>
    <id>https://chouxianyu.github.io/2021/04/11/李宏毅机器学习课程笔记-9-2如何训练RNN/</id>
    <published>2021-04-11T02:41:12.000Z</published>
    <updated>2021-04-11T02:43:24.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RNN的损失函数"><a href="#RNN的损失函数" class="headerlink" title="RNN的损失函数"></a>RNN的损失函数</h2><p>仍然以Slot Filling为例，如下图所示。</p><p><img src="https://pic2.zhimg.com/80/v2-bbab6148db7b998a52c988e160c3fd16_720w.png" alt="img"></p><p>对于1个word$x^i$，RNN输出1个one-hot编码的vector $y^i$，求$y^i$和对应label的交叉熵损失（Cross Entropy Loss），将多个word的loss求和即为RNN的损失函数。需要注意的是不能打乱word的语序，$x^{i+1}$要紧接着$x^i$输入。</p><p>确定RNN的损失函数后，RNN的训练其实也是用的梯度下降。训练前馈神经网络时我们使用有效的反向传播算法，为了方便地训练RNN，我们使用BPTT。基于BP，<strong>BPTT(Backpropagation Through Time)</strong>考虑了时间维度的信息。</p><h2 id="RNN的Error-Surface"><a href="#RNN的Error-Surface" class="headerlink" title="RNN的Error Surface"></a>RNN的Error Surface</h2><p>RNN的Error Surface如下图所示，其中$z$轴代表loss，$x$轴和$y$轴代表两个参数$w_1$和$w_2$。可以看出，RNN的Error Surface在某些地方非常平坦，在某些地方又非常的陡峭。<strong>这样的Error Surface导致在训练RNN时loss剧烈变化</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-9264ded1a5556fb9bce3cbd5f7d5a3aa_720w.png" alt="img"></p><h2 id="问题出现的原因"><a href="#问题出现的原因" class="headerlink" title="问题出现的原因"></a>问题出现的原因</h2><p>既然RNN的Error Surface中有这么平滑的地方，那会不会是sigmoid激活函数造成的梯度消失呢？原因并不是sigmoid，如果是的话，那换成ReLU就可以，但把sigmoid换成ReLU之后，效果反而更差了。那到底为什么会有非常陡峭和非常平滑的地方呢？</p><p><img src="https://pic4.zhimg.com/80/v2-e601dceb08a568fabb5e12ab811d310b_720w.png" alt="img"></p><p>如上图所示，假设某RNN只含1个神经元，并且该神经元是Linear的，input和output的weight都是1，没有bias，memory传递的weight是$w$，输入序列为[1, 0, 0, 0, …, 0]，所以$y^{1000}=w^{999}$。</p><p>现在我们考虑loss关于参数$w$的梯度，当$w:\ 1\ =&gt;\ 1.01$时，可知$y^{1000}:\ 1\ =&gt;\ 20000$，此时梯度很大；当$w:\ 0.99\ =&gt;\ 0.01$时，可知$y^{1000}$几乎没有变化，此时梯度很小。</p><p>从该例中可知，RNN的Error Surface中的“悬崖”出现的原因是，<strong>关于memory的参数$w$的作用随着时间增加不断增强，导致RNN出现梯度消失或梯度爆炸的问题</strong>。</p><h2 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h2><p>如何解决RNN梯度消失或梯度爆炸的问题？可以通过<strong>Clipping</strong>进行处理，Clipping的效果是使梯度不超过某个阈值，即当梯度即将超过某个阈值（比如15）时，就将梯度赋值为该阈值。</p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>有什么更好的方法可以解决RNN的Error Surface中的问题呢？LSTM就是使用最广泛的技巧，它可以“删除”Error Surface中比较平坦的部分，也就解决了梯度消失的问题，但它无法解决梯度爆炸的问题。正因如此，训练LSTM时需要将学习率调得特别小。</p><p>LSTM为什么可以解决RNN中梯度消失的问题呢，因为RNN和LSTM对memory的处理是不同的（LSTM有forget gate）。<strong>在RNN中，每个时间点memory中的旧值都会被新值覆盖，导致参数$w$对memory的影响每次都被清除，进而引发梯度消失。在LSTM中，每个时间点memory里的旧值会乘以$f(g(f))$再与新值相加，只有在forget gate被关闭时参数$w$对memory的影响才会被清除，在forget gate被打开时参数$w$对memory的影响就会通过累加得到保留，因此不会出现梯度消失的问题。</strong></p><p>LSTM在1997年被提出，第1版的LSTM被提出就是为了解决梯度消失的问题，但这1版本是没有forget gate的，forget gate是后来才加上去的。也有1种说法是，在训练LSTM时需要给forget gate特别大的bias，以确保forget gate在多数情况下是开启的。</p><h3 id="GRU（Gated-Recurrent-Unit-Cho-EMNLP’14）"><a href="#GRU（Gated-Recurrent-Unit-Cho-EMNLP’14）" class="headerlink" title="GRU（Gated Recurrent Unit, Cho, EMNLP’14）"></a>GRU（Gated Recurrent Unit, Cho, EMNLP’14）</h3><p>GRU比LSTM更简单，GRU只有2个gate，因此需要更少的参数量、鲁棒性更好、更不容易过拟合。GRU的基本思路是“旧的不去，新的不来”，GRU把input和forget gate联动起来，当forget gate把memory中的值清空时，input gate才会打开然后放入新的值。</p><h3 id="Clockwise-RNN（Jan-Koutnik-JMLR’14）"><a href="#Clockwise-RNN（Jan-Koutnik-JMLR’14）" class="headerlink" title="Clockwise RNN（Jan Koutnik, JMLR’14）"></a>Clockwise RNN（Jan Koutnik, JMLR’14）</h3><h3 id="SCRN（Structrally-Constrained-Recurrent-Network-Tomas-Mikolov-ICLR’15）"><a href="#SCRN（Structrally-Constrained-Recurrent-Network-Tomas-Mikolov-ICLR’15）" class="headerlink" title="SCRN（Structrally Constrained Recurrent Network, Tomas Mikolov, ICLR’15）"></a>SCRN（Structrally Constrained Recurrent Network, Tomas Mikolov, ICLR’15）</h3><h3 id="Vanilla-RNN-Initialized-with-Identity-Matrix-ReLU（Quoc-V-Le-arXiv’15）"><a href="#Vanilla-RNN-Initialized-with-Identity-Matrix-ReLU（Quoc-V-Le-arXiv’15）" class="headerlink" title="Vanilla RNN Initialized with Identity Matrix + ReLU（Quoc V.Le, arXiv’15）"></a>Vanilla RNN Initialized with Identity Matrix + ReLU（Quoc V.Le, arXiv’15）</h3><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RNN的损失函数&quot;&gt;&lt;a href=&quot;#RNN的损失函数&quot; class=&quot;headerlink&quot; title=&quot;RNN的损失函数&quot;&gt;&lt;/a&gt;RNN的损失函数&lt;/h2&gt;&lt;p&gt;仍然以Slot Filling为例，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.1循环神经网络RNN入门</title>
    <link href="https://chouxianyu.github.io/2021/04/10/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-1%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/10/李宏毅机器学习课程笔记-9-1循环神经网络RNN入门/</id>
    <published>2021-04-10T00:53:08.000Z</published>
    <updated>2021-04-10T01:02:16.365Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Slot-Filling"><a href="#Slot-Filling" class="headerlink" title="Slot Filling"></a>Slot Filling</h2><p>比如在订票系统中，输入“Arrive Taipei on November 2nd”这样一个序列，我们设置几个slot(槽位)，希望算法能够将关键词“Taipei”放入Destination这个slot，将”November”和”2nd”放入到达时间Time of Arrival这个slot，而“Arrive”和“on”不属于任何slot。那这个算法如何实现呢？</p><h2 id="Slot-Filling-with-FNN"><a href="#Slot-Filling-with-FNN" class="headerlink" title="Slot Filling with FNN"></a>Slot Filling with FNN</h2><p>可以用Feedforward Neural Network实现Slot Filling吗？可以，下面介绍这种FNN的输入和输出，但其存在问题。</p><p>输入是一个word（比如“Taipei”）并用vector来表示它；输出是1个probablity distribution，表示输入的word属于各个slot的概率。</p><p>如何用vector表示1个word呢？方法有很多。比如<strong>1-of-N Encoding</strong>(又名one-hot Encoding)，如下图所示。设定1个lexicon(词汇表)，那vector的size就和lexicon的size相同，vector中的每个维度对应lexicon中的word，vector中word对应的维度的值为1、其它维度的值为0。</p><p><img src="https://pic1.zhimg.com/80/v2-44be0e091d503721158e1bbee1cdb048_720w.png" alt="img"></p><p>如下图所示，只有1-of-N Encoding还不够，一些word不在lexicon中，对此我们需要在lexicon中添加1个”<strong>other</strong>“。除了1-of-N Encoding，还可以通过<strong>word hashing</strong>。可以用1个26×26×26的vector表示1个word，该vector中每个元素代表1个3字母序列。比如”apple”包括”app”、”ppl”、”ple”。</p><p><img src="https://pic4.zhimg.com/80/v2-828e73ac8019838e7667eeb033859d40_720w.png" alt="img"></p><p>使用FNN实现Slot Filling时会存在一个问题：假如有2个句子“Arrive Taipei on November 2nd”和“Leave Taipei on November 2nd”，在处理这2个句子时FNN会先处理“arrive”和“leave”这2个词汇然后再处理“Taipei”。<strong>这时FNN没有办法区分出“Taipei”是出发地还是目的地，而我们希望算法在处理序列时是有“记忆力”的（即在处理“Taipei”时，它还记得“Leave”或“Arrive”）</strong>，于是RNN诞生了。</p><h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><p>如下图所示，<strong>将每1个隐藏层的输出保存在memory中，网络不仅考虑了input，还要考虑memory中的数据</strong>（merory中的数据是需要有初值的，比如0）。</p><p><img src="https://pic1.zhimg.com/80/v2-f151d27c684e3ae8e60cb9d55d4a78fe_720w.png" alt="img"></p><p>因为RNN会考虑memory中存储的临时值，而不同输入产生的临时值不一定相同，所以<strong>改变输入序列中元素的顺序会导致最终输出结果的改变</strong>（Changing the sequence order will change the output）。</p><h2 id="Slot-Filling-with-RNN"><a href="#Slot-Filling-with-RNN" class="headerlink" title="Slot Filling with RNN"></a>Slot Filling with RNN</h2><p>如下图所示，以“Arrive Taipei on November 2nd” 这个word sequence为例，将“Arrive”的vector$x^1$输入到RNN，隐藏层生成$a^1$，根据$a^1$生成$y^1$，表示“arrive”属于每个slot的概率，其中$a^1$会被存储到memory中；将“Taipei”的vector$x^2$输入到RNN，此时隐藏层同时考虑$x^2$和memory中的$a^1$生成$a^2$，根据$a^2$生成$y^2$，表示“Taipei”属于某个slot的概率，此时再把$a^2$存到memory中；以此类推根据$x_3$和$a_2$生成$a_3$进而得到$y^3$……</p><p><img src="https://pic2.zhimg.com/80/v2-e16243c99c04f52df6f52ae560fdfb03_720w.png" alt="img"></p><h2 id="RNN的变体"><a href="#RNN的变体" class="headerlink" title="RNN的变体"></a>RNN的变体</h2><h3 id="Elman-Network-amp-Jordan-Network"><a href="#Elman-Network-amp-Jordan-Network" class="headerlink" title="Elman Network &amp; Jordan Network"></a>Elman Network &amp; Jordan Network</h3><p>RNN也有不同的变形。<strong>Elman Network是把隐藏层的输出存到memory中，而Jordan Network是把输出层的输出保存到memory中</strong>。由于隐藏层没有明确的训练目标，而整个NN具有明确的目标，因此Jordan Network的表现会更好一些。</p><p><img src="https://pic4.zhimg.com/80/v2-7df1a297e9879628ea03333d79b06d22_720w.png" alt="img"></p><h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>如下图所示，<strong>RNN可以是双向的</strong>。训练2个方向的RNN，1个从前往后读取序列，1个从后往前读取序列，然后使用2个RNN的隐藏层得到最后的输出层。这样的好处是，<strong>输出层的感受野更大</strong>，因为RNN在得到$y^{t+1}$的时候，它不只看了从句首$x^1$开始到$x^{t+1}$的数据，还看了从句尾$x^{n}$一直到$x^{t+1}$的输入，这就相当于<strong>RNN是在看过整个句子之后才计算每个word属于哪个slot的概率</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-a591f7a3eda6fd1328ae36273451bff2_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Slot-Filling&quot;&gt;&lt;a href=&quot;#Slot-Filling&quot; class=&quot;headerlink&quot; title=&quot;Slot Filling&quot;&gt;&lt;/a&gt;Slot Filling&lt;/h2&gt;&lt;p&gt;比如在订票系统中，输入“Arrive Taipei on N
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
