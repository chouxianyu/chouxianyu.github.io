<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>臭咸鱼的缺氧瓶</title>
  
  <subtitle>快给我氧气！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://chouxianyu.github.io/"/>
  <updated>2021-04-19T00:29:53.557Z</updated>
  <id>https://chouxianyu.github.io/</id>
  
  <author>
    <name>臭咸鱼</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.4基于Smoothness假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/19/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-4%E5%9F%BA%E4%BA%8ESmoothness%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/19/李宏毅机器学习课程笔记-10-4基于Smoothness假设的半监督学习/</id>
    <published>2021-04-19T00:27:39.000Z</published>
    <updated>2021-04-19T00:29:53.557Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Smoothness假设"><a href="#Smoothness假设" class="headerlink" title="Smoothness假设"></a>Smoothness假设</h2><h3 id="Smoothness假设的定义"><a href="#Smoothness假设的定义" class="headerlink" title="Smoothness假设的定义"></a>Smoothness假设的定义</h3><p>基于Smoothness假设的半监督学习的基本思路是“近朱者赤近墨者黑”，即<strong>相似的$x$具有相同的$\hat y$</strong>，其具体<strong>定义</strong>为：</p><ol><li>$x$的<strong>分布不平均</strong>，在某些地方(high density region)很集中，在某些地方很分散</li><li>如果$x^1$和$x^2$在一个<strong>high density region</strong>中距离非常近，则$x^1$和$x^2$通过1个<strong>high density path</strong>相连、$\hat y^1=\hat y^2$。</li></ol><p>举一个例子，如下图所示，$x^1,x^2,x^3$是3个样本，如果单纯地看它们之间的相似度，显然$x^2$和$x^3$更接近一些。但对于smoothness assumption来说，$x^1$和$x^2$是位于同一个high density region中，它们之间有high density path；而$x^2$与$x^3$之间则是“断开”的，没有high density path，因此$x^1$与$x^2$更“像”。</p><p><img src="https://pic1.zhimg.com/80/v2-a45cf1b179557c638d294edf952053a2_720w.png" alt="img"></p><h3 id="手写数字识别举例"><a href="#手写数字识别举例" class="headerlink" title="手写数字识别举例"></a>手写数字识别举例</h3><p>再举一个手写数字识别和人脸识别的例子，如下图所示，最左侧的2、最右侧的2和最右侧的3，从<strong>pixel角度</strong>来看明显是最右侧的2和3更加相似(尽管两者并非是同一个数字)，但如果考虑最左侧的2朝着最右侧的2的演化过程，可以发现产生了一种“<strong>间接相似性</strong>”(high density path)。根据Smoothness假设，由于这6个2之间存在间接的相似而这6个2和最右侧的3之间不存在high density path，因此这6个2是彼此相似的；而最右侧的3和这6个2是不相似的。</p><p><img src="https://pic4.zhimg.com/80/v2-c8fd736cc00ef0209e973b93b62b2541_720w.png" alt="img"></p><h3 id="文章分类举例"><a href="#文章分类举例" class="headerlink" title="文章分类举例"></a>文章分类举例</h3><p>假设对天文学(astronomy)和旅行(travel)的文章进行分类，它们有各自的专属词汇，此时如果unlabeled data与label data的词汇是相同或重合(overlap)的，那么就很容易分类；但真实情况中unlabeled data和labeled data之间可能没有任何重复的word，因为世界上的词汇太多了，sparse的分布中overlap难以发生。</p><p>但如果unlabeled data足够多，就会以一种<strong>相似传递</strong>的形式，建立起文档之间相似的桥梁。</p><h2 id="cluster-and-then-label"><a href="#cluster-and-then-label" class="headerlink" title="cluster and then label"></a>cluster and then label</h2><p>如何实现基于Smoothness假设的半监督学习呢？在具体实现上，最简单的方式是cluster and then label。</p><p>cluster and then label就是先<strong>把所有样本(包括有标签样本和无标签样本)分成几个cluster，然后根据每个cluster中各类别有标签样本的数量确定该cluster中所有样本的label，然后进一步用这些cluster学习得到分类器</strong>。</p><p>这种方法不一定会得到好的结果，因为该方法有个<strong>前提是我们能够把同类别的样本分到同一个cluster</strong>，而这并不容易。对图像分类来说，如果仅仅依据pixel-wise相似度来划分cluster，得到的结果一般都会很差。所以为了满足这个前提，我们需要设计较好的方法来描述一张图片(比如使用Deep Autoencoder提取图片特征feature)，以保证cluster时能够将同类别的样本分到同一个cluster。</p><h2 id="Graph-based-Approach"><a href="#Graph-based-Approach" class="headerlink" title="Graph-based Approach"></a>Graph-based Approach</h2><h3 id="high-density-path"><a href="#high-density-path" class="headerlink" title="high density path"></a>high density path</h3><p>如何实现基于Smoothness假设的半监督学习呢？我们可以将每个样本视为图中的1个点，<strong>通过图来表示connected by a high density path</strong>。Graph-based方法的基本思路是图中的有标注样本会影响与它们邻近的无标注样本并在图中产生“<strong>间接相似性</strong>”，即使某些无标注样本没有直接与有标注样本相连也仍然可以被判定为相似。如果想要让这种方法生效，<strong>收集到的数据一定要足够多</strong>，否则可能导致无法形成path、失去了information的传递效果。</p><h3 id="如何建立一张图"><a href="#如何建立一张图" class="headerlink" title="如何建立一张图"></a>如何建立一张图</h3><p>有时候点之间的边是比较好建立的(比如网页超链接、论文引用)，有时候需要我们自行建立点之间的边。图的好坏对最终结果的影响是非常关键的，但如何建图是一件heuristic的事情，需要我们凭经验和直觉来做，<strong>建图步骤</strong>如下：</p><ol><li><p>定义两个样本$x^i,x^j$之间的相似度计算方法$s(x^i,x^j)$</p><p> 如果是基于pixel-wise的相似度，那结果可能比较差，建议使用更好的方法(比如使用Autoencoder提取图片特征，并基于提取到的特征计算相似度)。</p><p> 推荐使用的相似度计算方法为高斯径向基函数(Gaussian Radial Basis Function)：$s(x^i,x^j)=exp(-\gamma||x^i-x^j||^2)$，其中$x^i,x^j$均为vector。经验上来说exp(exponential)通常是可以帮助提升性能的，因为它使得仅当$x^i,x^j$非常接近时similarity才会大、只要距离稍微远一点similarity就会迅速变小，也就是使用exponential可以做到<strong>只有非常近的两个点才能相连、稍微远一点就无法相连</strong>的效果。</p></li><li><p>建立点和点之间的边</p><ul><li><p>k-Nearest Neighbor(K近邻算法)</p><p>  在特征空间中，如果一个样本附近的k个最近样本的大多数属于某一类别，则该样本也属于这个类别</p></li><li><p>e-Neighborhood</p></li></ul></li><li><p>设置点和点之间边的权重</p><p> 一条边的权重应该和该边两个顶点的相似度成比例</p></li></ol><h3 id="如何定量地评估一个图符合Smoothness假设的程度"><a href="#如何定量地评估一个图符合Smoothness假设的程度" class="headerlink" title="如何定量地评估一个图符合Smoothness假设的程度"></a>如何定量地评估一个图符合Smoothness假设的程度</h3><p>那如何定量地评估一个图符合Smoothness假设的程度呢？</p><p><img src="https://pic1.zhimg.com/80/v2-db490c6a659a6fb1765c956d9f584cac_720w.png" alt="img"></p><p>如上图所示，我们定义1个图的<strong>Smoothness</strong>为$S=\frac{1}{2}\sum_{i,j}w_{i,j}(y^i-y^j)^2$并希望它<strong>越小越好</strong>，其中$i,j$为所有样本点的索引、$x^i$表示样本的特征、$y^j$表示样本的标注(有可能是伪标签)、$w_{i,j}$是2个样本之间边的权重、$\frac{1}{2}$只是为了方便计算。</p><p>上式Smoothness定义还可以表示为$S=y^TLy$，其中$y$是1个(R+U)-dim的vector：$y=[\dots,y^i,\dots,y^j,\dots]^T$、$L$是1个(R+U)×(R+U)的矩阵(名字叫做Graph Laplacian)。</p><p>Graph Laplacian的定义为$L=D-W$，其中$W_{i,j}$为2个样本点之间边的权重，把$W$每行元素之和放在该行对应的对角线上其它元素值为0即可得到$D$，如上图所示。在图神经网络(Spectral-based Convolution)中，有关于Graph Laplacian的介绍。</p><h3 id="如何训练"><a href="#如何训练" class="headerlink" title="如何训练"></a>如何训练</h3><p>Smoothness定义$S=y^TLy$中$y$是模型的输出(预测得到的类别)，它是取决于模型参数的，因此训练时仅需在有标注数据的损失函数上加上Smoothness即可：$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda S$，其中$\lambda S$可以被视为正则项。</p><p>由上可知，<strong>训练目标</strong>为：</p><ol><li>有标注数据的交叉熵越小越好，即模型的输出与标注越接近越好</li><li>所有数据的Smoothness越小越好，即不管是有标注数据还是无标注数据，模型输出都要符合Smoothness Assumption的假设</li></ol><p>注：训练时可以不仅仅要求整个模型的输出层要smooth，还可以对模型中任意一个隐藏层加上smooth的限制。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Smoothness假设&quot;&gt;&lt;a href=&quot;#Smoothness假设&quot; class=&quot;headerlink&quot; title=&quot;Smoothness假设&quot;&gt;&lt;/a&gt;Smoothness假设&lt;/h2&gt;&lt;h3 id=&quot;Smoothness假设的定义&quot;&gt;&lt;a href=
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.3基于Low-density Separation假设的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/18/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-3%E5%9F%BA%E4%BA%8ELow-density-Separation%E5%81%87%E8%AE%BE%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/18/李宏毅机器学习课程笔记-10-3基于Low-density-Separation假设的半监督学习/</id>
    <published>2021-04-18T07:17:34.000Z</published>
    <updated>2021-04-18T07:18:14.773Z</updated>
    
    <content type="html"><![CDATA[<p>按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即<strong>假设不同类别数据之间应该有1个很明显的boundary</strong>。</p><h3 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h3><p>最简单的基于Low-density Separation假设的半监督学习是Self-training。</p><ol><li><p>使用有标签的数据训练1个模型$f^*$，模型类型和训练方式没有限制，神经网络、深或浅、其它机器学习方法等等都可以</p></li><li><p>使用模型$f^<em>$生成未标注数据的伪标签(Pseudo-label)，即$y^u=f^</em>(x^u)$</p></li><li><p>取出一部分未标注数据将它们添加到有标签数据中，然后回到步骤1</p><p> 如何选择未标注数据仍然是一个open question，可以自行设计策略，比如给每个样本一个置信度。</p></li></ol><p>Self-training和<strong>生成模型中的半监督学习</strong>(见上1篇文章)还挺像的，它们的区别在于：</p><ol><li>Self-training使用<strong>hard label</strong>，即假定某个无标签样本一定属于某个类别(“非黑即白”)</li><li>生成模型使用<strong>soft label</strong>，即假定某个无标签样本有一定概率属于某类别(也可以理解为一个样本可以按照后验概率划分成多个部分，不同部分属于不同类别)</li></ol><p>Self-training使用了hard label，它并不适用于regression。</p><p>生成模型使用了soft label，它生成的伪标签在分类任务中是没有用的。因为把某个无标签样本(通过soft label生成伪标签)丢进模型重新训练模型，模型参数根本不会发生变化。</p><p>实际上，low-density separation就是<strong>通过hard label来提升分类效果</strong>的方法。</p><h3 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h3><p>该方法是Self-training的进阶版。</p><p>Self-training中使用的hard label还是有些武断和激进，Entropy-based Regularization对此进行了改进。</p><p><strong>在使用神经网络进行分类时，$y^u=f^<em>_{\theta^</em>}(x^u)$，其中$y_u$是1个one-hot编码。现在我们并不限制其必须是某个类别，而是将其看做1个分布，我们希望这个分布越集中越好(“非黑即白”)，因为分布越集中时它的含义就是样本$x^u$属于某类别的概率很大属于其它类别的概率很小</strong>。</p><p>我们可以使用Entropy评估分布$y^u$的集中程度$E(y^u)=-\sum_{m=1}^5y_m^uln(y_m^u)$，假设是5分类，其值越小则表示分布$y^u$越集中。</p><p>无监督分类的目标为有标签数据分类正确、无标签数据分类结果集中，所以损失函数则为$L=\sum_{x^r}C(y^r,\hat y^r)+\lambda\sum_{x^u}E(y^u)$，其中第1项为有标签数据的交叉熵损失、第2项为无标签数据的entropy、$\lambda$表示无标签数据的损失权重，因为式中第2项的作用类似于regularization，所以该方法被称为Entropy-based Regularization。</p><h3 id="Semi-supervised-SVM"><a href="#Semi-supervised-SVM" class="headerlink" title="Semi-supervised SVM"></a>Semi-supervised SVM</h3><p>SVM为两个类别的数据找到一个boundary，该boundary与两个类别的margin最大、分类错误最小。</p><p>Semi-supervised SVM穷举所有无标签数据的类别并进行计算，最终选择与两个类别的margin最大、分类错误最小的boundary。</p><p>在数据量大的时候，Semi-supervised SVM难以穷举出所有情况，但还有一种求近似解的方法，其大致思路是初始化一些label，然后每次尝试改动1个样本的label并判断是否更优，如果更优则改变该样本的label，具体见Transductive Inference for Text Classification using Support Vector Machines。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照“非黑即白”的思路，假设类别之间的boundary周围的data是很少的，即&lt;strong&gt;假设不同类别数据之间应该有1个很明显的boundary&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;Self-training&quot;&gt;&lt;a href=&quot;#Self-training&quot;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.2生成模型中的半监督学习</title>
    <link href="https://chouxianyu.github.io/2021/04/17/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-2%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>https://chouxianyu.github.io/2021/04/17/李宏毅机器学习课程笔记-10-2生成模型中的半监督学习/</id>
    <published>2021-04-17T02:46:22.000Z</published>
    <updated>2021-04-17T02:49:17.526Z</updated>
    
    <content type="html"><![CDATA[<p>生成模型中的半监督学习：Semi-supervised Learning for Generative Model</p><h2 id="有监督生成模型"><a href="#有监督生成模型" class="headerlink" title="有监督生成模型"></a>有监督生成模型</h2><p>有监督生成模型：Supervised Generative Model</p><p>如下图所示，在有监督生成模型中，得到$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$后，就可以计算出$x$属于类别$C_i$的概率$P(C_i|x)$。</p><p><img src="https://pic4.zhimg.com/80/v2-ee9b2801a6e660c4526a62103c10d2e0_720w.png" alt="img"></p><h2 id="半监督生成模型"><a href="#半监督生成模型" class="headerlink" title="半监督生成模型"></a>半监督生成模型</h2><p>半监督生成模型：Semi-supervised Generative Model</p><p>基于有监督生成模型，当有了无标签数据之后(下图中绿色圆点)，我们会明显发现有监督生成模型中的$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$并不够正确，比如2个类别的分布应该接近于下图中虚线圆圈、先验概率$P(C_1)$应该小于$P(C_2)$，所以应该使用无标签数据重新估计$P(C_1),P(C_2),\mu^1,\mu^2,\Sigma$。</p><p><img src="https://pic4.zhimg.com/80/v2-a334756241f389f2ca620c5f35ab5269_720w.png" alt="img"></p><h3 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h3><p>具体来讲，按照以下步骤进行计算：</p><ol><li><p>初始化参数：$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><p> 可以随机初始化，也可以用有标签数据估算</p></li><li><p>通过$\theta$计算每个样本$x^u$属于类别$C_i$的概率$P_\theta(C_i|x^u)$</p></li><li><p><strong>更新参数$\theta$</strong>（其实重点就是如何同时利用有标签数据和无标签数据实现半监督）</p><ul><li>$P(C_1)=\frac{N_1+\sum_{x^u}P(C_1|x^u)}{N}$，其中$N$是所有样本的数量、$N_1$是属于类别$C_1$的样本的数量。</li><li>$\mu^1=\frac{1}{N_1}\sum_{x^r\in C_1}x^r+\frac{1}{\sum_{x^u}P(C_1|x^u)}\sum_{x^u}P(C_1|x^u)x^u$，其中$x^r,x^u$分别指有标签的样本和无标签的样本</li></ul><p>同理可知其它参数的计算和更新方法</p></li><li><p>返回第2步</p></li></ol><p>理论上，上述步骤是可以收敛的，但参数$\theta$的初始化值会影响结果。其实上面的第2步是EM算法中的E，第3步是EM算法中的M。</p><h3 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h3><p>$\theta=\{P(C_1),P(C_2),\mu^1,\mu^2,\Sigma\}$</p><ul><li><p>Maximum likelihood with labelled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)$最大(有一个Closed-form solution)，其中每个有标注样本$x^r$的$P_\theta(x^r,\hat y^r)=P_\theta(x^r|\hat y^r)P(\hat y^r)$。</p></li><li><p>Maximum likelihood with labelled &amp; unlabeled data</p><p>  使得$logL(\theta)=\sum_{x^r}logP_\theta(x^r, \hat y^r)+\sum_{x^u}logP_\theta(x^u)$最大(该式并不是凹函数，所以需要迭代求解)，其中每个无标注样本$x^u$的$P_\theta(x^u)=P_\theta(x^u|C_1)P(C_1)+P_\theta(x^u|C_2)P(C_2)$</p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生成模型中的半监督学习：Semi-supervised Learning for Generative Model&lt;/p&gt;
&lt;h2 id=&quot;有监督生成模型&quot;&gt;&lt;a href=&quot;#有监督生成模型&quot; class=&quot;headerlink&quot; title=&quot;有监督生成模型&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概率生成模型" scheme="https://chouxianyu.github.io/tags/%E6%A6%82%E7%8E%87%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-10.1半监督学习简介</title>
    <link href="https://chouxianyu.github.io/2021/04/16/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-10-1%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>https://chouxianyu.github.io/2021/04/16/李宏毅机器学习课程笔记-10-1半监督学习简介/</id>
    <published>2021-04-16T00:22:16.000Z</published>
    <updated>2021-04-16T00:50:25.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有监督学习-Supervised-Learning"><a href="#有监督学习-Supervised-Learning" class="headerlink" title="有监督学习(Supervised Learning)"></a>有监督学习(Supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R$，其中每组数据包括算法的输入与输出(标签)。</p><h2 id="半监督学习-Semi-supervised-Learning"><a href="#半监督学习-Semi-supervised-Learning" class="headerlink" title="半监督学习(Semi-supervised Learning)"></a>半监督学习(Semi-supervised Learning)</h2><p>训练集数据为$\{ (x^r,\ \hat y^r) \}_{r=1}^R+\{ x^u\}_{u=R+1}^{U+R}$，即其中部分数据有标签而大量数据没有标签($U&gt;&gt;R$)。</p><p>半监督学习可以分为以下2种情况</p><ol><li><p><strong>Transductive Learning</strong></p><p> unlabeled data is the testing data，只使用testing data中的feature，并没有使用testing data中的label，所以并没有cheating。</p><p> 适用于已知testing data的情况，比如kaggle比赛。</p></li><li><p><strong>Inductive Learning</strong></p><p> unlabeled data is not the testing data，完全不使用testing data。</p><p> 适用于testing data未知的情况，这是大多数情况。</p></li></ol><h2 id="为什么需要半监督学习"><a href="#为什么需要半监督学习" class="headerlink" title="为什么需要半监督学习"></a>为什么需要半监督学习</h2><p>其实缺的并不是数据，缺少的是有标签的数据。利用这些大量的没有标签的数据进行学习，这是非常有价值的。</p><h2 id="为什么半监督学习有用"><a href="#为什么半监督学习有用" class="headerlink" title="为什么半监督学习有用"></a>为什么半监督学习有用</h2><p>The <strong>distribution</strong> of the unlabeled data tell us something：无标注数据的分布可以告诉我们一些东西</p><p><img src="https://pic3.zhimg.com/80/v2-676d19916cb98d7f251ff22a08eec087_720w.png" alt="img"></p><p><strong>半监督学习往往伴随着假设，而该假设的合理与否决定了结果的好坏程度。</strong>如上图所示，在猫狗图片分类中一只狗被认为是一只猫，这很可能是由于这2张图片的背景都是绿色，因此假设的合理性至关重要。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;有监督学习-Supervised-Learning&quot;&gt;&lt;a href=&quot;#有监督学习-Supervised-Learning&quot; class=&quot;headerlink&quot; title=&quot;有监督学习(Supervised Learning)&quot;&gt;&lt;/a&gt;有监督学习(Supe
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="半监督学习" scheme="https://chouxianyu.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.6基于RNN和PyTorch的文本情感分类</title>
    <link href="https://chouxianyu.github.io/2021/04/15/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-6%E5%9F%BA%E4%BA%8ERNN%E5%92%8CPyTorch%E7%9A%84%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/"/>
    <id>https://chouxianyu.github.io/2021/04/15/李宏毅机器学习课程笔记-9-6基于RNN和PyTorch的文本情感分类/</id>
    <published>2021-04-15T00:22:18.000Z</published>
    <updated>2021-04-15T00:45:28.163Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework4的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述</p><p>  通过RNN实现文本情感分类(Text Sentiment Classification)。</p></li><li><p>数据集描述</p><p>  输入是1个句子，输出是0(负面)或1(正面)。</p><p>  训练集：标注数据20万，无标注数据120万</p><p>  测试集：20万(无标注)</p></li><li><p>数据格式</p><ul><li>training_label.txt：<code>label +++$+++ sentence</code>，其中<code>+++$+++</code>只是分隔符</li><li>training_nolabel.txt：每一行就是一个句子，没有label</li><li>testing_data.txt：</li></ul></li><li><p>数据预处理</p><p>  一个句子(sentence)中有多个word，我们需要通过<strong>Word Embedding</strong>(我的其它文章里有介绍)用一个vector表示一个word， 然后使用RNN得到一个表示该sentence的vector。</p></li><li><p>半监督学习</p><p>  这里使用一种半监督学习方法：<strong>Self-Training</strong>(我的其它文章里有介绍)。使用有标签数据训练好模型，然后对无标签数据进行预测，并根据预测结果对无标签数据进行标注(“伪标签”)并继续训练模型</p></li><li><p>第三方库</p><p>  使用Python第三方库<code>gensim</code>实现word2vec模型，以进行Word Embedding。</p></li><li><p>代码</p><p>  <a href="https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw4_RNN" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes/tree/master/hw4_RNN</a></p></li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework4的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg&quot; target
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.5详解基于LSTM的RNN</title>
    <link href="https://chouxianyu.github.io/2021/04/14/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-5%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84RNN/"/>
    <id>https://chouxianyu.github.io/2021/04/14/李宏毅机器学习课程笔记-9-5详解基于LSTM的RNN/</id>
    <published>2021-04-14T02:38:35.000Z</published>
    <updated>2021-04-14T02:40:15.998Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1层LSTM神经元的架构"><a href="#1层LSTM神经元的架构" class="headerlink" title="1层LSTM神经元的架构"></a>1层LSTM神经元的架构</h2><p>根据上述内容，你可能看不出LSTM与RNN有什么关系，接下来具体介绍LSTM在RNN中的应用。</p><p>假设我们现在有一些LSTM（下图中白色部分）作为神经元，每个LSTM的memory cell里都存了一个scalar值（下图中红框中内容），把这些scalar连接起来就组成了1个vector $c^{t-1}$，即关于上个input（时间点为t-1）的memory。</p><p><img src="https://pic4.zhimg.com/80/v2-d96ed6d363d633b87729a22badf815a9_720w.png" alt="img"></p><p><strong>在时间点t，输入为1个vector $x^t$，它会经过4个线性的transform得到$z^f,z^i,z,z^o$，$z^f,z^i,z,z^o$这4个vector的dimension数量和LSTM神经元的数量相等，这4个vector的1个dimension即为1个LSTM神经元的输入（4个vector的第1个dimension为第1个LSTM神经元的输入）。</strong></p><h2 id="1个LSTM神经元的运算方法"><a href="#1个LSTM神经元的运算方法" class="headerlink" title="1个LSTM神经元的运算方法"></a>1个LSTM神经元的运算方法</h2><p>下图是单个LSTM神经元的运算方法，其4个input分别是$z$、$z^i$、$z^f$和$z^o$的其中1维（1维为1个神经元的输入）。每个LSTM神经元的input是各不相同的，但它们可以共同运算。</p><p>1个LSTM神经元的运算方法如下图所示。</p><p><img src="https://pic3.zhimg.com/80/v2-bc5c546a495db0ef197f4527f841562c_720w.png" alt="img"></p><p>$f(z^f)$与上一个时间点的memory $c^{t-1}$对应的cell值相乘，加上$g(z)$与$f(z^i)$的乘积，得到该时刻该cell中的值$c^t$，最终再乘以output gate的信号$f(z^o)$，得到输出$y^t$。</p><h2 id="1个LSTM神经元在相邻时刻时的运算方法"><a href="#1个LSTM神经元在相邻时刻时的运算方法" class="headerlink" title="1个LSTM神经元在相邻时刻时的运算方法"></a>1个LSTM神经元在相邻时刻时的运算方法</h2><p><img src="https://pic1.zhimg.com/80/v2-993d9ee86e0180e96e405e6b3248b41f_720w.png" alt="img"></p><p>上图是同1个LSTM神经元在2个相邻时刻的运算方法，其中与前文描述略有不同的是，这里还需要把当前时刻该神经元的输出$y^t$以及该神经元中cell保存的值$c^t$（peephole）都连接到下一时刻的输入上。因此在$t+1$时刻，神经元不只是考虑当前的输入$x^{t+1}$，还要看前一时刻该神经元的输出$h^t$和cell保存值$c^t$。</p><p>如何考虑结合$t+1$时刻的输入$x^{t+1}$和上一时刻该神经元的信息$h^t,c^t$呢？====&gt;<strong>把$x^{t+1}$、$h^t$和$c^t$这3个vector并在一起</strong>，乘上4个不同的转换矩阵，得到该神经元$t+1$时刻的4个输入$z$、$z^i$、$z^f$、$z^o$。</p><h2 id="多层LSTM在相邻时刻的运算方法"><a href="#多层LSTM在相邻时刻的运算方法" class="headerlink" title="多层LSTM在相邻时刻的运算方法"></a>多层LSTM在相邻时刻的运算方法</h2><p><img src="https://pic2.zhimg.com/80/v2-a6435474533a8871ad59ed5443055159_720w.png" alt="img"></p><p>上图中左边一列的2个LSTM代表2层LSTM，右边一列的2个LSTM则代表它们在下一时刻的状态。即横向是时间轴，纵向是层轴。</p><p>虽然看起来很复杂，感觉不一定work，但LSTM在RNN中已成为了标准做法。</p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1层LSTM神经元的架构&quot;&gt;&lt;a href=&quot;#1层LSTM神经元的架构&quot; class=&quot;headerlink&quot; title=&quot;1层LSTM神经元的架构&quot;&gt;&lt;/a&gt;1层LSTM神经元的架构&lt;/h2&gt;&lt;p&gt;根据上述内容，你可能看不出LSTM与RNN有什么关系，接下来
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.4LSTM入门</title>
    <link href="https://chouxianyu.github.io/2021/04/13/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-4LSTM%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/13/李宏毅机器学习课程笔记-9-4LSTM入门/</id>
    <published>2021-04-13T00:35:26.000Z</published>
    <updated>2021-04-13T00:47:38.903Z</updated>
    
    <content type="html"><![CDATA[<p>LSTM即Long Short-term Memory。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>前几篇文章提到的RNN都比较简单，可以任意读写memory，没有进一步对memory进行管理。<strong>现在常用的memory管理方式是LSTM</strong>。正如其名，LSTM是比较长的短期记忆，<code>-</code>是在short和term之间。<strong>前几篇提到的RNN在有新的输入时都会更新memory，这样的memory是非常短期的，而LSTM中可以有更久之前的memory</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-2d2d4f677d917a001fcf379e00472bbf_720w.png" alt="img"></p><p>如上图所示，LSTM中有3个gate、4个输入(3个gate控制信号和1个想要写入memory cell的值)和1个输出：</p><ul><li>input gate：当某个neuron的输出想要被写进memory cell，它要先经过input gate。如果input gate是关闭的，则任何内容都无法被写入。input gate的关闭与否、什么时候开闭是由神经网络学习到的。</li><li>output gate：output gate决定了外界是否可以从memory cell中读取数据。当output gate关闭的时候，memory里面的内容无法被读取。output gate的关闭与否、什么时候开闭也是由神经网络学习到的。</li><li>forget gate：forget gate决定什么时候需要把memory cell里存放的内容忘掉，什么时候要保存。这也是由神经网络学习到的。</li></ul><h2 id="LSTM计算式"><a href="#LSTM计算式" class="headerlink" title="LSTM计算式"></a>LSTM计算式</h2><p>下图展示了LSTM的计算式。</p><p><img src="https://pic1.zhimg.com/80/v2-de00669f5a90c477fb32b2fffb71571d_720w.png" alt="img"></p><ul><li>$z$是想要被存到memory cell里的值</li><li>$z_i$是input gate的控制信号</li><li>$z_o$是output gate的控制信号</li><li>$z_f$是forget gate的控制信号</li><li>$a$是综合上述4个输入得到的输出值</li></ul><p>$z$、$z_i$、$z_o$和$z_f$通过激活函数分别得到$g(z)$、$f(z_i)$、$f(z_o)$和$f(z_f)$，其中$z_i$、$z_o$和$z_f$的激活函数$f()$一般会选sigmoid函数，因为其输出在0~1之间，可表示gate的开启程度。</p><p>令$g(z)$与$f(z_i)$相乘得到$g(z)f(z_i)$，然后把原先存放在memory cell中的$c$与$f(z_f)$相乘得到$cf(z_f)$，两者相加得到存在memory cell中的新值$c’=g(z)f(z_i)+cf(z_f)$。</p><ul><li><p>若$f(z_i)=0$，则相当于并不使用输入$z$更新memory；若$f(z_i)=1$，则相当于直接输入$g(z)$。</p></li><li><p>若$f(z_f)=1$，则不忘记memory cell中的原值$c$；若$f(z_f)=0$，则原值$c$将被遗忘清除。</p><p>  可以看出，forget gate的逻辑与直觉是相反的，该控制信号打开表示记得原值，关闭却表示遗忘。这个gate取名为remember gate更好些。</p></li></ul><p>此后，$c’$通过激活函数得到$h(c’)$，与output gate的$f(z_o)$相乘，得到输出$a=h(c’)f(z_o)$。</p><h2 id="Apply-LSTM-to-NN"><a href="#Apply-LSTM-to-NN" class="headerlink" title="Apply LSTM  to NN"></a>Apply LSTM  to NN</h2><p>上述的LSTM应该如何应用于神经网络呢？其实直接把LSTM作为1个神经元就可以了。假设输入层有2个标量输入$x_1,x_2$，隐藏层中有2个神经元，每个神经元输出1个标量，则其结构如下图所示。</p><p><img src="https://pic3.zhimg.com/80/v2-af52398f38860c122b0741e07ebb3dbd_720w.png" alt="img"></p><ul><li><strong>标量输入$x_1,x_2$乘以4个参数得到4个值，这4个值作为LSTM的4个input</strong>。</li><li>在普通的神经元中，1个input对应1个output；而在LSTM中4个input才产生1个output，并且所有的input都是不相同的。</li><li>LSTM所需要的参数量是普通NN的4倍。</li></ul><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;LSTM即Long Short-term Memory。&lt;/p&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;前几篇文章提到的RNN都比较简单，可以任意读写mem
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="LSTM" scheme="https://chouxianyu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.3RNN的应用</title>
    <link href="https://chouxianyu.github.io/2021/04/12/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-3RNN%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/12/李宏毅机器学习课程笔记-9-3RNN的应用/</id>
    <published>2021-04-12T00:54:54.000Z</published>
    <updated>2021-04-12T01:02:36.510Z</updated>
    
    <content type="html"><![CDATA[<p>在Slot Filling中，输入是1个word vector，输出是每个word的label，<strong>输入和输出是等长的</strong>。</p><p>然而，RNN还可以实现多对1、多对多…</p><h2 id="Many-to-One"><a href="#Many-to-One" class="headerlink" title="Many to One"></a>Many to One</h2><p>Many to One：输入是1个vector sequence，输出是1个vector</p><ul><li><p>Sentiment Analysis</p><p>  输入1篇文章或1句话等（1个vector sequence），输出其情感倾向（分类或者回归，比如超好、好、普通、差、超差、[-1,1]）。</p></li><li><p>Key Term Extraction</p><p>  输入是1篇文章等，输出是几个关键词。</p></li></ul><h2 id="Many-to-Many"><a href="#Many-to-Many" class="headerlink" title="Many to Many"></a>Many to Many</h2><p><strong>Many to Many：输入和输出都是sequence，但输出更短</strong></p><p>比如Speech Recognition。输入是1段声音信号，每隔1小段时间（通常很短，比如0.01秒）就用1个vector表示，输出是1段文字。因此输入是1个vector sequence，而输出是1个charactor sequence，并且<strong>输入序列要比输出序列短</strong>。</p><p>如果仍然使用Slot Filling的方法，就只能做到输入的每个vector对应输出1个character，输入1句“好棒”的语音后可能输出文字“好好棒棒棒”，但其实应该输出文字“好棒”。我们可以通过<strong>Trimming</strong>去除输出中相同的character，但语音“好棒”和语音“好棒棒”是不同的，应该如何区分呢？可以用<strong>CTC(Connectionist Temporal Classification)</strong>，其基本思路是可以在输出中填充NULL，最终输出时删除NULL即可。</p><p><img src="https://pic2.zhimg.com/80/v2-c135e0952e8aa68cf0831e64c0cb0105_720w.png" alt="img"></p><p>如上图所示，输入中vector的数量多于label中character的数量，那CTC应该怎么训练呢？答案是假设所有的可能性都是对的。</p><h2 id="Many-to-Many-1"><a href="#Many-to-Many-1" class="headerlink" title="Many to Many"></a>Many to Many</h2><p><strong><a href="http://www.oalib.com/paper/4068742" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a>：输入和输出都是sequence，但两者长度不确定。</strong></p><p>以机器翻译为例，RNN要将英文的word sequence翻译成中文的character sequence（并不知道哪个sequence更长或更短）。</p><p><img src="https://pic1.zhimg.com/80/v2-67cb0355203c2db204efaba8eff6b2f2_720w.png" alt="img"></p><p>如上图所示，假设RNN的输入“machine learning”，在2个时间点分别输入”machine”和”learning”，在最后1个时间点时memory中就存储了整个word sequence的信息。接下来让RNN输出，得到“机”，然后把“机”当做input（这1步有很多极技巧，这里省略），并读取memory中的信息，就会输出“器”，以此类推，RNN会一直输出但不知道什么时候停止。那怎么让RNN停止输出呢？可以添加1个symbol<code>===</code>标志停止，当RNN输出这个symbol时就停止输出。</p><h2 id="Seq2Seq-for-Syntatic-Parsing"><a href="#Seq2Seq-for-Syntatic-Parsing" class="headerlink" title="Seq2Seq for Syntatic Parsing"></a>Seq2Seq for Syntatic Parsing</h2><p><a href="http://arxiv.org/abs/1412.7449" target="_blank" rel="noopener">Grammar as a Foreign Langauage</a>： 输入为1个word sequence，输出1个语法树（可以用sequence表示）。</p><h2 id="Seq2Seq-Auto-encoder-for-Text"><a href="#Seq2Seq-Auto-encoder-for-Text" class="headerlink" title="Seq2Seq Auto-encoder for Text"></a>Seq2Seq Auto-encoder for Text</h2><p>如果用bag-of-word来表示1段文本，就容易丢失word之间的联系和语序上的信息。比如“白血球消灭了感染病”和“感染病消灭了白血球”这2段文本语义完全相反但bag-of-word是相同的。</p><p><a href="https://arxiv.org/abs/1506.01057" target="_blank" rel="noopener">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a>：可以使用Seq2Seq Autoencoder，在考虑语序的情况下把文章编码成vector，只需要将RNN作为编码器和解码器即可。</p><p><img src="https://pic2.zhimg.com/80/v2-58c2031f882fd46db6171384e461756d_720w.png" alt="img"></p><p>如上图所示，word sequence输入RNN后被编码成embedded vector，然后再通过另1个RNN解码，如果解码后能得到一模一样的句子，则编码得到的vector就表示了这个word sequence中最重要的信息。</p><p><img src="https://pic4.zhimg.com/80/v2-e67956b01d8f5c5c2bd4b209a9c816ff_720w.png" alt="img"></p><p>如上图所示，这个过程可以是分层的（hierarchical），可以将每1个sentence编码成1个vector然后将它们加起来得到表示整个document的vector，然后再通过它产生多个setence的vector，然后将多个setence的vector解码得到word sequence。这是1个4层的LSTM（word sequence-sentence sequence-document-sentence sequence-word sequence）。</p><p>Seq2Seq Auto-encoder比较容易得到文法的编码，而Skip Thought（输入1个句子，输出其下1句）更容易得到语义的意思。</p><h2 id="Seq2Seq-Auto-encoder-for-Speech"><a href="#Seq2Seq-Auto-encoder-for-Speech" class="headerlink" title="Seq2Seq Auto-encoder for Speech"></a>Seq2Seq Auto-encoder for Speech</h2><p><a href="https://arxiv.org/abs/1603.00982" target="_blank" rel="noopener">Audio Word2Vec: Unsupervised Learning of Audio Segment Representations using Sequence-to-sequence Autoencoder</a></p><p>Seq2Seq Auto-encoder还可以用在语音上，它可以把1个audio segment(word-level)编码成1个fixed-length vector。这有什么用处呢？它可以基于语音之间的相似度做语音搜索。</p><p><img src="https://pic1.zhimg.com/80/v2-ac9ee7ee9e1c47683525266543036146_720w.png" alt="img"></p><p>那如何基于语音之间的相似度做语音搜索呢？如上图所示，假如有1个语音的database，可将其划分为audio segments（长度可变），然后使用Seq2Seq Auto-encoder将其编码为1个fixed-length vector。对于1段需要搜索的语音，通过Seq2Seq Auto-encoder将其编码成1个fixed-length vector，计算其与database中audio segments的vector的相似度。</p><p><img src="https://pic1.zhimg.com/80/v2-286be450d67ee1a810c5dac8889deba1_720w.png" alt="img"></p><p>那如何把1个audio segment编码成1个fixed-length vector呢？如上图所示，首先把audio segment转换为acoustic feature sequence，然后输入至RNN。该RNN作为Encoder，在最后1个时间点其memory中的值就代表整个acoustic feature sequence，这就是我们想要的vector。但是只有这个作为Encoder的RNN我们没有办法训练，所以还要训练1个作为Decoder的RNN。该RNN作为Decoder，以Encoder在最后1个时间点时memory中的vector为输入，然后输出1个acoustic feature sequence，训练目标是输出的acoustic feature sequence和输入的acoustic feature sequence越接近越好。由此可知，该例中Encoder和Decoder是要同时训练的。</p><h2 id="Attention-based-Model"><a href="#Attention-based-Model" class="headerlink" title="Attention-based Model"></a>Attention-based Model</h2><blockquote><p>專家發現，小兒失憶現象是由於動物的大腦在神經新生的過程中，處於不斷重組的狀態，為減少太多訊息的干擾，會不斷清除舊記憶，從而增加對新事物的學習能力。年幼小鼠的記憶保留能力所以低下，乃因其高度活躍的神經再生所致，而成年小鼠保留記憶能力的增加，也由於其大腦相對成熟，海馬體的神經再生活力已經下降。腦科學家既然可以抑制年幼小鼠海馬體的高度活躍神經再生活力，又可刺激成年小鼠海馬體增加其神經再生活力。</p><p>——————引自<a href="http://henrylo1605.blogspot.com/2015/05/blog-post_56.html" target="_blank" rel="noopener">http://henrylo1605.blogspot.com/2015/05/blog-post_56.html</a></p></blockquote><p>现在除了RNN之外，Attention-based Model也用到了memory的思想。机器也可以有记忆，神经网络通过操控读/写头去读/写信息，这个就是Neural Turing Machine。</p><h2 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h2><p>Attention-based Model常常用在Reading Comprehension上，让机器读1篇document，再把每个setence变成代表语义的vector，接下来让用户向机器提问，神经网络就会去调用读写头，取出memory中与查询语句相关的信息，综合处理之后，可以给出正确的回答。</p><h2 id="Visual-Question-Answering"><a href="#Visual-Question-Answering" class="headerlink" title="Visual Question Answering"></a>Visual Question Answering</h2><h2 id="Speech-Question-Answering"><a href="#Speech-Question-Answering" class="headerlink" title="Speech Question Answering"></a>Speech Question Answering</h2><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Slot Filling中，输入是1个word vector，输出是每个word的label，&lt;strong&gt;输入和输出是等长的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而，RNN还可以实现多对1、多对多…&lt;/p&gt;
&lt;h2 id=&quot;Many-to-One&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.2如何训练RNN</title>
    <link href="https://chouxianyu.github.io/2021/04/11/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-2%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83RNN/"/>
    <id>https://chouxianyu.github.io/2021/04/11/李宏毅机器学习课程笔记-9-2如何训练RNN/</id>
    <published>2021-04-11T02:41:12.000Z</published>
    <updated>2021-04-11T02:43:24.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RNN的损失函数"><a href="#RNN的损失函数" class="headerlink" title="RNN的损失函数"></a>RNN的损失函数</h2><p>仍然以Slot Filling为例，如下图所示。</p><p><img src="https://pic2.zhimg.com/80/v2-bbab6148db7b998a52c988e160c3fd16_720w.png" alt="img"></p><p>对于1个word$x^i$，RNN输出1个one-hot编码的vector $y^i$，求$y^i$和对应label的交叉熵损失（Cross Entropy Loss），将多个word的loss求和即为RNN的损失函数。需要注意的是不能打乱word的语序，$x^{i+1}$要紧接着$x^i$输入。</p><p>确定RNN的损失函数后，RNN的训练其实也是用的梯度下降。训练前馈神经网络时我们使用有效的反向传播算法，为了方便地训练RNN，我们使用BPTT。基于BP，<strong>BPTT(Backpropagation Through Time)</strong>考虑了时间维度的信息。</p><h2 id="RNN的Error-Surface"><a href="#RNN的Error-Surface" class="headerlink" title="RNN的Error Surface"></a>RNN的Error Surface</h2><p>RNN的Error Surface如下图所示，其中$z$轴代表loss，$x$轴和$y$轴代表两个参数$w_1$和$w_2$。可以看出，RNN的Error Surface在某些地方非常平坦，在某些地方又非常的陡峭。<strong>这样的Error Surface导致在训练RNN时loss剧烈变化</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-9264ded1a5556fb9bce3cbd5f7d5a3aa_720w.png" alt="img"></p><h2 id="问题出现的原因"><a href="#问题出现的原因" class="headerlink" title="问题出现的原因"></a>问题出现的原因</h2><p>既然RNN的Error Surface中有这么平滑的地方，那会不会是sigmoid激活函数造成的梯度消失呢？原因并不是sigmoid，如果是的话，那换成ReLU就可以，但把sigmoid换成ReLU之后，效果反而更差了。那到底为什么会有非常陡峭和非常平滑的地方呢？</p><p><img src="https://pic4.zhimg.com/80/v2-e601dceb08a568fabb5e12ab811d310b_720w.png" alt="img"></p><p>如上图所示，假设某RNN只含1个神经元，并且该神经元是Linear的，input和output的weight都是1，没有bias，memory传递的weight是$w$，输入序列为[1, 0, 0, 0, …, 0]，所以$y^{1000}=w^{999}$。</p><p>现在我们考虑loss关于参数$w$的梯度，当$w:\ 1\ =&gt;\ 1.01$时，可知$y^{1000}:\ 1\ =&gt;\ 20000$，此时梯度很大；当$w:\ 0.99\ =&gt;\ 0.01$时，可知$y^{1000}$几乎没有变化，此时梯度很小。</p><p>从该例中可知，RNN的Error Surface中的“悬崖”出现的原因是，<strong>关于memory的参数$w$的作用随着时间增加不断增强，导致RNN出现梯度消失或梯度爆炸的问题</strong>。</p><h2 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h2><p>如何解决RNN梯度消失或梯度爆炸的问题？可以通过<strong>Clipping</strong>进行处理，Clipping的效果是使梯度不超过某个阈值，即当梯度即将超过某个阈值（比如15）时，就将梯度赋值为该阈值。</p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>有什么更好的方法可以解决RNN的Error Surface中的问题呢？LSTM就是使用最广泛的技巧，它可以“删除”Error Surface中比较平坦的部分，也就解决了梯度消失的问题，但它无法解决梯度爆炸的问题。正因如此，训练LSTM时需要将学习率调得特别小。</p><p>LSTM为什么可以解决RNN中梯度消失的问题呢，因为RNN和LSTM对memory的处理是不同的（LSTM有forget gate）。<strong>在RNN中，每个时间点memory中的旧值都会被新值覆盖，导致参数$w$对memory的影响每次都被清除，进而引发梯度消失。在LSTM中，每个时间点memory里的旧值会乘以$f(g(f))$再与新值相加，只有在forget gate被关闭时参数$w$对memory的影响才会被清除，在forget gate被打开时参数$w$对memory的影响就会通过累加得到保留，因此不会出现梯度消失的问题。</strong></p><p>LSTM在1997年被提出，第1版的LSTM被提出就是为了解决梯度消失的问题，但这1版本是没有forget gate的，forget gate是后来才加上去的。也有1种说法是，在训练LSTM时需要给forget gate特别大的bias，以确保forget gate在多数情况下是开启的。</p><h3 id="GRU（Gated-Recurrent-Unit-Cho-EMNLP’14）"><a href="#GRU（Gated-Recurrent-Unit-Cho-EMNLP’14）" class="headerlink" title="GRU（Gated Recurrent Unit, Cho, EMNLP’14）"></a>GRU（Gated Recurrent Unit, Cho, EMNLP’14）</h3><p>GRU比LSTM更简单，GRU只有2个gate，因此需要更少的参数量、鲁棒性更好、更不容易过拟合。GRU的基本思路是“旧的不去，新的不来”，GRU把input和forget gate联动起来，当forget gate把memory中的值清空时，input gate才会打开然后放入新的值。</p><h3 id="Clockwise-RNN（Jan-Koutnik-JMLR’14）"><a href="#Clockwise-RNN（Jan-Koutnik-JMLR’14）" class="headerlink" title="Clockwise RNN（Jan Koutnik, JMLR’14）"></a>Clockwise RNN（Jan Koutnik, JMLR’14）</h3><h3 id="SCRN（Structrally-Constrained-Recurrent-Network-Tomas-Mikolov-ICLR’15）"><a href="#SCRN（Structrally-Constrained-Recurrent-Network-Tomas-Mikolov-ICLR’15）" class="headerlink" title="SCRN（Structrally Constrained Recurrent Network, Tomas Mikolov, ICLR’15）"></a>SCRN（Structrally Constrained Recurrent Network, Tomas Mikolov, ICLR’15）</h3><h3 id="Vanilla-RNN-Initialized-with-Identity-Matrix-ReLU（Quoc-V-Le-arXiv’15）"><a href="#Vanilla-RNN-Initialized-with-Identity-Matrix-ReLU（Quoc-V-Le-arXiv’15）" class="headerlink" title="Vanilla RNN Initialized with Identity Matrix + ReLU（Quoc V.Le, arXiv’15）"></a>Vanilla RNN Initialized with Identity Matrix + ReLU（Quoc V.Le, arXiv’15）</h3><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RNN的损失函数&quot;&gt;&lt;a href=&quot;#RNN的损失函数&quot; class=&quot;headerlink&quot; title=&quot;RNN的损失函数&quot;&gt;&lt;/a&gt;RNN的损失函数&lt;/h2&gt;&lt;p&gt;仍然以Slot Filling为例，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-9.1循环神经网络RNN入门</title>
    <link href="https://chouxianyu.github.io/2021/04/10/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-9-1%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/10/李宏毅机器学习课程笔记-9-1循环神经网络RNN入门/</id>
    <published>2021-04-10T00:53:08.000Z</published>
    <updated>2021-04-10T01:02:16.365Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Slot-Filling"><a href="#Slot-Filling" class="headerlink" title="Slot Filling"></a>Slot Filling</h2><p>比如在订票系统中，输入“Arrive Taipei on November 2nd”这样一个序列，我们设置几个slot(槽位)，希望算法能够将关键词“Taipei”放入Destination这个slot，将”November”和”2nd”放入到达时间Time of Arrival这个slot，而“Arrive”和“on”不属于任何slot。那这个算法如何实现呢？</p><h2 id="Slot-Filling-with-FNN"><a href="#Slot-Filling-with-FNN" class="headerlink" title="Slot Filling with FNN"></a>Slot Filling with FNN</h2><p>可以用Feedforward Neural Network实现Slot Filling吗？可以，下面介绍这种FNN的输入和输出，但其存在问题。</p><p>输入是一个word（比如“Taipei”）并用vector来表示它；输出是1个probablity distribution，表示输入的word属于各个slot的概率。</p><p>如何用vector表示1个word呢？方法有很多。比如<strong>1-of-N Encoding</strong>(又名one-hot Encoding)，如下图所示。设定1个lexicon(词汇表)，那vector的size就和lexicon的size相同，vector中的每个维度对应lexicon中的word，vector中word对应的维度的值为1、其它维度的值为0。</p><p><img src="https://pic1.zhimg.com/80/v2-44be0e091d503721158e1bbee1cdb048_720w.png" alt="img"></p><p>如下图所示，只有1-of-N Encoding还不够，一些word不在lexicon中，对此我们需要在lexicon中添加1个”<strong>other</strong>“。除了1-of-N Encoding，还可以通过<strong>word hashing</strong>。可以用1个26×26×26的vector表示1个word，该vector中每个元素代表1个3字母序列。比如”apple”包括”app”、”ppl”、”ple”。</p><p><img src="https://pic4.zhimg.com/80/v2-828e73ac8019838e7667eeb033859d40_720w.png" alt="img"></p><p>使用FNN实现Slot Filling时会存在一个问题：假如有2个句子“Arrive Taipei on November 2nd”和“Leave Taipei on November 2nd”，在处理这2个句子时FNN会先处理“arrive”和“leave”这2个词汇然后再处理“Taipei”。<strong>这时FNN没有办法区分出“Taipei”是出发地还是目的地，而我们希望算法在处理序列时是有“记忆力”的（即在处理“Taipei”时，它还记得“Leave”或“Arrive”）</strong>，于是RNN诞生了。</p><h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><p>如下图所示，<strong>将每1个隐藏层的输出保存在memory中，网络不仅考虑了input，还要考虑memory中的数据</strong>（merory中的数据是需要有初值的，比如0）。</p><p><img src="https://pic1.zhimg.com/80/v2-f151d27c684e3ae8e60cb9d55d4a78fe_720w.png" alt="img"></p><p>因为RNN会考虑memory中存储的临时值，而不同输入产生的临时值不一定相同，所以<strong>改变输入序列中元素的顺序会导致最终输出结果的改变</strong>（Changing the sequence order will change the output）。</p><h2 id="Slot-Filling-with-RNN"><a href="#Slot-Filling-with-RNN" class="headerlink" title="Slot Filling with RNN"></a>Slot Filling with RNN</h2><p>如下图所示，以“Arrive Taipei on November 2nd” 这个word sequence为例，将“Arrive”的vector$x^1$输入到RNN，隐藏层生成$a^1$，根据$a^1$生成$y^1$，表示“arrive”属于每个slot的概率，其中$a^1$会被存储到memory中；将“Taipei”的vector$x^2$输入到RNN，此时隐藏层同时考虑$x^2$和memory中的$a^1$生成$a^2$，根据$a^2$生成$y^2$，表示“Taipei”属于某个slot的概率，此时再把$a^2$存到memory中；以此类推根据$x_3$和$a_2$生成$a_3$进而得到$y^3$……</p><p><img src="https://pic2.zhimg.com/80/v2-e16243c99c04f52df6f52ae560fdfb03_720w.png" alt="img"></p><h2 id="RNN的变体"><a href="#RNN的变体" class="headerlink" title="RNN的变体"></a>RNN的变体</h2><h3 id="Elman-Network-amp-Jordan-Network"><a href="#Elman-Network-amp-Jordan-Network" class="headerlink" title="Elman Network &amp; Jordan Network"></a>Elman Network &amp; Jordan Network</h3><p>RNN也有不同的变形。<strong>Elman Network是把隐藏层的输出存到memory中，而Jordan Network是把输出层的输出保存到memory中</strong>。由于隐藏层没有明确的训练目标，而整个NN具有明确的目标，因此Jordan Network的表现会更好一些。</p><p><img src="https://pic4.zhimg.com/80/v2-7df1a297e9879628ea03333d79b06d22_720w.png" alt="img"></p><h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>如下图所示，<strong>RNN可以是双向的</strong>。训练2个方向的RNN，1个从前往后读取序列，1个从后往前读取序列，然后使用2个RNN的隐藏层得到最后的输出层。这样的好处是，<strong>输出层的感受野更大</strong>，因为RNN在得到$y^{t+1}$的时候，它不只看了从句首$x^1$开始到$x^{t+1}$的数据，还看了从句尾$x^{n}$一直到$x^{t+1}$的输入，这就相当于<strong>RNN是在看过整个句子之后才计算每个word属于哪个slot的概率</strong>。</p><p><img src="https://pic2.zhimg.com/80/v2-a591f7a3eda6fd1328ae36273451bff2_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Slot-Filling&quot;&gt;&lt;a href=&quot;#Slot-Filling&quot; class=&quot;headerlink&quot; title=&quot;Slot Filling&quot;&gt;&lt;/a&gt;Slot Filling&lt;/h2&gt;&lt;p&gt;比如在订票系统中，输入“Arrive Taipei on N
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="循环神经网络" scheme="https://chouxianyu.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-8.2图神经网络(Spatial-based Convolution)</title>
    <link href="https://chouxianyu.github.io/2021/04/05/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-8-2%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Spatial-based-Convolution/"/>
    <id>https://chouxianyu.github.io/2021/04/05/李宏毅机器学习课程笔记-8-2图神经网络-Spatial-based-Convolution/</id>
    <published>2021-04-05T12:06:39.000Z</published>
    <updated>2021-04-05T12:07:56.753Z</updated>
    
    <content type="html"><![CDATA[<h2 id="术语（Terminology）"><a href="#术语（Terminology）" class="headerlink" title="术语（Terminology）"></a>术语（Terminology）</h2><ul><li><p><strong>Aggregation</strong></p><p>  Aggregation是Convolution在GNN中的推广。Aggregation就是在某一个layer中用某node及其neighbor的feature得到下一个layer中该node的feature。</p></li><li><p><strong>Readout</strong></p><p>  Readout有点像是全连接在GNN中的推广。Readout就是汇总整个图的信息，最终得到一个特征来表示这整个图（Graph Representation）。</p></li></ul><h2 id="NN4G-Neural-Network-for-Graph"><a href="#NN4G-Neural-Network-for-Graph" class="headerlink" title="NN4G(Neural Network for Graph)"></a>NN4G(Neural Network for Graph)</h2><p>论文链接：<a href="https://ieeexplore.ieee.org/document/4773279" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/4773279</a></p><ul><li><p>输入层</p><p>  假如是一个化学分子，输入层的图中的结点就是一个原子。不同原子有不同的特征， 其特征可以是任何和原子相关的化学特征，所以需要<strong>embedding</strong>（将高维特征映射到低维特征），做完embedding也就得到了隐藏层$h^0$。</p></li><li><p>隐藏层$h^0$</p><p>  如何做embedding呢？让原特征乘以embedding matrix就得到隐藏层$h^0$。如下图所示，以1个结点为例，输入层中结点$v_3$的特征是$x_3$，该结点embedding时的计算式为$h^0_3=\bar w_0\cdot x_3$。<strong>embedding</strong>后就得到了隐藏层$h^0$，然后再对隐藏层$h^0$进行<strong>Aggregation</strong>就得到了隐藏层$h^1$。</p><p>  <img src="https://pic2.zhimg.com/80/v2-cff58a466296d02f900be31d89fca62a_720w.png" alt="img"></p></li><li><p>隐藏层$h^1$</p><p>  如何做Aggregation呢？如下图所示，以1个结点为例，在隐藏层$h^0$中，结点$h^0_3$和$h^0_0,h^0_2,h^0_4$3个结点相邻，则Aggregation时计算式为$h^1_3=\hat w_{1,0}(h^0_0+h^0_2+h^0_4)+\bar w_1\cdot x_3$。<strong>经过多次Aggregation，最后需要Readout</strong>。</p><p>  <img src="https://pic3.zhimg.com/80/v2-35dabe169d54b8815ad452c1c105cd75_720w.png" alt="img"></p></li><li><p>Readout</p><p>  如何做Readout呢？如下图所示，假设有3个隐藏层，那Readout的计算式为$y=MEAN(h^0)+MEAN(h^1)+MEAN(h^2)$。</p><p>  <img src="https://pic4.zhimg.com/80/v2-99a44d03b0f47295abfe6d62eaa77bde_720w.png" alt="img"></p></li></ul><h2 id="DCNN-Diffusion-Convolution-Neural-Network"><a href="#DCNN-Diffusion-Convolution-Neural-Network" class="headerlink" title="DCNN(Diffusion-Convolution Neural Network)"></a>DCNN(Diffusion-Convolution Neural Network)</h2><p>论文链接：<a href="https://arxiv.org/abs/1511.02136" target="_blank" rel="noopener">https://arxiv.org/abs/1511.02136</a></p><ul><li><p>输入层</p><p>  假如我们有1个和上例中（NN4G）一样的输入图。</p></li><li><p>隐藏层$h^0$</p><p>  如下图所示，从输入层到隐藏层$h^0$的计算式为$h^0_3=w^0_3MEAN(d(3,\cdot)=1)$，其中$d(3,\cdot)=1$表示所有与结点$x_3$距离为1的输入层结点的特征。</p><p>  <img src="https://pic4.zhimg.com/80/v2-97b6883501dbd6fca82612e42f9e02b4_720w.png" alt="img"></p></li><li><p>隐藏层$h^1$</p><p>  如下图所示，从隐藏层$h^0$到隐藏层$h^1$的计算式为$h^1_3=w^1_3MEAN(d(3,\cdot)=2)$，其中$d(3,\cdot)=2$表示所有与结点$x_3$距离为2的输入层结点的特征。</p><p>  <img src="https://pic2.zhimg.com/80/v2-8282b7f79e512aa9bc1a1b3a18a295aa_720w.png" alt="img"></p><p>  以此类推，<strong>叠加k个隐藏层后就可以获取各结点k范围内的信息</strong>。如下图所示，令1个隐藏层中多个结点的特征形成矩阵（1行是1个结点的特征），多个隐藏层的特征就形成多个通道$H^0,H^1,\dots,H^k$。</p><p>  <img src="https://pic2.zhimg.com/80/v2-ec751b3608ee583f1f6a4cd320ff2f0b_720w.png" alt="img"></p></li><li><p>Node features</p><p>  如何表达整个图的特征呢？如下图所示，将每个通道的特征flatten，然后再乘以参数$w$得到$y_1$即可。</p><p>  <img src="https://pic1.zhimg.com/80/v2-c226fe1e317a545f5c9c5b2c114a0a7b_720w.png" alt="img"></p><p>  也有其它做法，ICLR2018中<a href="https://arxiv.org/abs/1707.01926" target="_blank" rel="noopener">DGC(Diffusion Graph Convolution)</a>不是flatten，而是相加，如下图所示。</p><p>  <img src="https://pic4.zhimg.com/80/v2-7110f786304c6ed60fd4071e00e23047_720w.png" alt="img"></p></li></ul><h2 id="MoNET-Mixture-Model-Networks"><a href="#MoNET-Mixture-Model-Networks" class="headerlink" title="MoNET(Mixture Model Networks)"></a>MoNET(Mixture Model Networks)</h2><p>NN4G、DCNN都是将邻居结点的特征直接相加，并没有考虑各个邻居结点特征的重要性，而MoNET考虑了这个问题。</p><p>论文链接：<a href="https://arxiv.org/abs/1611.08402" target="_blank" rel="noopener">https://arxiv.org/abs/1611.08402</a></p><p>MoNET定义了结点距离的概念，基于结点距离表示各个邻居结点特征的重要性然后对各个邻居结点进行<strong>加权</strong>求和，而不是简单地取均值或求和。</p><p>如下图所示，假如我们有和上例一样的输入图，隐藏层$h^0$中结点$v_3$的特征为$h^0_3$，结点$v_3$和结点$v_0$的距离为$u_{3,0}$。</p><p>定义结点$x,y$的距离$u(x,y)=(\frac{1}{\sqrt{deg(x)}},\frac{1}{\sqrt{deg(y)}})^T$，其中$deg(x)$表示结点$x$的度（degree，度是连接到每个节点的边的数量）。</p><p><img src="https://pic1.zhimg.com/80/v2-454c766a5484d4fe7f79178e679fab55_720w.png" alt="img"></p><h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><p><strong>SA</strong>mple and aggre<strong>G</strong>at<strong>E</strong>(GraphSAGE)，在transductive和inductive setting上都能work。</p><p>论文链接：<a href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener">https://arxiv.org/abs/1706.02216</a></p><p>GraphSAGE的Aggregation除了mean，还有max pooling和LSTM。LSTM用来处理序列数据，但图中结点的邻居并没有序列关系，但如果每次在邻居中随机取样出不同顺序，那也许可以忽略顺序学习到顺序无关的信息。</p><h2 id="GAT-Graph-Attention-Networks"><a href="#GAT-Graph-Attention-Networks" class="headerlink" title="GAT(Graph Attention Networks)"></a>GAT(Graph Attention Networks)</h2><p>论文链接：<a href="https://arxiv.org/abs/1710.10903" target="_blank" rel="noopener">https://arxiv.org/abs/1710.10903</a></p><p>GAT不只是做加权求和（weighted sum），而其中的weight是通过学习得到的，方法就是对邻居做attention。</p><p>假如我们有1个和上例中（NN4G）一样的输入图。在做aggregation时，我们通过函数$f$计算各个邻居结点$v_0,v_2,v_4$对结点$v_3$的重要性，然后做加权求和。</p><p><img src="https://pic4.zhimg.com/80/v2-d293babed38f57a74e8740be39dd69d8_720w.png" alt="img"></p><h2 id="GIN-Graph-Isomorphism-Network"><a href="#GIN-Graph-Isomorphism-Network" class="headerlink" title="GIN(Graph Isomorphism Network)"></a>GIN(Graph Isomorphism Network)</h2><p>这篇论文偏理论，证明出有些方法是work的，有些是不会work的。</p><p>比如提取特征时不要用mean或max（在一些情况下会fail），要用sum，如下图所示。</p><p><img src="https://pic4.zhimg.com/80/v2-ad2c1fd4a3043d56cd5420c03d3cfef7_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;术语（Terminology）&quot;&gt;&lt;a href=&quot;#术语（Terminology）&quot; class=&quot;headerlink&quot; title=&quot;术语（Terminology）&quot;&gt;&lt;/a&gt;术语（Terminology）&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="图神经网络" scheme="https://chouxianyu.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-7.4基于CNN和PyTorch的食物图片分类</title>
    <link href="https://chouxianyu.github.io/2021/04/05/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-7-4%E5%9F%BA%E4%BA%8ECNN%E5%92%8CPyTorch%E7%9A%84%E9%A3%9F%E7%89%A9%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    <id>https://chouxianyu.github.io/2021/04/05/李宏毅机器学习课程笔记-7-4基于CNN和PyTorch的食物图片分类/</id>
    <published>2021-04-05T11:42:47.000Z</published>
    <updated>2021-04-13T08:52:03.190Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework3的记录。</p><p>全部课程PPT、数据和代码下载链接：</p><p>链接：<a href="https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg" target="_blank" rel="noopener">https://pan.baidu.com/s/1n_N7aoaNxxwqO03EmV5Bjg</a> 提取码：tpmc</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述</p><p>  通过CNN实现食物图片分类，数据集已提供</p></li><li><p>数据集描述</p><p>  11个图片类别，训练集中有9866张图片，验证集中有3430张图片，测试集中有3347张图片。</p><p>  训练集和验证集中图片命名格式为<code>类别_编号.jpg</code>，编号不重要。</p></li><li><p>代码</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn.modules.activation <span class="keyword">import</span> ReLU</span><br><span class="line"><span class="keyword">from</span> torch.nn.modules.batchnorm <span class="keyword">import</span> BatchNorm2d</span><br><span class="line"><span class="keyword">from</span> torch.nn.modules.pooling <span class="keyword">import</span> MaxPool1d, MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""加载数据"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_files</span><span class="params">(dir_path)</span>:</span> <span class="comment"># 读取文件夹中的所有图片</span></span><br><span class="line">    filenames = sorted(os.listdir(dir_path))</span><br><span class="line">    x = np.zeros((len(filenames), <span class="number">128</span>, <span class="number">128</span>, <span class="number">3</span>), dtype=np.uint8) <span class="comment"># (N,H,W,C)</span></span><br><span class="line">    y = np.zeros((len(filenames)), dtype=np.uint8)</span><br><span class="line">    <span class="keyword">for</span> i, filename <span class="keyword">in</span> enumerate(filenames):</span><br><span class="line">        img = cv2.imread(os.path.join(dir_path, filename))</span><br><span class="line">        x[i, : , :] = cv2.resize(img, (<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">        y[i] = int(filename.split(<span class="string">"_"</span>)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line">train_x, train_y = read_files(<span class="string">"./data/training"</span>)</span><br><span class="line">val_x, val_y = read_files(<span class="string">"./data/validation"</span>)</span><br><span class="line">print(<span class="string">"Data Loaded"</span>)</span><br><span class="line">print(<span class="string">"Size of training data : %d"</span> % len(train_x))</span><br><span class="line">print(<span class="string">"Size of validation data : %d"</span> % len(val_x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""数据变换（训练时进行数据增强）"""</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(mode=<span class="keyword">None</span>), <span class="comment"># 将图片格式转换成PIL格式</span></span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>), <span class="comment"># 随机水平翻转</span></span><br><span class="line">    transforms.RandomRotation(<span class="number">15</span>), <span class="comment"># 随机旋转图片</span></span><br><span class="line">    transforms.ToTensor(), <span class="comment"># 转换成torch中的tensor并将值normalize到[0.0,1.0]</span></span><br><span class="line">])</span><br><span class="line">val_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""加载数据"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImgDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, y=None, transform=None)</span>:</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.y = torch.LongTensor(y)</span><br><span class="line">        self.transform = transform</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.x)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        X = self.x[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            X = self.transform(X)</span><br><span class="line">        <span class="keyword">if</span> self.y <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            Y = self.y[index]</span><br><span class="line">            <span class="keyword">return</span> X, Y</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">train_set = ImgDataset(train_x, train_y, train_transform)</span><br><span class="line">val_set = ImgDataset(val_x, val_y, val_transform)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="keyword">True</span>)</span><br><span class="line">val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""定义模型"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        self.cnn = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [64, 128, 128]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>), <span class="comment"># [64, 64, 64]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [128, 64, 64]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>), <span class="comment"># [128, 32, 32]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [256, 32, 32]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>), <span class="comment"># [256, 16, 16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 16, 16]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>), <span class="comment"># [512, 8, 8]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>), <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.cnn(x)</span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>], <span class="number">-1</span>) <span class="comment"># torch.nn只支持mini-batches而不支持单个sample，第1个维度是mini-batch中图片（特征）的索引，即将每张图片都展开</span></span><br><span class="line">        <span class="keyword">return</span> self.fc(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""训练并测试模型"""</span></span><br><span class="line">model = Model() <span class="comment"># model = Model().cuda()</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    epoch_start_time = time.time()</span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    val_acc = <span class="number">0.0</span></span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># batch_loss.backward()的gradient会累加，所以每个batch都需要置零</span></span><br><span class="line">        pred = model(data[<span class="number">0</span>]) <span class="comment"># pred = model(data[0].cuda())</span></span><br><span class="line">        batch_loss = criterion(pred, data[<span class="number">1</span>]) <span class="comment"># batch_loss = criterion(pred, data[1].cuda())</span></span><br><span class="line">        batch_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_acc += np.sum(np.argmax(pred.detach().numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">        <span class="comment"># train_acc += np.sum(np.argmax(pred.cpu().detach().numpy(), axis=1) == data[1].numpy())</span></span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(val_loader):</span><br><span class="line">            pred = model[data[<span class="number">0</span>]] <span class="comment"># pred = model(data[0].cuda())</span></span><br><span class="line">            batch_loss = criterion(pred, data[<span class="number">1</span>]) <span class="comment"># batch_loss = criterion(pred, data[1].cuda())</span></span><br><span class="line">            val_acc += np.sum(np.argmax(pred.detach().numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">            <span class="comment"># val_acc += np.sum(np.argmax(pred.cpu().detach().numpy(), axis=1) == data[1].numpy())</span></span><br><span class="line">            val_loss += batch_loss.item()</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f'</span> % \</span><br><span class="line">            (epoch+<span class="number">1</span>, epochs, time.time()-epoch_start_time, \</span><br><span class="line">             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))</span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework3的记录。&lt;/p&gt;
&lt;p&gt;全部课程PPT、数据和代码下载链接：&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pan.baidu.com/
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="图片分类" scheme="https://chouxianyu.github.io/tags/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
      <category term="卷积神经网络" scheme="https://chouxianyu.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch入门：基于LeNet5和CIFAR10的图片分类</title>
    <link href="https://chouxianyu.github.io/2021/04/04/PyTorch%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8ELeNet5%E5%92%8CCIFAR10%E7%9A%84%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    <id>https://chouxianyu.github.io/2021/04/04/PyTorch入门：基于LeNet5和CIFAR10的图片分类/</id>
    <published>2021-04-04T05:45:03.000Z</published>
    <updated>2021-04-04T05:53:56.482Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="https://www.cnblogs.com/chouxianyu/p/14613460.html" target="_blank" rel="noopener">PyTorch入门：使用PyTorch搭建神经网络LeNet5</a>一文中，我们已经使用PyTorch实现了一个简单的神经网络LeNet5，本文将基于PyTorch使用LeNet5和CIFAR10实现图片分类模型的定义、训练和测试的全过程，代码(有详细注释)如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建神经网络模型：将LeNet5模型的输入改为3个通道</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">6</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(in_features=<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>, out_features=<span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(in_features=<span class="number">120</span>, out_features=<span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(in_features=<span class="number">84</span>, out_features=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## normalize：torchvision中数据集是元素值在[0,1]范围的PIL图片(C,H,W)，需将其数值范围转换为[-1,1]</span></span><br><span class="line">normalization = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 加载CIFAR10数据集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="keyword">True</span>, transform=normalization, download=<span class="keyword">True</span>)</span><br><span class="line">train_set_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=<span class="number">4</span>, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">0</span>) <span class="comment"># Windows系统中建议把num_workers设为0</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="keyword">False</span>, transform=normalization, download=<span class="keyword">True</span>)</span><br><span class="line">test_set_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=<span class="number">4</span>, shuffle=<span class="keyword">False</span>, num_workers=<span class="number">0</span>) <span class="comment"># Windows系统中建议把num_workers设为0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## 显示CIFAR10数据集中的一些图片</span></span><br><span class="line"><span class="comment"># def imshow(img):</span></span><br><span class="line"><span class="comment">#     # print(img.size())</span></span><br><span class="line"><span class="comment">#     img = img / 2 + 0.5 # unnormalize: [-1,1] =&gt; [0,1]</span></span><br><span class="line"><span class="comment">#     img = img.numpy()</span></span><br><span class="line"><span class="comment">#     plt.imshow(np.transpose(img, (1, 2, 0))) # PIL的(C,H,W) =&gt; matplotlib的(H,W,C)</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')</span></span><br><span class="line"><span class="comment"># data_iter = iter(train_set_loader)</span></span><br><span class="line"><span class="comment"># images, labels = data_iter.next() # images, labels都是tensor</span></span><br><span class="line"><span class="comment"># # print(images.size())</span></span><br><span class="line"><span class="comment"># # print(labels.size())</span></span><br><span class="line"><span class="comment"># imshow(torchvision.utils.make_grid(images))</span></span><br><span class="line"><span class="comment"># print(' '.join('%s' % classes[labels[j]] for j in range(len(labels))))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 定义神经网络、损失函数和优化器</span></span><br><span class="line">net = Net()</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(params=net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>) <span class="comment"># SGD with momentum</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 训练神经网络</span></span><br><span class="line">print(<span class="string">'Training Started'</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">5</span>): <span class="comment"># 1个epoch会将所有数据训练一次</span></span><br><span class="line">    running_loss = <span class="number">0.0</span> <span class="comment"># 用来在控制台输出loss，以观察训练情况</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(iterable=train_set_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># 获取数据</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        <span class="comment"># 清空梯度缓存</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 输出每2000个mini-batch的平均loss</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>: <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            print(<span class="string">'[%3d, %5d] loss: %.3f'</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 保存模型参数</span></span><br><span class="line">torch.save(net.state_dict(), <span class="string">'./data/LeNet5.pt'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 测试模型</span></span><br><span class="line">print(<span class="string">'Testing Started'</span>)</span><br><span class="line">net_new = Net()</span><br><span class="line">net_new.load_state_dict(torch.load(<span class="string">'./data/LeNet5.pt'</span>))</span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_set_loader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        _, predictions = torch.max(net_new(images), <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predictions==labels).sum().item()</span><br><span class="line">print(<span class="string">'Accuracy: %d/%d = %.2f%%'</span> % (correct, total, correct/total*<span class="number">100</span>) )</span><br><span class="line"></span><br><span class="line"><span class="string">"""Explore:</span></span><br><span class="line"><span class="string">使用GPU后会发现速度并没有增加很多，原因是LeNet这个模型非常小。</span></span><br><span class="line"><span class="string">如果将模型宽度增大（增加2个卷积层的卷积核数量），GPU对模型的加速效果会是怎么样的呢？</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在&lt;a href=&quot;https://www.cnblogs.com/chouxianyu/p/14613460.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PyTorch入门：使用PyTorch搭建神经网络LeNet5&lt;/a&gt;一文中，我们已经使
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
      <category term="图片分类" scheme="https://chouxianyu.github.io/tags/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch入门：使用PyTorch搭建神经网络LeNet5</title>
    <link href="https://chouxianyu.github.io/2021/04/03/PyTorch%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BD%BF%E7%94%A8PyTorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CLeNet5/"/>
    <id>https://chouxianyu.github.io/2021/04/03/PyTorch入门：使用PyTorch搭建神经网络LeNet5/</id>
    <published>2021-04-03T01:47:13.000Z</published>
    <updated>2021-04-03T04:17:40.842Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在本文中，我们基于PyTorch构建一个简单的神经网络LeNet5。</p><p>在阅读本文之前，建议您了解一些卷积神经网络的前置知识，比如卷积、Max Pooling和全连接层等等，可以看我写的相关文章：<a href="https://zhuanlan.zhihu.com/p/360796545" target="_blank" rel="noopener">李宏毅机器学习课程笔记-7.1CNN入门详解</a>。</p><p>通过阅读本文，您可以学习到如何使用PyTorch构建神经网络LeNet5。</p><h1 id="模型说明"><a href="#模型说明" class="headerlink" title="模型说明"></a>模型说明</h1><p>在本例中，我们使用如下图所示的神经网络模型：LeNet5。</p><p><img src="https://pic1.zhimg.com/80/v2-e3852bfd8a716bda7cddac603628affa_720w.png" alt="img"></p><p>该模型有1个输入层、2个卷积层、2次Max Pooling、2个全连接层和1个输出层。</p><ul><li><p>输入层INPUT</p><p>  1个channel，图片size是32×32。</p></li><li><p>卷积层C1</p><p>  6个channel，特征图的size是28×28，即每个卷积核的size为(5,5)，stride为1。</p></li><li><p>下采样操作S2</p><p>  6个channel，特征图的size是14×14，即Max Pooling窗口size为(2,2)。</p></li><li><p>卷积层C3</p><p>  16个channel，特征图的size是10×10，即每个卷积核的size为(5,5)，stride为1。</p></li><li><p>下采样操作S4</p><p>  16个channel，特征图的size是5×5，即Max Pooling窗口size为(2,2)。</p></li><li><p>全连接层F5</p><p>  120个神经元。</p></li><li><p>全连接层F6</p><p>  84个神经元。</p></li><li><p>输出层OUTPUT</p><p>  10个神经元。</p></li></ul><p>另外，除了输入层和输出层，剩下的卷积层、最大池化操作和全连接层后面都要加上Relu激活函数，下采样操作S4之后需要进行Flatten以和全连接层F5衔接起来。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet5</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LeNet5, self).__init__()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        self.fc5 = nn.Linear(in_features=<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>, out_features=<span class="number">120</span>)</span><br><span class="line">        self.fc6 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.OUTPUT = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, (<span class="number">2</span>, <span class="number">2</span>)) <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.relu(self.conv3(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>) <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>) <span class="comment"># Flatten</span></span><br><span class="line">        x = F.relu(self.fc5(x))</span><br><span class="line">        x = F.relu(self.fc6(x))</span><br><span class="line">        x = self.OUTPUT(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = LeNet5()</span><br><span class="line">output = net(torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line"><span class="comment"># print(output)</span></span><br></pre></td></tr></table></figure><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html</a></p><p>其实本文内容主要是PyTorch的官方教程。</p><p>PyTorch官方教程中代码实现与图片所示的LeNet5不符（PyTorch官方教程代码中是3×3的卷积核，而图片中LeNet5是5×5的卷积核），本文中我是按照图片所示模型结构实现的。</p><p>其实PyTorch开发者和其他开发者也注意到了这一问题，详见：</p><p><a href="https://github.com/pytorch/tutorials/pull/515" target="_blank" rel="noopener">https://github.com/pytorch/tutorials/pull/515</a></p><p><a href="https://github.com/pytorch/tutorials/commit/630802450c13c78f02f744af1c47d1033b6fe206" target="_blank" rel="noopener">https://github.com/pytorch/tutorials/commit/630802450c13c78f02f744af1c47d1033b6fe206</a></p><p><a href="https://github.com/pytorch/tutorials/pull/1257" target="_blank" rel="noopener">https://github.com/pytorch/tutorials/pull/1257</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;在本文中，我们基于PyTorch构建一个简单的神经网络LeNet5。&lt;/p&gt;
&lt;p&gt;在阅读本文之前，建议您了解一些卷积神经网络的前置知识，比
      
    
    </summary>
    
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="PyTorch" scheme="https://chouxianyu.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-8.1图神经网络入门</title>
    <link href="https://chouxianyu.github.io/2021/04/02/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-8-1%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8/"/>
    <id>https://chouxianyu.github.io/2021/04/02/李宏毅机器学习课程笔记-8-1图神经网络入门/</id>
    <published>2021-04-01T17:25:04.000Z</published>
    <updated>2021-04-01T17:41:57.916Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GNN的用处"><a href="#GNN的用处" class="headerlink" title="GNN的用处"></a>GNN的用处</h2><h3 id="分类（Classification）"><a href="#分类（Classification）" class="headerlink" title="分类（Classification）"></a>分类（Classification）</h3><p>比如，有很多不同的化学分子，将其表示成图作为输入，用GNN判断其是否会导致突变，这就是一个有监督分类问题。</p><h3 id="生成（Generation）"><a href="#生成（Generation）" class="headerlink" title="生成（Generation）"></a>生成（Generation）</h3><p>比如，我们需要开发针对新冠病毒的新药，我们可以训练出一个可以生成我们想要的分子（输出形式为图）的GNN，然后用这个GNN生成可以对抗病毒的某种化学分子。</p><p>GraphVAE</p><h2 id="为什么要用GNN"><a href="#为什么要用GNN" class="headerlink" title="为什么要用GNN"></a>为什么要用GNN</h2><p>上面列举的分类、生成的例子中输入或输出都是图，所以要用GNN。图不仅包含了各个结点的信息，更重要的是它包含了<strong>各个结点之间的关系</strong>。</p><h2 id="使用GNN时可能遇到的问题"><a href="#使用GNN时可能遇到的问题" class="headerlink" title="使用GNN时可能遇到的问题"></a>使用GNN时可能遇到的问题</h2><ul><li>如何通过结点间的信息帮助模型</li><li>图中可能包含大量结点，数据集非常大</li><li><strong>大量结点都是没有label的</strong></li></ul><h2 id="GNN的两种思路"><a href="#GNN的两种思路" class="headerlink" title="GNN的两种思路"></a>GNN的两种思路</h2><p>很直观地可以想到，一个结点和它的相邻结点肯定有某些特定的关系，比如说相似（近朱者赤近墨者黑）、相反、合作等等。在多数情况下，数据集unlabeled node都是远多于labeled node的，我们想要得到一个较好的模型，那我们要如何利用仅有的少量labeled node以及它和邻居间的关系呢？结合CNN，我们要如何将卷积这个操作推广到GNN模型中，用卷积将结点嵌入到某个特征空间中呢？有两种方法</p><ul><li><p><strong>Spatial-based Convolution</strong></p><p>  Generalize the concept of convolution(corelation) to graph.</p></li><li><p><strong>Spectral-based Convolution</strong></p><p>  Back to the definition of convolution in signal processing.</p></li></ul><h2 id="GNN导图"><a href="#GNN导图" class="headerlink" title="GNN导图"></a>GNN导图</h2><p><img src="https://pic4.zhimg.com/80/v2-7e0da7ed579a0d8a74bb7d873d3449ae_720w.png" alt="img"></p><h2 id="任务和数据集"><a href="#任务和数据集" class="headerlink" title="任务和数据集"></a>任务和数据集</h2><h3 id="常见任务"><a href="#常见任务" class="headerlink" title="常见任务"></a>常见任务</h3><ul><li>Classification</li><li>Regression</li><li>Graph Classification</li><li>Graph Representation Learning</li><li>Link Prediction</li></ul><h3 id="常用数据集"><a href="#常用数据集" class="headerlink" title="常用数据集"></a>常用数据集</h3><ul><li>CORA: citation network, 2.7k nodes and 5.4k links</li><li>TU-MUTAG: 188 molecules with 18 nodes on average</li></ul><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p><a href="https://www.dgl.ai/" target="_blank" rel="noopener">https://www.dgl.ai/</a></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;GNN的用处&quot;&gt;&lt;a href=&quot;#GNN的用处&quot; class=&quot;headerlink&quot; title=&quot;GNN的用处&quot;&gt;&lt;/a&gt;GNN的用处&lt;/h2&gt;&lt;h3 id=&quot;分类（Classification）&quot;&gt;&lt;a href=&quot;#分类（Classification）&quot;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="图神经网络" scheme="https://chouxianyu.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-7.3CNN应用案例</title>
    <link href="https://chouxianyu.github.io/2021/04/01/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-7-3CNN%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B/"/>
    <id>https://chouxianyu.github.io/2021/04/01/李宏毅机器学习课程笔记-7-3CNN应用案例/</id>
    <published>2021-04-01T04:15:26.000Z</published>
    <updated>2021-04-01T04:18:04.287Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Deep-Dream"><a href="#Deep-Dream" class="headerlink" title="Deep Dream"></a>Deep Dream</h2><p><a href="https://deepdreamgenerator.com/" target="_blank" rel="noopener">Deep Dream</a>是这样的：如果给机器一张图片$x$，Deep Dream会把机器看到的内容加到图片$x$中得到$x’$。那如何实现呢？</p><p><img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201221135654357-945005692.png"></p><p>如上图所示，将图片$x$输入到CNN中，然后取出CNN中某一层$L$（可以是卷积、池化阶段的隐藏层，也可以是FNN中的隐藏层）的输出$O$，然后将$L$中的正值调大、负值调小得到一个新的输出$O’$，然后通过梯度下降找到一张新的图片$x’$使层$L$的输出为$O’$，这个$x’$就是我们要的结果。直观理解的话，也就是<strong>让CNN夸大它所看到的内容</strong>。</p><p>然后就得到了如下结果……（看到的时候我惊了，真是十分哇塞）</p><p><img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201221135818664-1882676933.png"></p><h2 id="Deep-Style"><a href="#Deep-Style" class="headerlink" title="Deep Style"></a>Deep Style</h2><p><a href="https://dreamscopeapp.com/" target="_blank" rel="noopener">Deep Style</a>是这样的：如果给机器一张图片$x$和$y$，Deep Style可以把图片$y$的风格加到图片$x$上，也就是<strong>风格迁移</strong>。</p><p>那如何实现呢？论文：<a href="https://arxiv.org/abs/1508.06576" target="_blank" rel="noopener">A Neural Algorithm of Artistic Style</a>。</p><ol><li>把图片$x$传入CNN并得到输出，然后其输出作为图片$x$的内容$c_x$（<strong>content</strong>）；</li><li>把图片$y$传入CNN并得到输出，但不是考虑输出的值是什么，而是考虑输出层中各个filter输出之间的相关性（corelation）作为图片$y$的风格$s_y$（<strong>style</strong>）；</li><li>最后基于同一个CNN找到图片$z$，图片$z$传入CNN后得到的内容$c_z$像$c_x$、风格$s_z$像$s_y$。</li></ol><p>如下图所示</p><p><img src="https://pic1.zhimg.com/80/v2-fb5dd2b4083a6b896f57bb7e7a231c50_720w.png" alt="img"></p><h2 id="围棋"><a href="#围棋" class="headerlink" title="围棋"></a>围棋</h2><p>CNN不单单可以用在图像上，还可以用在其它方面，比如下围棋。</p><p>在下围棋这件事上，其实FNN就可以（输入和输出都是19×19=361的vector），但CNN的效果更好。当然还可以用强化学习。</p><p>为什么CNN可以用来下围棋呢？因为围棋具有图像的3个性质，不过AlphaGo并没有用Max Pooling因为它不需要。</p><h2 id="语音"><a href="#语音" class="headerlink" title="语音"></a>语音</h2><p>如下图所示，用<strong>语谱图（Spectrogram）</strong>表示语音。</p><p>语谱图的x轴是时间，y轴是频率，z轴是幅度。幅度用颜色表示（比如亮色表示高、暗色表示低）。</p><p>在语谱图中，CNN的卷积核往往只在y轴方向上移动，这样可以消除男生女生声音频率的差异；卷积核往往不在x轴上移动，因为时间域一般是在后面用LSTM等等进行处理，如下图所示。</p><p><img src="https://pic1.zhimg.com/80/v2-65e8d3ffdc43a45f4f9ca39ea16a9805_720w.png" alt="img"></p><h2 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h2><p>CNN也可以用在文字处理上，比如文本情感分析。具体不再讲，可以看李宏毅老师的<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=17" target="_blank" rel="noopener">视频</a>。</p><p><img src="https://pic4.zhimg.com/80/v2-fec6cc1a30d3f436c71587f91f8f82ee_720w.png" alt="img"></p><h2 id="图片生成"><a href="#图片生成" class="headerlink" title="图片生成"></a>图片生成</h2><p>Deep Dream的方法还是不能画出图片，不过也有其它较为成功的方法，如下图所示。</p><p><img src="https://pic2.zhimg.com/80/v2-dc95952a08fcb965d30784de27789aef_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Deep-Dream&quot;&gt;&lt;a href=&quot;#Deep-Dream&quot; class=&quot;headerlink&quot; title=&quot;Deep Dream&quot;&gt;&lt;/a&gt;Deep Dream&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://deepdreamgenerator.co
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="卷积神经网络" scheme="https://chouxianyu.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-7.2CNN学到了什么</title>
    <link href="https://chouxianyu.github.io/2021/03/31/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-7-2CNN%E5%AD%A6%E5%88%B0%E4%BA%86%E4%BB%80%E4%B9%88/"/>
    <id>https://chouxianyu.github.io/2021/03/31/李宏毅机器学习课程笔记-7-2CNN学到了什么/</id>
    <published>2021-03-31T05:36:40.000Z</published>
    <updated>2021-03-31T05:37:13.456Z</updated>
    
    <content type="html"><![CDATA[<h2 id="卷积核学到了什么"><a href="#卷积核学到了什么" class="headerlink" title="卷积核学到了什么"></a>卷积核学到了什么</h2><p>如果想知道下图中第1个卷积层中的每个卷积核的功能，因为它参数比较少而且其输入是原图片，所以我们直接结合原图片观察卷积核的参数就可以知道该卷积核的功能。</p><p><img src="https://pic2.zhimg.com/80/v2-cb97966c67656a905b06956b7925f645_720w.png" alt="img" style="zoom: 80%;"></p><p>如上图所示，CNN中第2个卷积层的输入不是直观的图片而且其卷积核的感受野比第1个卷积层中卷积核的感受野更大，因此我们无法通过观察卷积核参数了解卷积核学习到了什么。</p><p>上图中CNN第2个卷积层中有50个卷积核，每个卷积核的输出都是一个大小为11×11的矩阵。</p><p>现在定义函数$a^k=\sum_{i=1}^{11}\sum_{j=1}^{11}a^k_{ij}$来衡量某卷积核被“激活”的程度，即将卷积核所输出矩阵的元素之和作为其被“激活”程度，被“激活”程度指CNN输入与该卷积核有多匹配。</p><p>接下来，通过梯度下降求得$x^<em>=arg\ max_x\ a^k$，即找到最能“激活”卷积核的输入图片$x^</em>$，然后将其可视化希求反映该卷积核学习到的内容。</p><p>上图左下角可视化了最能“激活”第2个卷积层中某12个卷积核的12张图片，可以看出各卷积核适用于检测<strong>小的纹理</strong>（这个案例是数字识别）。</p><h2 id="全连接层学到了什么"><a href="#全连接层学到了什么" class="headerlink" title="全连接层学到了什么"></a>全连接层学到了什么</h2><p>如下图所示，我们同样可以用梯度下降找到最能“激活”全连接层中某个神经元的输入，将该输入其可视化，以此观察全连接层学习到了什么。和卷积核不同，卷积核学习到的是<strong>较小的pattern</strong>，全连接层中的神经元学习到的是<strong>尺寸较大的pattern</strong>。</p><p><img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201221130655109-1379139074.png" style="zoom: 50%;"></p><h2 id="输出层学到了什么"><a href="#输出层学到了什么" class="headerlink" title="输出层学到了什么"></a>输出层学到了什么</h2><p>如下图所示，我们同样可以用梯度下降找到最能“激活”输出层中某个神经元的输入，将该输入其可视化，以此观察输出层学习到了什么。在想象中这些输入应该是对应的数字，然而并不是（有人说眯着眼马马虎虎可以从中看到数字）。</p><p>在其它的案例中也有这样的情况，即<strong>机器学习到的内容和人类所理解的内容是不同的</strong>。<a href="https://www.youtube.com/watch?v=M2IebCN9Ht4" target="_blank" rel="noopener">这个视频</a>里讲了相关例子。</p><p>但这个方法(通过“激活”卷积核反映学习到的内容)确实是有效的，那如何改进呢？我们可以对输入做一些限制（constraint）。</p><p><img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201221131204130-1053266641.png" style="zoom: 50%;"></p><p>在该例中数字图片中底色是黑色，前景色（数字）是白色。</p><p>如下图所示，简单考虑的话，我们可以添加图片中大部分像素是黑色的限制（值接近0，也就是L1正则化），然后将求得的输入可视化。</p><p><img src="https://img2020.cnblogs.com/blog/1478490/202012/1478490-20201221133929054-200979562.png" style="zoom:50%;"></p><p>当然，我们可以用更好的方法（比如说更好的限制）找到人类更容易理解的输入……这也是Deep Dream的精神。</p><h2 id="神经网络可视化"><a href="#神经网络可视化" class="headerlink" title="神经网络可视化"></a>神经网络可视化</h2><p><img src="https://pic4.zhimg.com/80/v2-59efdfca9bf326af0199db3ece69dd28_720w.png" alt="img"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;卷积核学到了什么&quot;&gt;&lt;a href=&quot;#卷积核学到了什么&quot; class=&quot;headerlink&quot; title=&quot;卷积核学到了什么&quot;&gt;&lt;/a&gt;卷积核学到了什么&lt;/h2&gt;&lt;p&gt;如果想知道下图中第1个卷积层中的每个卷积核的功能，因为它参数比较少而且其输入是原图片，所以我
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="卷积神经网络" scheme="https://chouxianyu.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-7.1CNN入门详解</title>
    <link href="https://chouxianyu.github.io/2021/03/29/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-7-1CNN%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/"/>
    <id>https://chouxianyu.github.io/2021/03/29/李宏毅机器学习课程笔记-7-1CNN入门详解/</id>
    <published>2021-03-29T09:09:58.000Z</published>
    <updated>2021-03-29T10:54:37.445Z</updated>
    
    <content type="html"><![CDATA[<p>卷积神经网络（CNN）常常被用来做图像处理，当然也可以用一般的神经网络，那它们各自有什么优缺点呢？</p><h2 id="FNN用于图片处理的缺点"><a href="#FNN用于图片处理的缺点" class="headerlink" title="FNN用于图片处理的缺点"></a>FNN用于图片处理的缺点</h2><p>使用一般的全连接前馈神经网络（FNN）处理图片时的缺点：</p><ul><li><p>需要很多的参数</p><p>  假设有一张尺寸100×100的图片（尺寸已经算很小了），那输入层就有100×100×3=30K个像素，假设第一个隐藏层有1K个神经元（一个神经元包含30K个参数），这就已经需要30M个参数了……</p></li><li><p>该架构中每个神经元就是一个分类器，这是没必要的</p><p>  第一个隐藏层作为最基础的pattern分类器（比如判断有无绿色、边缘等），第二个隐藏层基于第一个隐藏层继续做pattern分类（比如木头、肉类），以此类推……</p></li></ul><p>按照人类的直观理解，我们不是像全连接神经网络一样去处理图片的。具体来看，有哪些方面呢？</p><h2 id="图片的一些性质"><a href="#图片的一些性质" class="headerlink" title="图片的一些性质"></a>图片的一些性质</h2><p>结合全连接前馈神经网络的缺点和人类对图片的直观理解，可以得到下述图片的3个性质。</p><h3 id="性质1：Some-patterns-are-much-smaller-than-the-whole-image"><a href="#性质1：Some-patterns-are-much-smaller-than-the-whole-image" class="headerlink" title="性质1：Some patterns are much smaller than the whole image."></a>性质1：Some patterns are much smaller than the whole image.</h3><p>在识别某个模式（pattern）时，一个神经元并不需要图片的所有像素点。对于一张人类全身照的图片，我们只需要看到头部而非整张图片就可以判断它是一个人脸。所以我们应该是可以用少量参数去识别这些pattern的。</p><p><img src="https://pic4.zhimg.com/80/v2-753ba3ca45cd6cc08d8a8d837d2ec425_720w.jpeg" alt="img" style="zoom:80%;"></p><h3 id="性质2：The-same-patterns-appear-in-different-regions"><a href="#性质2：The-same-patterns-appear-in-different-regions" class="headerlink" title="性质2：The same patterns appear in different regions."></a>性质2：The same patterns appear in different regions.</h3><p>比如说人脸可以在图片的中间区域，也可以在图片的某个角落区域。所以识别不同区域中的相同pattern的多个分类器（或detector）应该用同一组参数或者共享参数。</p><p><img src="https://pic1.zhimg.com/80/v2-cb9dfd6b582245692a8fe50979f5f77d_720w.png" alt="img" style="zoom:80%;"></p><h3 id="性质3：Subsampling-the-pixels-will-not-change-the-object"><a href="#性质3：Subsampling-the-pixels-will-not-change-the-object" class="headerlink" title="性质3：Subsampling the pixels will not change the object"></a>性质3：Subsampling the pixels will not change the object</h3><p>将图片缩小/下采样，并不会影响我们理解图片。所以我们可以通过将图片变小，进而用更少的参数处理图片。</p><p><img src="https://pic2.zhimg.com/80/v2-ee9888d41dfe87f1d8715949676ca025_720w.png" alt="img" style="zoom:80%;"></p><h2 id="CNN架构说明"><a href="#CNN架构说明" class="headerlink" title="CNN架构说明"></a>CNN架构说明</h2><p>2014年在ECCV上提出，针对上述的图片的3个性质，确定了CNN的架构如下。</p><p><img src="https://pic2.zhimg.com/80/v2-ea984acebb9fe399847d16b36d6fc559_720w.png" alt="img" style="zoom:80%;"></p><p>如上图所示，图片经过卷积层然后进行最大池化（max pooling），这个步骤可以进行多次；然后将数据展开（Flatten），然后将数据传进全连接前馈网络得到最后的图片分类结果。</p><h2 id="CNN架构作用探析"><a href="#CNN架构作用探析" class="headerlink" title="CNN架构作用探析"></a>CNN架构作用探析</h2><p><img src="https://pic1.zhimg.com/80/v2-544d4e0360461bfebe9624b4b20fedb5_720w.png" alt="img" style="zoom:80%;"></p><p>如上图所示，卷积是针对了图片的性质1和性质2，最大池化是针对了图片的性质3。</p><h2 id="卷积-Convolution-★"><a href="#卷积-Convolution-★" class="headerlink" title="卷积(Convolution) ★"></a>卷积(Convolution) ★</h2><p>假设有一张6×6的二值图，即一个6×6的矩阵。</p><h3 id="卷积核（Filter）"><a href="#卷积核（Filter）" class="headerlink" title="卷积核（Filter）"></a>卷积核（Filter）</h3><p>神经元就是一个计算/函数，卷积核其实就是神经元。</p><p>如下图所示，1个卷积层可以有多个卷积核，矩阵里元素的值就是需要通过学习得到的参数。</p><p>因为这里的输入是一个矩阵，所以卷积核也是1个矩阵（卷积核的通道数等于输入的通道数）。</p><p>假设卷积核大小是3×3，这对应了图片的性质1，即用小的卷积核识别一个小的pattern。</p><p><img src="https://pic1.zhimg.com/80/v2-dd755bcb25fdadf2bc819d96e03879f8_720w.png" alt="img" style="zoom:80%;"></p><h3 id="怎么做卷积"><a href="#怎么做卷积" class="headerlink" title="怎么做卷积"></a>怎么做卷积</h3><p>如下图所示</p><p><img src="https://pic3.zhimg.com/80/v2-be01890275fa85d7b665e5cc70131f30_720w.png" alt="img" style="zoom:80%;"></p><ul><li><p>卷积区域</p><p>  根据该卷积核的大小（以3×3为例），选择图片中相同大小的区域进行卷积。</p></li><li><p>卷积的计算方法</p><p>  从图片中扫描得到的3×3矩阵和卷积核的3×3矩阵，这2个矩阵相同位置的元素相乘可以得到9个值并求和（也就是内积）得到1个值，这就是1次卷积操作。</p></li><li><p>卷积顺序和方向</p><p>  卷积核按照从左到右、从上到下的顺序，从图片左上角开始移动，移动步长（stride）可以设置（以1为例）。在扫描到的每个区域中，都进行1次卷积。1个卷积核移动结束后，则得到1个新的矩阵（大小为4×4），即<strong>1个卷积核的输出是1个矩阵</strong>。</p><p>  卷积层有多个卷积核，每个卷积核都按照该方式进行卷积得到多个矩阵，这些矩阵合起来就形成了1个卷积层的<strong>特征图（Feature Map）</strong>，这个特征图也就是卷积层的输出。</p><p>  <strong>卷积层特征图的通道数等于该卷积层中卷积核的数量，即某卷积层有多少个卷积核，那该卷积层的特征图就有多少个通道</strong>。</p></li></ul><h3 id="卷积的作用"><a href="#卷积的作用" class="headerlink" title="卷积的作用"></a>卷积的作用</h3><p>在上图中，卷积核1的“对角线”的值都是1，就可以识别出图片中哪个区域具有“对角线”。在上图得到的4×4矩阵中，我们可以看到左上角和左下角3个元素的值为3，即有“对角线”。这对应了图片的性质2，我们用1个filter/1组参数识别了不同位置的相同pattern。</p><h3 id="卷积核是矩阵还是张量"><a href="#卷积核是矩阵还是张量" class="headerlink" title="卷积核是矩阵还是张量"></a>卷积核是矩阵还是张量</h3><p>卷积核可以是矩阵，也可以是张量，要根据其输入决定。</p><p><strong>卷积核的通道数等于其所在卷积层输入的通道数（即其所在卷积层前一层的特征图的通道数）</strong>，即单个卷积核会考虑输入的所有通道。</p><p>假如输入是一张RGB图片（大小为3×N×N，即有3个通道、每个通道中矩阵大小为N×N），那卷积核就是1个张量（大小为3×M×M，即有3个通道、每个通道中矩阵大小为M×M），卷积计算方法和上面一样是求内积（两个3×M×M的张量求内积）。</p><h3 id="卷积中如何做梯度下降"><a href="#卷积中如何做梯度下降" class="headerlink" title="卷积中如何做梯度下降"></a>卷积中如何做梯度下降</h3><p>因为一个卷积核要对图片的不同区域进行多次卷积，每次卷积都会有一个梯度，最终把这些梯度取平均值就好了。</p><p>大概这么个意思，实操中这种底层的东西不需要我们实现。</p><h2 id="Convolution-VS-Fully-Connected"><a href="#Convolution-VS-Fully-Connected" class="headerlink" title="Convolution VS Fully Connected"></a>Convolution VS Fully Connected</h2><p>其实，卷积核就是一个神经元，它相当于全连接层中的神经元并没有全连接（没有使用图片的所有像素，当然这样的层也就不能称为全连接层了），这样有两个好处</p><h3 id="模型的参数更少"><a href="#模型的参数更少" class="headerlink" title="模型的参数更少"></a>模型的参数更少</h3><p>如下图所示，因为没有使用所有像素、不是全连接，因此需要的参数更少。</p><p><img src="https://pic2.zhimg.com/80/v2-d386d44d45dc643867b81dc8a4a6a719_720w.png" alt="img" style="zoom: 80%;"></p><h3 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h3><p>如下图所示，因为用同1个卷积核在图片的不同区域做卷积，即用1组参数对不同区域的像素进行计算，得到了多个值、达成了多个神经元的效果，实现了参数共享。比如下图中神经元“3”处理图片第1个像素和神经元“-1”处理图片第2个像素就使用了同一个参数“1”（卷积核的第1个参数）。</p><p>因为实现了参数共享，卷积就比全连接进一步减少了参数量。</p><p><img src="https://pic2.zhimg.com/80/v2-ce7e944ef9280d1bb8505b4fc5f831cf_720w.png" alt="img" style="zoom: 80%;"></p><h2 id="最大池化（Max-Pooling）"><a href="#最大池化（Max-Pooling）" class="headerlink" title="最大池化（Max Pooling）"></a>最大池化（Max Pooling）</h2><p>最大池化是一种下采样（Subsample）,下采样不一定要取最大值，也可以取平均值。</p><h3 id="怎么做最大池化"><a href="#怎么做最大池化" class="headerlink" title="怎么做最大池化"></a>怎么做最大池化</h3><p><img src="https://pic1.zhimg.com/80/v2-b42884461b41f67fa084cc8e2a9d8ac3_720w.png" alt="img" style="zoom: 80%;"></p><p>如上图所示，假如某Max Pooling层的上1层是1个有2个卷积核的卷积层，该卷积层的输出是一个张量（大小为2×4×4，即2个通道、每个通道中矩阵的大小为4×4）。</p><p>对于输入中的每个通道，Max Pooling将4×4的矩阵划分成4个2×2的子矩阵（子矩阵大小可以人为设定），只取出每个子矩阵中的最大值就得到一个2×2的矩阵。又因为该Max Pooling层的输入有2个通道，所以其输出就是一个大小为2×2×2的张量。</p><h3 id="取最大值的话，该怎么微分？"><a href="#取最大值的话，该怎么微分？" class="headerlink" title="取最大值的话，该怎么微分？"></a>取最大值的话，该怎么微分？</h3><p>见笔记“Tips for Training DNN”Maxout部分，Max Pooling和Maxout其实是一样的。</p><h2 id="Flatten-amp-FNN"><a href="#Flatten-amp-FNN" class="headerlink" title="Flatten &amp; FNN"></a>Flatten &amp; FNN</h2><p>经过一系列的卷积和最大池化，将得到的特征图展开排列，作为FNN的输入，最后输出结果。</p><p><img src="https://pic4.zhimg.com/80/v2-591c85b68d94cb41194b8a70303a063c_720w.png" alt="img" style="zoom: 80%;"></p><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;卷积神经网络（CNN）常常被用来做图像处理，当然也可以用一般的神经网络，那它们各自有什么优缺点呢？&lt;/p&gt;
&lt;h2 id=&quot;FNN用于图片处理的缺点&quot;&gt;&lt;a href=&quot;#FNN用于图片处理的缺点&quot; class=&quot;headerlink&quot; title=&quot;FNN用于图片处理的缺
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://chouxianyu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="https://chouxianyu.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="卷积神经网络" scheme="https://chouxianyu.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-4.5逻辑回归Python实战</title>
    <link href="https://chouxianyu.github.io/2021/03/28/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-4-5%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92Python%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/03/28/李宏毅机器学习课程笔记-4-5逻辑回归Python实战/</id>
    <published>2021-03-28T02:40:20.000Z</published>
    <updated>2021-04-13T08:57:16.104Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework2的记录。</p><p>关注我的公众号：<code>臭咸鱼</code>，回复<code>LHY</code>可获取课程PPT、数据和代码下载链接。</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述（Task Description）</p><p>  二分类（Binary Classification）</p><p>  根据个人资料，判断每个人的年收入是否超过50000美元。</p></li><li><p>数据集描述（Dataset Description）</p><ul><li>train.csv</li><li>test_no_label.csv</li><li>x_train.csv</li><li>Y_train.csv</li><li>X_test.csv</li></ul></li><li><p>参考链接</p><p>  <a href="https://colab.research.google.com/drive/1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C" target="_blank" rel="noopener">https://colab.research.google.com/drive/1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C</a></p></li><li><p>代码</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">np.random.seed(<span class="number">0</span>) <span class="comment"># 使每次随机生成的数字相同</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 函数定义</span></span><br><span class="line"><span class="comment"># 归一化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_normalize</span><span class="params">(X, train=True, specified_column=None, X_mean=None, X_std=None)</span>:</span></span><br><span class="line">    <span class="comment"># This function normalizes specific columns of X.</span></span><br><span class="line">    <span class="comment"># The mean and standard variance of training data will be reused when processing testing data.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Arguments:</span></span><br><span class="line">    <span class="comment">#     X: data to be processed</span></span><br><span class="line">    <span class="comment">#     train: 'True' when processing training data, 'False' for testing data</span></span><br><span class="line">    <span class="comment">#     specific_column: indexes of the columns that will be normalized. If 'None', all columns</span></span><br><span class="line">    <span class="comment">#         will be normalized.</span></span><br><span class="line">    <span class="comment">#     X_mean: mean value of training data, used when train = 'False'</span></span><br><span class="line">    <span class="comment">#     X_std: standard deviation of training data, used when train = 'False'</span></span><br><span class="line">    <span class="comment"># Outputs:</span></span><br><span class="line">    <span class="comment">#     X: normalized data</span></span><br><span class="line">    <span class="comment">#     X_mean: computed mean value of training data</span></span><br><span class="line">    <span class="comment">#     X_std: computed standard deviation of training data</span></span><br><span class="line">    <span class="keyword">if</span> specified_column <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        specified_column = np.arange(X.shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        X_mean = np.mean(X[:, specified_column], axis=<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        X_std = np.std(X[:, specified_column], axis=<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    X[:, specified_column] = (X[:, specified_column] - X_mean) / (X_std + <span class="number">1e-8</span>)</span><br><span class="line">    <span class="keyword">return</span> X, X_mean, X_std</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集划分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_train_valid_split</span><span class="params">(X, Y, valid_ratio=<span class="number">0.25</span>)</span>:</span></span><br><span class="line">    <span class="comment"># This function splits data into training set and validation set.</span></span><br><span class="line">    train_size = int(len(X) * (<span class="number">1</span> - valid_ratio))</span><br><span class="line">    <span class="keyword">return</span> X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据打乱</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span><span class="params">(X, Y)</span>:</span></span><br><span class="line">    <span class="comment"># This function shuffles two equal-length list/array, X and Y, together.</span></span><br><span class="line">    randomize = np.arange(len(X))</span><br><span class="line">    np.random.shuffle(randomize)</span><br><span class="line">    <span class="keyword">return</span> (X[randomize], Y[randomize])</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="comment"># Sigmoid function can be used to calculate probability.</span></span><br><span class="line">    <span class="comment"># To avoid overflow, minimum/maximum output value is set.</span></span><br><span class="line">    <span class="keyword">return</span> np.clip(<span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-z)), <span class="number">1e-8</span>, <span class="number">1</span> - ( <span class="number">1e-8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_f</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This is the logistic regression function, parameterized by w and b</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Arguements:</span></span><br><span class="line">    <span class="comment">#     X: input data, shape = [batch_size, data_dimension]</span></span><br><span class="line">    <span class="comment">#     w: weight vector, shape = [data_dimension, ]</span></span><br><span class="line">    <span class="comment">#     b: bias, scalar</span></span><br><span class="line">    <span class="comment"># Output:</span></span><br><span class="line">    <span class="comment">#     predicted probability of each row of X being positively labeled, shape = [batch_size, ]</span></span><br><span class="line">    <span class="keyword">return</span> _sigmoid(np.matmul(X, w) + b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This function returns a truth value prediction for each row of X </span></span><br><span class="line">    <span class="comment"># by rounding the result of logistic regression function.</span></span><br><span class="line">    <span class="keyword">return</span> np.round(_f(X, w, b)).astype(np.int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_accuracy</span><span class="params">(Y_pred, Y_label)</span>:</span></span><br><span class="line">    <span class="comment"># This function calculates prediction accuracy</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - np.mean(np.abs(Y_pred - Y_label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉熵损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_cross_entropy_loss</span><span class="params">(y_pred, Y_label)</span>:</span></span><br><span class="line">    <span class="comment"># This function computes the cross entropy.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Arguements:</span></span><br><span class="line">    <span class="comment">#     y_pred: probabilistic predictions, float vector</span></span><br><span class="line">    <span class="comment">#     Y_label: ground truth labels, bool vector</span></span><br><span class="line">    <span class="comment"># Output:</span></span><br><span class="line">    <span class="comment">#     cross entropy, scalar</span></span><br><span class="line">    <span class="keyword">return</span> -np.dot(Y_label, np.log(y_pred)) - np.dot((<span class="number">1</span> - Y_label), np.log(<span class="number">1</span> - y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度计算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gradient</span><span class="params">(X, Y_label, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This function computes the gradient of cross entropy loss with respect to weight w and bias b.</span></span><br><span class="line">    Y_pred = _f(X, w, b)</span><br><span class="line">    pred_error = Y_label - Y_pred</span><br><span class="line">    w_grad = -np.sum(pred_error * X.T, axis=<span class="number">1</span>)</span><br><span class="line">    b_grad = -np.sum(pred_error)</span><br><span class="line">    <span class="keyword">return</span> w_grad, b_grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 文件路径</span></span><br><span class="line">X_train_fpath = <span class="string">'../data/X_train.csv'</span></span><br><span class="line">Y_train_fpath = <span class="string">'../data/Y_train.csv'</span></span><br><span class="line">X_test_fpath = <span class="string">'../data/X_test.csv'</span></span><br><span class="line">output_fpath = <span class="string">'output.csv'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 读取数据</span></span><br><span class="line"><span class="keyword">with</span> open(X_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    X_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float) <span class="comment"># 不要第一列的ID</span></span><br><span class="line">    <span class="comment"># print(X_train)</span></span><br><span class="line"><span class="keyword">with</span> open(Y_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)<span class="comment"># 不要第一列的ID，只取第二列</span></span><br><span class="line">    <span class="comment"># print(Y_train)</span></span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    X_test = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)</span><br><span class="line">    <span class="comment"># print(X_test)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 数据集处理</span></span><br><span class="line"><span class="comment"># 训练集和测试集normalization</span></span><br><span class="line">X_train, X_mean, X_std = _normalize(X_train, train=<span class="keyword">True</span>)</span><br><span class="line">X_test, _, _ = _normalize(X_test, train=<span class="keyword">False</span>, specified_column=<span class="keyword">None</span>, X_mean=X_mean, X_std=X_std)</span><br><span class="line"><span class="comment"># 训练集验证集划分</span></span><br><span class="line">X_train, Y_train, X_valid, Y_valid = _train_valid_split(X_train,Y_train, valid_ratio=<span class="number">0.1</span>)</span><br><span class="line">train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">valid_size = X_valid.shape[<span class="number">0</span>]</span><br><span class="line">test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">data_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line">print(<span class="string">'Size of training set: &#123;&#125;'</span>.format(train_size))</span><br><span class="line">print(<span class="string">'Size of validation set: &#123;&#125;'</span>.format(valid_size))</span><br><span class="line">print(<span class="string">'Size of testing set: &#123;&#125;'</span>.format(test_size))</span><br><span class="line">print(<span class="string">'Dimension of data: &#123;&#125;'</span>.format(data_dim))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 训练（使用小批次梯度下降法，Mini-batch training）</span></span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">w = np.zeros((data_dim, ))</span><br><span class="line">b = np.zeros((<span class="number">1</span>, ))</span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">max_iter = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">learning_rate = <span class="number">0.2</span></span><br><span class="line"><span class="comment"># 保存每个epoch的loss以作图</span></span><br><span class="line">train_loss = []</span><br><span class="line">valid_loss = []</span><br><span class="line">train_acc = []</span><br><span class="line">valid_acc = []</span><br><span class="line">step = <span class="number">1</span></span><br><span class="line"><span class="comment"># 迭代</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(max_iter):</span><br><span class="line">    <span class="comment"># 打乱训练集</span></span><br><span class="line">    X_train, Y_train = _shuffle(X_train, Y_train)</span><br><span class="line">    <span class="comment"># Mini-batch training</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(int(np.floor(X_train.shape[<span class="number">0</span>] / batch_size))):</span><br><span class="line">        <span class="comment"># 取batch</span></span><br><span class="line">        X = X_train[idx * batch_size : idx * batch_size + batch_size]</span><br><span class="line">        Y = Y_train[idx * batch_size : idx * batch_size + batch_size]</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        w_grad, b_grad = _gradient(X, Y, w, b)</span><br><span class="line">        <span class="comment"># 梯度下降（learning rate decay with time）</span></span><br><span class="line">        w = w - learning_rate / np.sqrt(step) * w_grad</span><br><span class="line">        b = b - learning_rate / np.sqrt(step) * b_grad</span><br><span class="line">        step = step + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算训练集和验证集的loss和精度</span></span><br><span class="line">    y_train_pred = _f(X_train, w, b)</span><br><span class="line">    Y_train_pred = np.round(y_train_pred)</span><br><span class="line">    train_acc.append(_accuracy(Y_train_pred, Y_train))</span><br><span class="line">    train_loss.append(_cross_entropy_loss(y_train_pred, Y_train) / train_size)</span><br><span class="line">    y_valid_pred = _f(X_valid, w, b)</span><br><span class="line">    Y_valid_pred = np.round(y_valid_pred)</span><br><span class="line">    valid_acc.append(_accuracy(Y_valid_pred, Y_valid))</span><br><span class="line">    valid_loss.append(_cross_entropy_loss(y_valid_pred, Y_valid) / valid_size)</span><br><span class="line">print(<span class="string">'Training loss: &#123;&#125;'</span>.format(train_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Validation loss: &#123;&#125;'</span>.format(valid_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Training accuracy: &#123;&#125;'</span>.format(train_acc[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Validation accuracy: &#123;&#125;'</span>.format(valid_acc[<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 训练过程可视化</span></span><br><span class="line"><span class="comment"># loss可视化</span></span><br><span class="line">plt.plot(train_loss)</span><br><span class="line">plt.plot(valid_loss)</span><br><span class="line">plt.title(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'valid'</span>])</span><br><span class="line">plt.savefig(<span class="string">'Loss.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># accuracy可视化</span></span><br><span class="line">plt.plot(train_acc)</span><br><span class="line">plt.plot(valid_acc)</span><br><span class="line">plt.title(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'valid'</span>])</span><br><span class="line">plt.savefig(<span class="string">'Accuracy.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 预测测试集</span></span><br><span class="line">predictions = _predict(X_test, w, b)</span><br><span class="line"><span class="keyword">with</span> open(output_fpath, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'id,label\n'</span>)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(predictions):</span><br><span class="line">        f.write(<span class="string">'&#123;&#125;,&#123;&#125;\n'</span>.format(i, label))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 寻找最重要的10个维度的特征</span></span><br><span class="line">index = np.argsort(np.abs(w))[::<span class="number">-1</span>] <span class="comment"># 将w按绝对值从大到小排序</span></span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    features = np.array(f.readline().strip(<span class="string">'\n'</span>).split(<span class="string">','</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index[:<span class="number">10</span>]:</span><br><span class="line">        print(features[i], w[i])</span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework2的记录。&lt;/p&gt;
&lt;p&gt;关注我的公众号：&lt;code&gt;臭咸鱼&lt;/code&gt;，回复&lt;code&gt;LHY&lt;/code&gt;可获取课程PPT、数据和代码下载链接。&lt;/p&gt;
&lt;p&gt;代码仓库：&lt;a href=&quot;https://g
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="逻辑回归" scheme="https://chouxianyu.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="线性回归" scheme="https://chouxianyu.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="分类" scheme="https://chouxianyu.github.io/tags/%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习课程笔记-4.4概率生成模型Python实战</title>
    <link href="https://chouxianyu.github.io/2021/03/28/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-4-4%E6%A6%82%E7%8E%87%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8BPython%E5%AE%9E%E6%88%98/"/>
    <id>https://chouxianyu.github.io/2021/03/28/李宏毅机器学习课程笔记-4-4概率生成模型Python实战/</id>
    <published>2021-03-28T02:12:34.000Z</published>
    <updated>2021-04-13T08:57:27.173Z</updated>
    
    <content type="html"><![CDATA[<p>本文为作者学习李宏毅机器学习课程时参照样例完成homework2的记录。</p><p>关注我的公众号：<code>臭咸鱼</code>，回复<code>LHY</code>可获取课程PPT、数据和代码下载链接。</p><p>代码仓库：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes" target="_blank" rel="noopener">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p><ul><li><p>任务描述（Task Description）</p><p>  二分类（Binary Classification）</p><p>  根据个人资料，判断每个人的年收入是否超过50000美元。</p></li><li><p>数据集描述（Dataset Description）</p><ul><li>train.csv</li><li>test_no_label.csv</li><li>x_train.csv</li><li>Y_train.csv</li><li>X_test.csv</li></ul></li><li><p>参考链接</p><p>  <a href="https://colab.research.google.com/drive/1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C" target="_blank" rel="noopener">https://colab.research.google.com/drive/1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C</a></p></li><li><p>代码</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 文件路径</span></span><br><span class="line">X_train_fpath = <span class="string">'../data/X_train.csv'</span></span><br><span class="line">Y_train_fpath = <span class="string">'../data/Y_train.csv'</span></span><br><span class="line">X_test_fpath = <span class="string">'../data/X_test.csv'</span></span><br><span class="line">output_fpath = <span class="string">'output.csv'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 函数定义</span></span><br><span class="line"><span class="comment"># 归一化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_normalize</span><span class="params">(X, train=True, specified_column=None, X_mean=None, X_std=None)</span>:</span></span><br><span class="line">    <span class="comment"># This function normalizes specific columns of X.</span></span><br><span class="line">    <span class="comment"># The mean and standard variance of training data will be reused when processing testing data.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Arguments:</span></span><br><span class="line">    <span class="comment">#     X: data to be processed</span></span><br><span class="line">    <span class="comment">#     train: 'True' when processing training data, 'False' for testing data</span></span><br><span class="line">    <span class="comment">#     specific_column: indexes of the columns that will be normalized. If 'None', all columns</span></span><br><span class="line">    <span class="comment">#         will be normalized.</span></span><br><span class="line">    <span class="comment">#     X_mean: mean value of training data, used when train = 'False'</span></span><br><span class="line">    <span class="comment">#     X_std: standard deviation of training data, used when train = 'False'</span></span><br><span class="line">    <span class="comment"># Outputs:</span></span><br><span class="line">    <span class="comment">#     X: normalized data</span></span><br><span class="line">    <span class="comment">#     X_mean: computed mean value of training data</span></span><br><span class="line">    <span class="comment">#     X_std: computed standard deviation of training data</span></span><br><span class="line">    <span class="keyword">if</span> specified_column <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        specified_column = np.arange(X.shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        X_mean = np.mean(X[:, specified_column], axis=<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        X_std = np.std(X[:, specified_column], axis=<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    X[:, specified_column] = (X[:, specified_column] - X_mean) / (X_std + <span class="number">1e-8</span>)</span><br><span class="line">    <span class="keyword">return</span> X, X_mean, X_std</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集划分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_train_valid_split</span><span class="params">(X, Y, valid_ratio=<span class="number">0.25</span>)</span>:</span></span><br><span class="line">    <span class="comment"># This function splits data into training set and validation set.</span></span><br><span class="line">    train_size = int(len(X) * (<span class="number">1</span> - valid_ratio))</span><br><span class="line">    <span class="keyword">return</span> X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="comment"># Sigmoid function can be used to calculate probability.</span></span><br><span class="line">    <span class="comment"># To avoid overflow, minimum/maximum output value is set.</span></span><br><span class="line">    <span class="keyword">return</span> np.clip(<span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-z)), <span class="number">1e-8</span>, <span class="number">1</span> - ( <span class="number">1e-8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_f</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This is the logistic regression function, parameterized by w and b</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Arguements:</span></span><br><span class="line">    <span class="comment">#     X: input data, shape = [batch_size, data_dimension]</span></span><br><span class="line">    <span class="comment">#     w: weight vector, shape = [data_dimension, ]</span></span><br><span class="line">    <span class="comment">#     b: bias, scalar</span></span><br><span class="line">    <span class="comment"># Output:</span></span><br><span class="line">    <span class="comment">#     predicted probability of each row of X being positively labeled, shape = [batch_size, ]</span></span><br><span class="line">    <span class="keyword">return</span> _sigmoid(np.matmul(X, w) + b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This function returns a truth value prediction for each row of X </span></span><br><span class="line">    <span class="comment"># by rounding the result of logistic regression function.</span></span><br><span class="line">    <span class="keyword">return</span> np.round(_f(X, w, b)).astype(np.int)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_accuracy</span><span class="params">(Y_pred, Y_label)</span>:</span></span><br><span class="line">    <span class="comment"># This function calculates prediction accuracy</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - np.mean(np.abs(Y_pred - Y_label))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 读取数据</span></span><br><span class="line"><span class="keyword">with</span> open(X_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    X_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float) <span class="comment"># 不要第一列的ID</span></span><br><span class="line">    <span class="comment"># print(X_train)</span></span><br><span class="line"><span class="keyword">with</span> open(Y_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)<span class="comment"># 不要第一列的ID，只取第二列</span></span><br><span class="line">    <span class="comment"># print(Y_train)</span></span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f) <span class="comment"># 不需要第一行的表头</span></span><br><span class="line">    X_test = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)</span><br><span class="line">    <span class="comment"># print(X_test)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 数据集处理</span></span><br><span class="line"><span class="comment"># 训练集和测试集normalization</span></span><br><span class="line">X_train, X_mean, X_std = _normalize(X_train, train=<span class="keyword">True</span>)</span><br><span class="line">X_test, _, _ = _normalize(X_test, train=<span class="keyword">False</span>, specified_column=<span class="keyword">None</span>, X_mean=X_mean, X_std=X_std)</span><br><span class="line">data_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算每个类别的样本的平均值和协方差</span></span><br><span class="line"><span class="comment"># 区分类别</span></span><br><span class="line">X_train_0 = np.array([x <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X_train, Y_train) <span class="keyword">if</span> y==<span class="number">0</span>])</span><br><span class="line">X_train_1 = np.array([x <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X_train, Y_train) <span class="keyword">if</span> y==<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 计算每个类别的样本的平均值</span></span><br><span class="line">mean_0 = np.mean(X_train_0, axis=<span class="number">0</span>) <span class="comment"># 计算每个维度特征的平均值</span></span><br><span class="line">mean_1 = np.mean(X_train_1, axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 计算每个类别的样本的协方差矩阵（可以研究下协方差矩阵是如何计算的以及为什么）</span></span><br><span class="line">cov_0 = np.zeros((data_dim, data_dim))</span><br><span class="line">cov_1 = np.zeros((data_dim, data_dim))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> X_train_0:</span><br><span class="line">    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[<span class="number">0</span>] <span class="comment"># transpose没有参数的话，就是转置，计算协方差矩阵时需要转置</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> X_train_1:</span><br><span class="line">    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 计算共享协方差矩阵（Shared covariance is taken as a weighted average of individual in-class covariance）</span></span><br><span class="line">cov = (cov_0 * X_train_0.shape[<span class="number">0</span>] + cov_1 * X_train_1.shape[<span class="number">0</span>]) / (X_train_0.shape[<span class="number">0</span>] + X_train_1.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算权重和偏置</span></span><br><span class="line"><span class="comment"># 计算协方差矩阵的逆矩阵</span></span><br><span class="line"><span class="comment"># Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.</span></span><br><span class="line"><span class="comment"># Via SVD decomposition, one can get matrix inverse efficiently and accurately.</span></span><br><span class="line">u, s, v = np.linalg.svd(cov, full_matrices=<span class="keyword">False</span>)</span><br><span class="line">inv = np.matmul(v.T * <span class="number">1</span> / s, u.T)</span><br><span class="line"><span class="comment"># 计算weight和bias</span></span><br><span class="line">w = np.dot(inv, mean_0 - mean_1)</span><br><span class="line">b = (<span class="number">-0.5</span>) * np.dot(mean_0, np.dot(inv, mean_0)) + <span class="number">0.5</span> * np.dot(mean_1, np.dot(inv, mean_1)) + np.log(float(X_train_0.shape[<span class="number">0</span>])) / X_train_1.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算在训练集上的准确率</span></span><br><span class="line">Y_train_pred = <span class="number">1</span> - _predict(X_train, w, b)</span><br><span class="line">print(<span class="string">'Training accuracy: &#123;&#125;'</span>.format(_accuracy(Y_train_pred, Y_train)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 预测测试集结果</span></span><br><span class="line">predictions = <span class="number">1</span> - _predict(X_test, w, b)</span><br><span class="line"><span class="keyword">with</span> open(output_fpath, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'id,label\n'</span>)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(predictions):</span><br><span class="line">        f.write(<span class="string">'&#123;&#125;,&#123;&#125;\n'</span>.format(i, label))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 寻找最重要的10个维度的特征</span></span><br><span class="line">index = np.argsort(np.abs(w))[::<span class="number">-1</span>] <span class="comment"># 将w按绝对值从大到小排序</span></span><br><span class="line"><span class="keyword">with</span> open(X_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    features = np.array(f.readline().strip(<span class="string">'\n'</span>).split(<span class="string">','</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index[:<span class="number">10</span>]:</span><br><span class="line">        print(features[i], w[i])</span><br></pre></td></tr></table></figure><hr><p>Github（github.com）：<a href="https://github.com/chouxianyu" target="_blank" rel="noopener">@chouxianyu</a></p><p>Github Pages（github.io）：<a href="https://chouxianyu.github.io/">@臭咸鱼</a></p><p>知乎（zhihu.com）：<a href="https://www.zhihu.com/people/chouxianyu0" target="_blank" rel="noopener">@臭咸鱼</a></p><p>博客园（cnblogs.com）：<a href="https://www.cnblogs.com/chouxianyu/" target="_blank" rel="noopener">@臭咸鱼</a></p><p>B站（bilibili.com）：<a href="https://space.bilibili.com/346368054" target="_blank" rel="noopener">@绝版臭咸鱼</a></p><p>微信公众号：<a href="https://images.cnblogs.com/cnblogs_com/chouxianyu/1511971/o_201224051323wechat_qrcode.jpg" target="_blank" rel="noopener">@臭咸鱼</a></p><p>转载请注明出处，欢迎讨论和交流!</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文为作者学习李宏毅机器学习课程时参照样例完成homework2的记录。&lt;/p&gt;
&lt;p&gt;关注我的公众号：&lt;code&gt;臭咸鱼&lt;/code&gt;，回复&lt;code&gt;LHY&lt;/code&gt;可获取课程PPT、数据和代码下载链接。&lt;/p&gt;
&lt;p&gt;代码仓库：&lt;a href=&quot;https://g
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://chouxianyu.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概率生成模型" scheme="https://chouxianyu.github.io/tags/%E6%A6%82%E7%8E%87%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="分类" scheme="https://chouxianyu.github.io/tags/%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
</feed>
